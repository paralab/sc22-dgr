// generated by Dendro-GR SymPyGR code gernation framework
//date: 2018-10-14 00:09:24
#include "rhs_bssn.cuh"
namespace cuda {

/**@brief compute RHS 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__global__ void __computeBSSNRHS(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams ,const cudaDeviceProp* __deviceProperties, unsigned int stream_id){

// shared memory allocation for deriv and rhs computation
__shared__  double __sm_base[5248];
	__shared__ bool beta0_bool[1728];
	__shared__ bool beta1_bool[1728];
	__shared__ bool beta2_bool[1728];

	for(unsigned int blk=__gpuBlockMap[2*blockIdx.x];blk<__gpuBlockMap[2*blockIdx.x+1];++blk){


	// blocks assigned to each gpu block 
	const _Block * dblock=&__dendroBlkList[blk];
	// compute the derivatives
	__compute_derivatives(__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,beta0_bool,beta1_bool,beta2_bool,stream_id);
	__syncthreads();
	// compute the RHS
	__compute_a_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_b_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_gt_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_chi_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_At_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_K_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_Gt_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__compute_B_rhs(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	__ko_dissipation(__unzipOutVar,__unzipInVar,__derivWorkspace,dblock,__gpuBlockMap,__bssnParams,__deviceProperties,__sm_base,stream_id);
	__syncthreads();
	}// end of the block loop
} // end of kernel 


/**@brief compute derivs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
*/ 
__device__ void __compute_derivatives(const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, bool* beta0_bool, bool* beta1_bool, bool* beta2_bool, unsigned int stream_id){

	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={12,12,12};
	double * unzipVarInShared = __sm_base + 0;
	double * unzipVarOutShared0 = __sm_base + 1728;
	double * unzipVarOutShared1 = __sm_base + 3456;
	const unsigned int Lb = 0;// load begin bound
	const unsigned int Le = sz[0]-0;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*3)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(0,(int)(0 + tile_sz[2]*iter_z -2*iter_z*3));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-0-1);


		 if((ijk_lm[5]-ijk_lm[4]+1)<=9) 
		  ijk_lm[4]=ijk_lm[4]-(9-(ijk_lm[5]-ijk_lm[4]+1)) ; 
 
	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(0,(int)(0 + tile_sz[1]*iter_y -2*iter_y*3));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-0-1);

		 if((ijk_lm[3]-ijk_lm[2]+1)<=9) 
		  ijk_lm[2]=ijk_lm[2]-(9-(ijk_lm[3]-ijk_lm[2]+1)) ; 
 
	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(0,(int)(0 + tile_sz[0]*iter_x -2*iter_x*3));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-0-1);

		 if((ijk_lm[1]-ijk_lm[0]+1)<=9) 
		  ijk_lm[0]=ijk_lm[0]-(9-(ijk_lm[1]-ijk_lm[0]+1)) ; 
 

		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) unzipVarOutShared0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) unzipVarOutShared1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		cuda::__extractSign3D<double>((double *)unzipVarInShared,(bool *) beta0_bool,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		cuda::__extractSign3D<double>((double *)unzipVarOutShared0,(bool *) beta1_bool,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		cuda::__extractSign3D<double>((double *)unzipVarOutShared1,(bool *) beta2_bool,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable alpha 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable alpha 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable alpha 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable alpha 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable alpha 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable alpha 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable beta0 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable beta0 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable beta0 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable beta0 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable beta0 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable beta0 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable beta1 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable beta1 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable beta1 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable beta1 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable beta1 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable beta1 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable beta2 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable beta2 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable beta2 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable beta2 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable beta2 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable beta2 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B0][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable B0 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable B0 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable B0 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B1][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable B1 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable B1 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable B1 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B2][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable B2 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable B2 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable B2 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable chi 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable chi 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable chi 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable chi 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable chi 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable chi 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_GT0][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable Gt0 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable Gt0 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable Gt0 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_GT1][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable Gt1 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable Gt1 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable Gt1 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_GT2][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable Gt2 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable Gt2 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable Gt2 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable K 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable K 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable K 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable gt0 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable gt0 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable gt0 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable gt0 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable gt0 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable gt0 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable gt1 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable gt1 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable gt1 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable gt1 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable gt1 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable gt1 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable gt2 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable gt2 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable gt2 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable gt2 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable gt2 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable gt2 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable gt3 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable gt3 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable gt3 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable gt3 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable gt3 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable gt3 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable gt4 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable gt4 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable gt4 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable gt4 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable gt4 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable gt4 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable gt5 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv xy for variable gt5 
		_RSWS_deriv42_y((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv xz for variable gt5 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_0_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable gt5 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();
		// computing deriv yz for variable gt5 
		_RSWS_deriv42_z((double *) unzipVarOutShared1,(const double *) unzipVarOutShared0,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared1,&(__derivWorkspace->__grad2_1_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);


		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable gt5 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_deriv42_xx((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_0_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_yy((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_1_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42_zz((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad2_2_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable At0 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable At0 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable At0 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable At1 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable At1 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable At1 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable At2 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable At2 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable At2 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable At3 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable At3 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable At3 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable At4 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable At4 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable At4 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		//load input data from global to shared memory
		cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) unzipVarInShared,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		__syncthreads();
		//sync to make sure all the data is loaded
		// computing deriv x for variable At5 
		_RSWS_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_0_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv y for variable At5 
		_RSWS_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_1_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		// computing deriv z for variable At5 
		_RSWS_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__grad_2_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();


		_RSWS_ko_deriv42_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_0_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_1_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_ko_deriv42_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz,(const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__kograd_2_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_x((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dx, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta0_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=3;
		tile_lm[1]=(ijk_lm[1]-ijk_lm[0]);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_0_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_y((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dy, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta1_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=3;
		tile_lm[3]=(ijk_lm[3]-ijk_lm[2]);

		tile_lm[4]=(iter_z)? 3: 0;
		tile_lm[5]=(iter_z==(BLK_ITERATIONS_Z-1)) ? (ijk_lm[5]-ijk_lm[4]) : (ijk_lm[5]-ijk_lm[4]-3);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_1_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		_RSWS_deriv42adv_z((double *) unzipVarOutShared0,(const double *) unzipVarInShared,dz, (const unsigned int *) ijk_lm , (const unsigned int *) alignedSz , (const unsigned int *) tile_sz, (const bool*) beta2_bool , 3, bflag);
		__syncthreads();

		tile_lm[0]=(iter_x)? 3: 0;
		tile_lm[1]=(iter_x==(BLK_ITERATIONS_X-1)) ? (ijk_lm[1]-ijk_lm[0]) : (ijk_lm[1]-ijk_lm[0]-3);

		tile_lm[2]=(iter_y)? 3: 0;
		tile_lm[3]=(iter_y==(BLK_ITERATIONS_Y-1)) ? (ijk_lm[3]-ijk_lm[2]) : (ijk_lm[3]-ijk_lm[2]-3);

		tile_lm[4]=3;
		tile_lm[5]=(ijk_lm[5]-ijk_lm[4]);


		cuda::__storeSharedToGlobal3D<double>((double *) unzipVarOutShared0,&(__derivWorkspace->__agrad_2_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();
		  } // end of block tile loop x
		 } // end of block tile loop y
		} // end of block tile loop z

} // end of function __compute_derivatives

/**@brief compute a_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_a_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for a_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={8,8,8};
	
	 //input vars begin
	double * alpha = __sm_base + 0;
	double * K = __sm_base + 512;
	double * beta0 = __sm_base + 1024;
	double * beta1 = __sm_base + 1536;
	double * beta2 = __sm_base + 2048;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * agrad_1_alpha = __sm_base + 2560;
	double * agrad_2_alpha = __sm_base + 3072;
	double * agrad_0_alpha = __sm_base + 3584;
	 // deriv vars end
	 // output vars begin
	double * a_rhs = __sm_base + 4096;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 12
			     // Dendro: printing temp variables
			      // Dendro: printing variables

		   a_rhs[pp] = -2*K[pp]*alpha[pp] + lambda[0]*(beta0[pp]*agrad_0_alpha[pp] + beta1[pp]*agrad_1_alpha[pp] + beta2[pp]*agrad_2_alpha[pp]);
			      // Dendro: reduced ops: 12
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(a_rhs, &__unzipOutVar[cuda::VAR::U_ALPHA][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_a_rhs 

/**@brief compute b_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_b_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for b_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={6,6,6};
	
	 //input vars begin
	double * beta1 = __sm_base + 0;
	double * beta2 = __sm_base + 216;
	double * alpha = __sm_base + 432;
	double * B2 = __sm_base + 648;
	double * beta0 = __sm_base + 864;
	double * B1 = __sm_base + 1080;
	double * B0 = __sm_base + 1296;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * agrad_1_beta1 = __sm_base + 1512;
	double * agrad_1_beta2 = __sm_base + 1728;
	double * agrad_0_beta2 = __sm_base + 1944;
	double * agrad_2_beta0 = __sm_base + 2160;
	double * agrad_2_beta2 = __sm_base + 2376;
	double * agrad_2_beta1 = __sm_base + 2592;
	double * agrad_0_beta1 = __sm_base + 2808;
	double * agrad_1_beta0 = __sm_base + 3024;
	double * agrad_0_beta0 = __sm_base + 3240;
	 // deriv vars end
	 // output vars begin
	double * b_rhs0 = __sm_base + 3456;
	double * b_rhs2 = __sm_base + 3672;
	double * b_rhs1 = __sm_base + 3888;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B2][offset],(double *) B2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B1][offset],(double *) B1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B0][offset],(double *) B0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 51
			     // Dendro: printing temp variables
		 const double DENDRO_0 = (3.0L/4.0L)*alpha[pp]*lambda_f[1] + (3.0L/4.0L)*lambda_f[0];
			      // Dendro: printing variables

		   b_rhs0[pp] = B0[pp]*DENDRO_0 + lambda[1]*(beta0[pp]*agrad_0_beta0[pp] + beta1[pp]*agrad_1_beta0[pp] + beta2[pp]*agrad_2_beta0[pp]);
		   b_rhs1[pp] = B1[pp]*DENDRO_0 + lambda[1]*(beta0[pp]*agrad_0_beta1[pp] + beta1[pp]*agrad_1_beta1[pp] + beta2[pp]*agrad_2_beta1[pp]);
		   b_rhs2[pp] = B2[pp]*DENDRO_0 + lambda[1]*(beta0[pp]*agrad_0_beta2[pp] + beta1[pp]*agrad_1_beta2[pp] + beta2[pp]*agrad_2_beta2[pp]);
			      // Dendro: reduced ops: 39
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(b_rhs0, &__unzipOutVar[cuda::VAR::U_BETA0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(b_rhs2, &__unzipOutVar[cuda::VAR::U_BETA2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(b_rhs1, &__unzipOutVar[cuda::VAR::U_BETA1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_b_rhs 

/**@brief compute gt_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_gt_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for gt_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={4,4,4};
	
	 //input vars begin
	double * gt1 = __sm_base + 0;
	double * beta1 = __sm_base + 64;
	double * gt3 = __sm_base + 128;
	double * beta2 = __sm_base + 192;
	double * At1 = __sm_base + 256;
	double * alpha = __sm_base + 320;
	double * gt4 = __sm_base + 384;
	double * gt2 = __sm_base + 448;
	double * gt5 = __sm_base + 512;
	double * At3 = __sm_base + 576;
	double * At4 = __sm_base + 640;
	double * At0 = __sm_base + 704;
	double * At2 = __sm_base + 768;
	double * beta0 = __sm_base + 832;
	double * gt0 = __sm_base + 896;
	double * At5 = __sm_base + 960;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * agrad_2_gt5 = __sm_base + 1024;
	double * agrad_2_gt1 = __sm_base + 1088;
	double * grad_0_beta0 = __sm_base + 1152;
	double * agrad_0_gt0 = __sm_base + 1216;
	double * agrad_1_gt3 = __sm_base + 1280;
	double * grad_1_beta1 = __sm_base + 1344;
	double * grad_2_beta0 = __sm_base + 1408;
	double * agrad_1_gt0 = __sm_base + 1472;
	double * agrad_1_gt4 = __sm_base + 1536;
	double * grad_0_beta1 = __sm_base + 1600;
	double * agrad_2_gt2 = __sm_base + 1664;
	double * grad_2_beta2 = __sm_base + 1728;
	double * agrad_2_gt0 = __sm_base + 1792;
	double * agrad_1_gt2 = __sm_base + 1856;
	double * agrad_0_gt5 = __sm_base + 1920;
	double * agrad_1_gt5 = __sm_base + 1984;
	double * agrad_0_gt3 = __sm_base + 2048;
	double * agrad_0_gt2 = __sm_base + 2112;
	double * agrad_1_gt1 = __sm_base + 2176;
	double * agrad_0_gt1 = __sm_base + 2240;
	double * grad_2_beta1 = __sm_base + 2304;
	double * agrad_2_gt4 = __sm_base + 2368;
	double * grad_1_beta0 = __sm_base + 2432;
	double * agrad_2_gt3 = __sm_base + 2496;
	double * grad_0_beta2 = __sm_base + 2560;
	double * grad_1_beta2 = __sm_base + 2624;
	double * agrad_0_gt4 = __sm_base + 2688;
	 // deriv vars end
	 // output vars begin
	double * gt_rhs01 = __sm_base + 2752;
	double * gt_rhs22 = __sm_base + 2816;
	double * gt_rhs11 = __sm_base + 2880;
	double * gt_rhs00 = __sm_base + 2944;
	double * gt_rhs12 = __sm_base + 3008;
	double * gt_rhs02 = __sm_base + 3072;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 210
			     // Dendro: printing temp variables
		 const double DENDRO_0 = 2*alpha[pp];
		 const double DENDRO_1 = grad_0_beta0[pp];
		 const double DENDRO_2 = (2.0L/3.0L)*gt0[pp];
		 const double DENDRO_3 = grad_1_beta1[pp];
		 const double DENDRO_4 = grad_2_beta2[pp];
		 const double DENDRO_5 = 2*gt1[pp];
		 const double DENDRO_6 = grad_0_beta1[pp];
		 const double DENDRO_7 = 2*gt2[pp];
		 const double DENDRO_8 = grad_0_beta2[pp];
		 const double DENDRO_9 = grad_1_beta0[pp];
		 const double DENDRO_10 = grad_1_beta2[pp];
		 const double DENDRO_11 = (1.0L/3.0L)*gt1[pp];
		 const double DENDRO_12 = (2.0L/3.0L)*DENDRO_4;
		 const double DENDRO_13 = grad_2_beta0[pp];
		 const double DENDRO_14 = grad_2_beta1[pp];
		 const double DENDRO_15 = (1.0L/3.0L)*gt2[pp];
		 const double DENDRO_16 = (2.0L/3.0L)*DENDRO_3;
		 const double DENDRO_17 = (2.0L/3.0L)*DENDRO_1;
		 const double DENDRO_18 = 2*gt4[pp];
		 const double DENDRO_19 = (1.0L/3.0L)*gt4[pp];
			      // Dendro: printing variables

		   gt_rhs00[pp] = -At0[pp]*DENDRO_0 + (4.0L/3.0L)*DENDRO_1*gt0[pp] - DENDRO_2*DENDRO_3 - DENDRO_2*DENDRO_4 + DENDRO_5*DENDRO_6 + DENDRO_7*DENDRO_8 + beta0[pp]*agrad_0_gt0[pp] + beta1[pp]*agrad_1_gt0[pp] + beta2[pp]*agrad_2_gt0[pp];
		   gt_rhs01[pp] = -At1[pp]*DENDRO_0 + DENDRO_1*DENDRO_11 + DENDRO_10*gt2[pp] + DENDRO_11*DENDRO_3 - DENDRO_12*gt1[pp] + DENDRO_6*gt3[pp] + DENDRO_8*gt4[pp] + DENDRO_9*gt0[pp] + beta0[pp]*agrad_0_gt1[pp] + beta1[pp]*agrad_1_gt1[pp] + beta2[pp]*agrad_2_gt1[pp];
		   gt_rhs02[pp] = -At2[pp]*DENDRO_0 + DENDRO_1*DENDRO_15 + DENDRO_13*gt0[pp] + DENDRO_14*gt1[pp] + DENDRO_15*DENDRO_4 - DENDRO_16*gt2[pp] + DENDRO_6*gt4[pp] + DENDRO_8*gt5[pp] + beta0[pp]*agrad_0_gt2[pp] + beta1[pp]*agrad_1_gt2[pp] + beta2[pp]*agrad_2_gt2[pp];
		   gt_rhs11[pp] = -At3[pp]*DENDRO_0 + DENDRO_10*DENDRO_18 - DENDRO_12*gt3[pp] - DENDRO_17*gt3[pp] + (4.0L/3.0L)*DENDRO_3*gt3[pp] + DENDRO_5*DENDRO_9 + beta0[pp]*agrad_0_gt3[pp] + beta1[pp]*agrad_1_gt3[pp] + beta2[pp]*agrad_2_gt3[pp];
		   gt_rhs12[pp] = -At4[pp]*DENDRO_0 + DENDRO_10*gt5[pp] + DENDRO_13*gt1[pp] + DENDRO_14*gt3[pp] - DENDRO_17*gt4[pp] + DENDRO_19*DENDRO_3 + DENDRO_19*DENDRO_4 + DENDRO_9*gt2[pp] + beta0[pp]*agrad_0_gt4[pp] + beta1[pp]*agrad_1_gt4[pp] + beta2[pp]*agrad_2_gt4[pp];
		   gt_rhs22[pp] = -At5[pp]*DENDRO_0 + DENDRO_13*DENDRO_7 + DENDRO_14*DENDRO_18 - DENDRO_16*gt5[pp] - DENDRO_17*gt5[pp] + (4.0L/3.0L)*DENDRO_4*gt5[pp] + beta0[pp]*agrad_0_gt5[pp] + beta1[pp]*agrad_1_gt5[pp] + beta2[pp]*agrad_2_gt5[pp];
			      // Dendro: reduced ops: 162
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(gt_rhs01, &__unzipOutVar[cuda::VAR::U_SYMGT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(gt_rhs22, &__unzipOutVar[cuda::VAR::U_SYMGT5][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(gt_rhs11, &__unzipOutVar[cuda::VAR::U_SYMGT3][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(gt_rhs00, &__unzipOutVar[cuda::VAR::U_SYMGT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(gt_rhs12, &__unzipOutVar[cuda::VAR::U_SYMGT4][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(gt_rhs02, &__unzipOutVar[cuda::VAR::U_SYMGT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_gt_rhs 

/**@brief compute chi_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_chi_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for chi_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={7,7,7};
	
	 //input vars begin
	double * K = __sm_base + 0;
	double * beta1 = __sm_base + 343;
	double * beta2 = __sm_base + 686;
	double * alpha = __sm_base + 1029;
	double * beta0 = __sm_base + 1372;
	double * chi = __sm_base + 1715;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * agrad_1_chi = __sm_base + 2058;
	double * grad_0_beta0 = __sm_base + 2401;
	double * agrad_0_chi = __sm_base + 2744;
	double * agrad_2_chi = __sm_base + 3087;
	double * grad_1_beta1 = __sm_base + 3430;
	double * grad_2_beta2 = __sm_base + 3773;
	 // deriv vars end
	 // output vars begin
	double * chi_rhs = __sm_base + 4116;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 22
			     // Dendro: printing temp variables
		 const double DENDRO_0 = (2.0L/3.0L)*chi[pp];
			      // Dendro: printing variables

		   chi_rhs[pp] = DENDRO_0*K[pp]*alpha[pp] - DENDRO_0*(grad_0_beta0[pp] + grad_1_beta1[pp] + grad_2_beta2[pp]) + beta0[pp]*agrad_0_chi[pp] + beta1[pp]*agrad_1_chi[pp] + beta2[pp]*agrad_2_chi[pp];
			      // Dendro: reduced ops: 20
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(chi_rhs, &__unzipOutVar[cuda::VAR::U_CHI][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_chi_rhs 

/**@brief compute At_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_At_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for At_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={3,3,3};
	
	 //input vars begin
	double * K = __sm_base + 0;
	double * gt1 = __sm_base + 27;
	double * beta1 = __sm_base + 54;
	double * gt3 = __sm_base + 81;
	double * At1 = __sm_base + 108;
	double * gt5 = __sm_base + 135;
	double * alpha = __sm_base + 162;
	double * gt4 = __sm_base + 189;
	double * gt2 = __sm_base + 216;
	double * beta2 = __sm_base + 243;
	double * At3 = __sm_base + 270;
	double * At4 = __sm_base + 297;
	double * At0 = __sm_base + 324;
	double * At2 = __sm_base + 351;
	double * beta0 = __sm_base + 378;
	double * gt0 = __sm_base + 405;
	double * chi = __sm_base + 432;
	double * At5 = __sm_base + 459;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * grad2_0_0_gt3 = __sm_base + 486;
	double * grad2_2_2_alpha = __sm_base + 513;
	double * grad2_1_2_gt1 = __sm_base + 540;
	double * grad_2_gt3 = __sm_base + 567;
	double * grad_1_beta1 = __sm_base + 594;
	double * grad_0_Gt1 = __sm_base + 621;
	double * grad_1_gt5 = __sm_base + 648;
	double * grad2_0_2_gt5 = __sm_base + 675;
	double * grad2_1_1_alpha = __sm_base + 702;
	double * agrad_1_At2 = __sm_base + 729;
	double * grad2_0_1_gt0 = __sm_base + 756;
	double * agrad_2_At1 = __sm_base + 783;
	double * grad_1_gt1 = __sm_base + 810;
	double * agrad_0_At3 = __sm_base + 837;
	double * agrad_1_At4 = __sm_base + 864;
	double * grad_2_beta2 = __sm_base + 891;
	double * grad_0_chi = __sm_base + 918;
	double * agrad_2_At4 = __sm_base + 945;
	double * grad2_0_2_gt4 = __sm_base + 972;
	double * grad_1_chi = __sm_base + 999;
	double * grad2_0_1_gt1 = __sm_base + 1026;
	double * grad2_1_2_alpha = __sm_base + 1053;
	double * grad2_1_2_gt3 = __sm_base + 1080;
	double * grad2_2_2_gt1 = __sm_base + 1107;
	double * agrad_2_At3 = __sm_base + 1134;
	double * grad2_0_0_gt2 = __sm_base + 1161;
	double * grad_1_beta0 = __sm_base + 1188;
	double * grad_0_gt2 = __sm_base + 1215;
	double * grad_0_beta2 = __sm_base + 1242;
	double * grad2_2_2_gt4 = __sm_base + 1269;
	double * agrad_2_At5 = __sm_base + 1296;
	double * grad_0_gt5 = __sm_base + 1323;
	double * grad2_0_1_alpha = __sm_base + 1350;
	double * agrad_2_At2 = __sm_base + 1377;
	double * grad_0_Gt2 = __sm_base + 1404;
	double * grad_0_gt4 = __sm_base + 1431;
	double * grad2_2_2_chi = __sm_base + 1458;
	double * grad2_0_2_gt3 = __sm_base + 1485;
	double * agrad_1_At1 = __sm_base + 1512;
	double * grad2_0_0_gt4 = __sm_base + 1539;
	double * grad_0_gt1 = __sm_base + 1566;
	double * grad2_0_0_gt0 = __sm_base + 1593;
	double * agrad_0_At4 = __sm_base + 1620;
	double * grad2_1_1_gt4 = __sm_base + 1647;
	double * grad2_0_2_chi = __sm_base + 1674;
	double * grad2_0_1_chi = __sm_base + 1701;
	double * grad2_0_2_gt1 = __sm_base + 1728;
	double * agrad_0_At2 = __sm_base + 1755;
	double * grad2_0_0_gt5 = __sm_base + 1782;
	double * grad_2_Gt2 = __sm_base + 1809;
	double * grad_1_Gt2 = __sm_base + 1836;
	double * agrad_0_At0 = __sm_base + 1863;
	double * grad_0_gt3 = __sm_base + 1890;
	double * grad_2_beta1 = __sm_base + 1917;
	double * grad_1_gt3 = __sm_base + 1944;
	double * grad2_1_1_gt3 = __sm_base + 1971;
	double * grad2_0_2_alpha = __sm_base + 1998;
	double * grad2_0_1_gt5 = __sm_base + 2025;
	double * agrad_2_At0 = __sm_base + 2052;
	double * grad2_2_2_gt0 = __sm_base + 2079;
	double * grad_1_gt2 = __sm_base + 2106;
	double * grad2_0_0_gt1 = __sm_base + 2133;
	double * grad2_0_1_gt3 = __sm_base + 2160;
	double * grad_2_Gt0 = __sm_base + 2187;
	double * grad_1_alpha = __sm_base + 2214;
	double * grad2_1_2_gt4 = __sm_base + 2241;
	double * grad2_1_1_gt5 = __sm_base + 2268;
	double * grad_2_gt4 = __sm_base + 2295;
	double * grad2_2_2_gt5 = __sm_base + 2322;
	double * grad_2_gt2 = __sm_base + 2349;
	double * agrad_1_At0 = __sm_base + 2376;
	double * grad2_2_2_gt3 = __sm_base + 2403;
	double * grad_2_gt1 = __sm_base + 2430;
	double * grad2_0_2_gt2 = __sm_base + 2457;
	double * grad_1_gt0 = __sm_base + 2484;
	double * grad_0_beta0 = __sm_base + 2511;
	double * grad_1_Gt0 = __sm_base + 2538;
	double * grad2_1_2_gt5 = __sm_base + 2565;
	double * grad_2_gt0 = __sm_base + 2592;
	double * grad_2_Gt1 = __sm_base + 2619;
	double * grad2_1_1_gt2 = __sm_base + 2646;
	double * grad2_2_2_gt2 = __sm_base + 2673;
	double * grad_2_alpha = __sm_base + 2700;
	double * agrad_1_At5 = __sm_base + 2727;
	double * grad_2_beta0 = __sm_base + 2754;
	double * grad_1_gt4 = __sm_base + 2781;
	double * grad2_1_1_gt0 = __sm_base + 2808;
	double * grad2_0_2_gt0 = __sm_base + 2835;
	double * grad_0_beta1 = __sm_base + 2862;
	double * grad_0_alpha = __sm_base + 2889;
	double * grad_1_Gt1 = __sm_base + 2916;
	double * grad2_1_2_gt0 = __sm_base + 2943;
	double * grad2_0_0_alpha = __sm_base + 2970;
	double * grad2_0_1_gt2 = __sm_base + 2997;
	double * grad_0_gt0 = __sm_base + 3024;
	double * grad2_1_2_gt2 = __sm_base + 3051;
	double * grad_2_gt5 = __sm_base + 3078;
	double * agrad_0_At1 = __sm_base + 3105;
	double * agrad_1_At3 = __sm_base + 3132;
	double * grad_2_chi = __sm_base + 3159;
	double * grad2_0_0_chi = __sm_base + 3186;
	double * agrad_0_At5 = __sm_base + 3213;
	double * grad2_1_1_gt1 = __sm_base + 3240;
	double * grad_0_Gt0 = __sm_base + 3267;
	double * grad2_1_1_chi = __sm_base + 3294;
	double * grad2_0_1_gt4 = __sm_base + 3321;
	double * grad2_1_2_chi = __sm_base + 3348;
	double * grad_1_beta2 = __sm_base + 3375;
	 // deriv vars end
	 // output vars begin
	double * At_rhs12 = __sm_base + 3402;
	double * At_rhs11 = __sm_base + 3429;
	double * At_rhs22 = __sm_base + 3456;
	double * At_rhs02 = __sm_base + 3483;
	double * At_rhs00 = __sm_base + 3510;
	double * At_rhs01 = __sm_base + 3537;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 630012
			     // Dendro: printing temp variables
		 const double DENDRO_0 = grad_0_beta0[pp];
		 const double DENDRO_1 = (2.0L/3.0L)*At0[pp];
		 const double DENDRO_2 = grad_1_beta1[pp];
		 const double DENDRO_3 = grad_2_beta2[pp];
		 const double DENDRO_4 = 2*At1[pp];
		 const double DENDRO_5 = grad_0_beta1[pp];
		 const double DENDRO_6 = 2*At2[pp];
		 const double DENDRO_7 = grad_0_beta2[pp];
		 const double DENDRO_8 = pow(gt4[pp], 2);
		 const double DENDRO_9 = DENDRO_8*gt0[pp];
		 const double DENDRO_10 = pow(gt1[pp], 2);
		 const double DENDRO_11 = DENDRO_10*gt5[pp];
		 const double DENDRO_12 = pow(gt2[pp], 2);
		 const double DENDRO_13 = DENDRO_12*gt3[pp];
		 const double DENDRO_14 = gt0[pp]*gt3[pp];
		 const double DENDRO_15 = DENDRO_14*gt5[pp];
		 const double DENDRO_16 = gt1[pp]*gt2[pp];
		 const double DENDRO_17 = 2*DENDRO_16*gt4[pp];
		 const double DENDRO_18 = DENDRO_11 + DENDRO_13 - DENDRO_15 - DENDRO_17 + DENDRO_9;
		 const double DENDRO_19 = 1.0/DENDRO_18;
		 const double DENDRO_20 = 2*At1[pp]*DENDRO_19;
		 const double DENDRO_21 = gt1[pp]*gt5[pp];
		 const double DENDRO_22 = gt2[pp]*gt4[pp];
		 const double DENDRO_23 = DENDRO_21 - DENDRO_22;
		 const double DENDRO_24 = gt0[pp]*gt4[pp];
		 const double DENDRO_25 = -DENDRO_16 + DENDRO_24;
		 const double DENDRO_26 = -DENDRO_12 + gt0[pp]*gt5[pp];
		 const double DENDRO_27 = 2*At0[pp]*DENDRO_19;
		 const double DENDRO_28 = At1[pp]*DENDRO_23;
		 const double DENDRO_29 = gt1[pp]*gt4[pp] - gt2[pp]*gt3[pp];
		 const double DENDRO_30 = -At2[pp]*DENDRO_29;
		 const double DENDRO_31 = -DENDRO_8 + gt3[pp]*gt5[pp];
		 const double DENDRO_32 = 2*At2[pp]*DENDRO_19;
		 const double DENDRO_33 = -DENDRO_10 + DENDRO_14;
		 const double DENDRO_34 = (1.0L/12.0L)*chi[pp];
		 const double DENDRO_35 = grad2_0_0_alpha[pp];
		 const double DENDRO_36 = grad_1_alpha[pp];
		 const double DENDRO_37 = 1.0/chi[pp];
		 const double DENDRO_38 = grad_2_chi[pp];
		 const double DENDRO_39 = grad_0_chi[pp];
		 const double DENDRO_40 = grad_1_chi[pp];
		 const double DENDRO_41 = DENDRO_26*DENDRO_40;
		 const double DENDRO_42 = DENDRO_23*DENDRO_39 + DENDRO_25*DENDRO_38 - DENDRO_41;
		 const double DENDRO_43 = 0.5*DENDRO_37*DENDRO_42;
		 const double DENDRO_44 = grad_0_gt0[pp];
		 const double DENDRO_45 = 0.5*gt1[pp]*gt5[pp] - 0.5*gt2[pp]*gt4[pp];
		 const double DENDRO_46 = grad_0_gt2[pp];
		 const double DENDRO_47 = 1.0*DENDRO_46;
		 const double DENDRO_48 = grad_2_gt0[pp];
		 const double DENDRO_49 = 0.5*DENDRO_48;
		 const double DENDRO_50 = DENDRO_47 - DENDRO_49;
		 const double DENDRO_51 = grad_0_gt1[pp];
		 const double DENDRO_52 = 1.0*DENDRO_51;
		 const double DENDRO_53 = grad_1_gt0[pp];
		 const double DENDRO_54 = 0.5*DENDRO_53;
		 const double DENDRO_55 = DENDRO_52 - DENDRO_54;
		 const double DENDRO_56 = DENDRO_26*DENDRO_55;
		 const double DENDRO_57 = DENDRO_25*DENDRO_50 + DENDRO_44*DENDRO_45 - DENDRO_56;
		 const double DENDRO_58 = DENDRO_19*DENDRO_36*(DENDRO_43*gt0[pp] + DENDRO_57);
		 const double DENDRO_59 = grad_2_alpha[pp];
		 const double DENDRO_60 = 12*DENDRO_19*DENDRO_59;
		 const double DENDRO_61 = DENDRO_25*DENDRO_40;
		 const double DENDRO_62 = DENDRO_29*DENDRO_39;
		 const double DENDRO_63 = DENDRO_33*DENDRO_38;
		 const double DENDRO_64 = DENDRO_61 - DENDRO_62 - DENDRO_63;
		 const double DENDRO_65 = 0.5*DENDRO_37*DENDRO_64;
		 const double DENDRO_66 = DENDRO_65*gt0[pp];
		 const double DENDRO_67 = DENDRO_25*DENDRO_55;
		 const double DENDRO_68 = 0.5*gt1[pp]*gt4[pp] - 0.5*gt2[pp]*gt3[pp];
		 const double DENDRO_69 = DENDRO_44*DENDRO_68;
		 const double DENDRO_70 = DENDRO_33*DENDRO_50;
		 const double DENDRO_71 = DENDRO_69 + DENDRO_70;
		 const double DENDRO_72 = -DENDRO_67 + DENDRO_71;
		 const double DENDRO_73 = grad_0_alpha[pp];
		 const double DENDRO_74 = 0.5*DENDRO_31*DENDRO_44;
		 const double DENDRO_75 = DENDRO_19*DENDRO_74;
		 const double DENDRO_76 = DENDRO_29*DENDRO_50;
		 const double DENDRO_77 = DENDRO_19*DENDRO_76;
		 const double DENDRO_78 = DENDRO_23*DENDRO_55;
		 const double DENDRO_79 = DENDRO_19*DENDRO_78;
		 const double DENDRO_80 = 1.0/(-DENDRO_11 - DENDRO_13 + DENDRO_15 + DENDRO_17 - DENDRO_9);
		 const double DENDRO_81 = -DENDRO_21 + DENDRO_22;
		 const double DENDRO_82 = DENDRO_29*DENDRO_38;
		 const double DENDRO_83 = DENDRO_31*DENDRO_39;
		 const double DENDRO_84 = DENDRO_82 + DENDRO_83;
		 const double DENDRO_85 = DENDRO_40*DENDRO_81 + DENDRO_84;
		 const double DENDRO_86 = DENDRO_37*(-1.0*DENDRO_39 + 0.5*DENDRO_80*DENDRO_85*gt0[pp]);
		 const double DENDRO_87 = 3*alpha[pp];
		 const double DENDRO_88 = grad_0_Gt0[pp];
		 const double DENDRO_89 = 4*gt1[pp];
		 const double DENDRO_90 = grad_0_Gt1[pp];
		 const double DENDRO_91 = 4*gt2[pp];
		 const double DENDRO_92 = grad_0_Gt2[pp];
		 const double DENDRO_93 = pow(chi[pp], -2);
		 const double DENDRO_94 = pow(DENDRO_39, 2);
		 const double DENDRO_95 = 4.0*DENDRO_19*DENDRO_25;
		 const double DENDRO_96 = 4*DENDRO_19*DENDRO_29;
		 const double DENDRO_97 = 4.0*DENDRO_19*DENDRO_23;
		 const double DENDRO_98 = 2.0*DENDRO_19*DENDRO_33;
		 const double DENDRO_99 = 2.0*DENDRO_19*DENDRO_26;
		 const double DENDRO_100 = 2.0*DENDRO_19*DENDRO_31;
		 const double DENDRO_101 = pow(DENDRO_18, -2);
		 const double DENDRO_102 = 4*DENDRO_101*DENDRO_33;
		 const double DENDRO_103 = grad_0_gt4[pp];
		 const double DENDRO_104 = 0.25*DENDRO_103;
		 const double DENDRO_105 = -DENDRO_104;
		 const double DENDRO_106 = grad_1_gt2[pp];
		 const double DENDRO_107 = 0.25*DENDRO_106;
		 const double DENDRO_108 = grad_2_gt1[pp];
		 const double DENDRO_109 = 0.75*DENDRO_108;
		 const double DENDRO_110 = grad_0_gt5[pp];
		 const double DENDRO_111 = DENDRO_103 - DENDRO_106 + DENDRO_108;
		 const double DENDRO_112 = DENDRO_111*DENDRO_26;
		 const double DENDRO_113 = DENDRO_110*DENDRO_25 - DENDRO_112 + DENDRO_23*DENDRO_48;
		 const double DENDRO_114 = 4*DENDRO_101;
		 const double DENDRO_115 = 2.0*DENDRO_101*DENDRO_23;
		 const double DENDRO_116 = DENDRO_23*DENDRO_53;
		 const double DENDRO_117 = grad_0_gt3[pp];
		 const double DENDRO_118 = DENDRO_117*DENDRO_26;
		 const double DENDRO_119 = DENDRO_103 + DENDRO_106 - DENDRO_108;
		 const double DENDRO_120 = DENDRO_119*DENDRO_25;
		 const double DENDRO_121 = DENDRO_116 - DENDRO_118 + DENDRO_120;
		 const double DENDRO_122 = DENDRO_117*DENDRO_57;
		 const double DENDRO_123 = 4*DENDRO_101*DENDRO_25;
		 const double DENDRO_124 = 0.25*DENDRO_117;
		 const double DENDRO_125 = DENDRO_113*DENDRO_124;
		 const double DENDRO_126 = -DENDRO_103 + DENDRO_106 + DENDRO_108;
		 const double DENDRO_127 = DENDRO_121*DENDRO_126;
		 const double DENDRO_128 = 2.0*DENDRO_101*DENDRO_29;
		 const double DENDRO_129 = 4*DENDRO_101*DENDRO_29;
		 const double DENDRO_130 = 0.25*DENDRO_53;
		 const double DENDRO_131 = -DENDRO_130;
		 const double DENDRO_132 = DENDRO_131 + 0.5*DENDRO_51;
		 const double DENDRO_133 = DENDRO_113*DENDRO_132;
		 const double DENDRO_134 = 4*DENDRO_101*DENDRO_23;
		 const double DENDRO_135 = DENDRO_121*DENDRO_132;
		 const double DENDRO_136 = 0.5*DENDRO_117;
		 const double DENDRO_137 = grad_1_gt1[pp];
		 const double DENDRO_138 = 1.0*DENDRO_137;
		 const double DENDRO_139 = -DENDRO_138;
		 const double DENDRO_140 = DENDRO_136 + DENDRO_139;
		 const double DENDRO_141 = DENDRO_100*grad2_0_0_gt0[pp] - DENDRO_102*DENDRO_113*(DENDRO_105 + DENDRO_107 + DENDRO_109) - DENDRO_114*DENDRO_31*DENDRO_57*(DENDRO_52 + DENDRO_54) + DENDRO_115*(DENDRO_121*DENDRO_53 + DENDRO_122) + DENDRO_123*(DENDRO_125 + 0.5*DENDRO_127) - DENDRO_128*(DENDRO_111*DENDRO_57 + DENDRO_113*DENDRO_53) - DENDRO_129*(DENDRO_126*DENDRO_57 + DENDRO_133) + DENDRO_134*(DENDRO_135 - 2*DENDRO_140*DENDRO_57) + 4*DENDRO_88*gt0[pp] + DENDRO_89*DENDRO_90 + DENDRO_91*DENDRO_92 - DENDRO_93*DENDRO_94 - DENDRO_95*grad2_1_2_gt0[pp] + DENDRO_96*grad2_0_2_gt0[pp] - DENDRO_97*grad2_0_1_gt0[pp] + DENDRO_98*grad2_2_2_gt0[pp] + DENDRO_99*grad2_1_1_gt0[pp];
		 const double DENDRO_142 = 3.0*DENDRO_101*DENDRO_33;
		 const double DENDRO_143 = DENDRO_111*DENDRO_23;
		 const double DENDRO_144 = DENDRO_110*DENDRO_29;
		 const double DENDRO_145 = DENDRO_31*DENDRO_48;
		 const double DENDRO_146 = DENDRO_144 + DENDRO_145;
		 const double DENDRO_147 = -DENDRO_143 + DENDRO_146;
		 const double DENDRO_148 = DENDRO_147*DENDRO_48;
		 const double DENDRO_149 = 3.0*DENDRO_101*DENDRO_26;
		 const double DENDRO_150 = DENDRO_117*DENDRO_23;
		 const double DENDRO_151 = DENDRO_31*DENDRO_53;
		 const double DENDRO_152 = DENDRO_119*DENDRO_29;
		 const double DENDRO_153 = DENDRO_151 + DENDRO_152;
		 const double DENDRO_154 = -DENDRO_150 + DENDRO_153;
		 const double DENDRO_155 = DENDRO_154*DENDRO_53;
		 const double DENDRO_156 = 4*DENDRO_101*DENDRO_121*DENDRO_26;
		 const double DENDRO_157 = 6.0*DENDRO_101*DENDRO_44;
		 const double DENDRO_158 = DENDRO_74 + DENDRO_76;
		 const double DENDRO_159 = DENDRO_158 - DENDRO_78;
		 const double DENDRO_160 = 0.25*DENDRO_110;
		 const double DENDRO_161 = grad_2_gt2[pp];
		 const double DENDRO_162 = 1.0*DENDRO_161;
		 const double DENDRO_163 = -DENDRO_162;
		 const double DENDRO_164 = DENDRO_29*DENDRO_48;
		 const double DENDRO_165 = DENDRO_110*DENDRO_33;
		 const double DENDRO_166 = DENDRO_111*DENDRO_25;
		 const double DENDRO_167 = -DENDRO_164 - DENDRO_165 + DENDRO_166;
		 const double DENDRO_168 = 4*DENDRO_101*DENDRO_167*DENDRO_33;
		 const double DENDRO_169 = DENDRO_117*DENDRO_25;
		 const double DENDRO_170 = DENDRO_29*DENDRO_53;
		 const double DENDRO_171 = DENDRO_119*DENDRO_33;
		 const double DENDRO_172 = DENDRO_170 + DENDRO_171;
		 const double DENDRO_173 = -DENDRO_169 + DENDRO_172;
		 const double DENDRO_174 = 0.75*DENDRO_106;
		 const double DENDRO_175 = 0.25*DENDRO_108;
		 const double DENDRO_176 = 4*DENDRO_101*DENDRO_26*(DENDRO_105 + DENDRO_174 + DENDRO_175);
		 const double DENDRO_177 = 4*DENDRO_101*DENDRO_31;
		 const double DENDRO_178 = DENDRO_47 + DENDRO_49;
		 const double DENDRO_179 = 0.25*DENDRO_48;
		 const double DENDRO_180 = DENDRO_154*DENDRO_179;
		 const double DENDRO_181 = DENDRO_130*DENDRO_147;
		 const double DENDRO_182 = DENDRO_164 + DENDRO_165;
		 const double DENDRO_183 = -DENDRO_166 + DENDRO_182;
		 const double DENDRO_184 = DENDRO_110*DENDRO_72;
		 const double DENDRO_185 = DENDRO_147*DENDRO_44;
		 const double DENDRO_186 = DENDRO_159*DENDRO_48;
		 const double DENDRO_187 = DENDRO_154*DENDRO_44;
		 const double DENDRO_188 = DENDRO_159*DENDRO_53;
		 const double DENDRO_189 = 0.25*DENDRO_185;
		 const double DENDRO_190 = 0.25*DENDRO_187;
		 const double DENDRO_191 = DENDRO_160*DENDRO_173;
		 const double DENDRO_192 = DENDRO_126*DENDRO_183;
		 const double DENDRO_193 = DENDRO_119*DENDRO_72;
		 const double DENDRO_194 = DENDRO_113*DENDRO_140;
		 const double DENDRO_195 = DENDRO_111*DENDRO_121;
		 const double DENDRO_196 = 0.25*DENDRO_195;
		 const double DENDRO_197 = 0.5*DENDRO_110;
		 const double DENDRO_198 = DENDRO_163 + DENDRO_197;
		 const double DENDRO_199 = DENDRO_169 - DENDRO_170 - DENDRO_171;
		 const double DENDRO_200 = DENDRO_198*DENDRO_199;
		 const double DENDRO_201 = DENDRO_119*DENDRO_167;
		 const double DENDRO_202 = 0.25*DENDRO_201;
		 const double DENDRO_203 = -DENDRO_202;
		 const double DENDRO_204 = -DENDRO_179;
		 const double DENDRO_205 = DENDRO_204 + 0.5*DENDRO_46;
		 const double DENDRO_206 = DENDRO_110 - 2.0*DENDRO_161;
		 const double DENDRO_207 = 2*DENDRO_37;
		 const double DENDRO_208 = grad2_0_0_chi[pp];
		 const double DENDRO_209 = -DENDRO_208;
		 const double DENDRO_210 = DENDRO_19*DENDRO_38;
		 const double DENDRO_211 = DENDRO_67 - DENDRO_69 - DENDRO_70;
		 const double DENDRO_212 = DENDRO_19*DENDRO_40;
		 const double DENDRO_213 = DENDRO_19*DENDRO_39;
		 const double DENDRO_214 = -DENDRO_74 - DENDRO_76 + DENDRO_78;
		 const double DENDRO_215 = DENDRO_113*DENDRO_29;
		 const double DENDRO_216 = grad_1_gt5[pp];
		 const double DENDRO_217 = DENDRO_216*DENDRO_25;
		 const double DENDRO_218 = grad_2_gt3[pp];
		 const double DENDRO_219 = DENDRO_218*DENDRO_26;
		 const double DENDRO_220 = DENDRO_126*DENDRO_23;
		 const double DENDRO_221 = DENDRO_217 - DENDRO_219 + DENDRO_220;
		 const double DENDRO_222 = DENDRO_221*DENDRO_25;
		 const double DENDRO_223 = DENDRO_121*DENDRO_23;
		 const double DENDRO_224 = grad_2_gt5[pp];
		 const double DENDRO_225 = 0.5*gt0[pp]*gt4[pp] - 0.5*gt1[pp]*gt2[pp];
		 const double DENDRO_226 = 0.5*DENDRO_216;
		 const double DENDRO_227 = grad_2_gt4[pp];
		 const double DENDRO_228 = 1.0*DENDRO_227;
		 const double DENDRO_229 = -DENDRO_228;
		 const double DENDRO_230 = DENDRO_226 + DENDRO_229;
		 const double DENDRO_231 = -DENDRO_198*DENDRO_23 + DENDRO_224*DENDRO_225 + DENDRO_230*DENDRO_26;
		 const double DENDRO_232 = DENDRO_231*DENDRO_33;
		 const double DENDRO_233 = grad_1_gt3[pp];
		 const double DENDRO_234 = 0.5*DENDRO_233*DENDRO_26;
		 const double DENDRO_235 = grad_1_gt4[pp];
		 const double DENDRO_236 = 1.0*DENDRO_235;
		 const double DENDRO_237 = 0.5*DENDRO_218;
		 const double DENDRO_238 = DENDRO_236 - DENDRO_237;
		 const double DENDRO_239 = DENDRO_238*DENDRO_25;
		 const double DENDRO_240 = DENDRO_140*DENDRO_23;
		 const double DENDRO_241 = -DENDRO_234 + DENDRO_239 - DENDRO_240;
		 const double DENDRO_242 = DENDRO_241*DENDRO_26;
		 const double DENDRO_243 = DENDRO_31*DENDRO_57;
		 const double DENDRO_244 = 2.0*DENDRO_101*(DENDRO_215 - 1.0*DENDRO_222 - 1.0*DENDRO_223 + DENDRO_232 + DENDRO_242 + DENDRO_243);
		 const double DENDRO_245 = DENDRO_167*DENDRO_29;
		 const double DENDRO_246 = DENDRO_218*DENDRO_25;
		 const double DENDRO_247 = DENDRO_216*DENDRO_33;
		 const double DENDRO_248 = DENDRO_126*DENDRO_29;
		 const double DENDRO_249 = DENDRO_246 - DENDRO_247 - DENDRO_248;
		 const double DENDRO_250 = DENDRO_249*DENDRO_25;
		 const double DENDRO_251 = DENDRO_199*DENDRO_23;
		 const double DENDRO_252 = 0.5*DENDRO_224*DENDRO_33;
		 const double DENDRO_253 = DENDRO_198*DENDRO_29;
		 const double DENDRO_254 = DENDRO_230*DENDRO_25;
		 const double DENDRO_255 = -DENDRO_252 + DENDRO_253 - DENDRO_254;
		 const double DENDRO_256 = DENDRO_255*DENDRO_33;
		 const double DENDRO_257 = DENDRO_238*DENDRO_33;
		 const double DENDRO_258 = DENDRO_140*DENDRO_29 + DENDRO_225*DENDRO_233 - DENDRO_257;
		 const double DENDRO_259 = DENDRO_258*DENDRO_26;
		 const double DENDRO_260 = DENDRO_211*DENDRO_31;
		 const double DENDRO_261 = 2.0*DENDRO_101*(DENDRO_245 - 1.0*DENDRO_250 - 1.0*DENDRO_251 + DENDRO_256 + DENDRO_259 + DENDRO_260);
		 const double DENDRO_262 = DENDRO_143 - DENDRO_144 - DENDRO_145;
		 const double DENDRO_263 = DENDRO_262*DENDRO_29;
		 const double DENDRO_264 = DENDRO_218*DENDRO_23;
		 const double DENDRO_265 = DENDRO_216*DENDRO_29;
		 const double DENDRO_266 = DENDRO_126*DENDRO_31;
		 const double DENDRO_267 = DENDRO_264 - DENDRO_265 - DENDRO_266;
		 const double DENDRO_268 = DENDRO_25*DENDRO_267;
		 const double DENDRO_269 = DENDRO_150 - DENDRO_151 - DENDRO_152;
		 const double DENDRO_270 = DENDRO_23*DENDRO_269;
		 const double DENDRO_271 = DENDRO_224*DENDRO_68;
		 const double DENDRO_272 = DENDRO_23*DENDRO_230;
		 const double DENDRO_273 = DENDRO_198*DENDRO_31;
		 const double DENDRO_274 = -DENDRO_271 - DENDRO_272 + DENDRO_273;
		 const double DENDRO_275 = DENDRO_274*DENDRO_33;
		 const double DENDRO_276 = DENDRO_238*DENDRO_29;
		 const double DENDRO_277 = DENDRO_140*DENDRO_31 + DENDRO_233*DENDRO_45 - DENDRO_276;
		 const double DENDRO_278 = DENDRO_26*DENDRO_277;
		 const double DENDRO_279 = DENDRO_214*DENDRO_31;
		 const double DENDRO_280 = 2.0*DENDRO_101*(DENDRO_263 - 1.0*DENDRO_268 - 1.0*DENDRO_270 + DENDRO_275 + DENDRO_278 + DENDRO_279);
		 const double DENDRO_281 = grad2_2_2_chi[pp];
		 const double DENDRO_282 = 3*DENDRO_37;
		 const double DENDRO_283 = pow(DENDRO_38, 2);
		 const double DENDRO_284 = DENDRO_33*(2*DENDRO_281 - DENDRO_282*DENDRO_283);
		 const double DENDRO_285 = grad2_1_1_chi[pp];
		 const double DENDRO_286 = pow(DENDRO_40, 2);
		 const double DENDRO_287 = DENDRO_26*(-DENDRO_282*DENDRO_286 + 2*DENDRO_285);
		 const double DENDRO_288 = DENDRO_31*(2*DENDRO_208 - DENDRO_282*DENDRO_94);
		 const double DENDRO_289 = grad2_1_2_chi[pp];
		 const double DENDRO_290 = DENDRO_38*DENDRO_40;
		 const double DENDRO_291 = 2*DENDRO_25*(-DENDRO_282*DENDRO_290 + 2*DENDRO_289);
		 const double DENDRO_292 = grad2_0_2_chi[pp];
		 const double DENDRO_293 = 3*DENDRO_37*DENDRO_39;
		 const double DENDRO_294 = 2*DENDRO_29*(2*DENDRO_292 - DENDRO_293*DENDRO_38);
		 const double DENDRO_295 = grad2_0_1_chi[pp];
		 const double DENDRO_296 = 2*DENDRO_23*(-DENDRO_293*DENDRO_40 + 2*DENDRO_295);
		 const double DENDRO_297 = 2*DENDRO_19;
		 const double DENDRO_298 = -1.0*DENDRO_215 + DENDRO_222 + DENDRO_223 - DENDRO_232 - DENDRO_242 - DENDRO_243;
		 const double DENDRO_299 = DENDRO_297*DENDRO_298*DENDRO_40;
		 const double DENDRO_300 = -1.0*DENDRO_245 + DENDRO_250 + DENDRO_251 - DENDRO_256 - DENDRO_259 - DENDRO_260;
		 const double DENDRO_301 = DENDRO_297*DENDRO_300*DENDRO_38;
		 const double DENDRO_302 = -1.0*DENDRO_263 + DENDRO_268 + DENDRO_270 - DENDRO_275 - DENDRO_278 - DENDRO_279;
		 const double DENDRO_303 = DENDRO_297*DENDRO_302*DENDRO_39;
		 const double DENDRO_304 = DENDRO_19*DENDRO_37*(DENDRO_284 + DENDRO_287 + DENDRO_288 - DENDRO_291 + DENDRO_294 - DENDRO_296 + DENDRO_299 + DENDRO_301 + DENDRO_303);
		 const double DENDRO_305 = grad2_2_2_alpha[pp];
		 const double DENDRO_306 = DENDRO_19*DENDRO_36*(DENDRO_231 + DENDRO_43*gt5[pp]);
		 const double DENDRO_307 = 4*DENDRO_19*DENDRO_73;
		 const double DENDRO_308 = 0.5*gt5[pp];
		 const double DENDRO_309 = DENDRO_23*DENDRO_40;
		 const double DENDRO_310 = DENDRO_309 - DENDRO_82 - DENDRO_83;
		 const double DENDRO_311 = DENDRO_308*DENDRO_310*DENDRO_37;
		 const double DENDRO_312 = DENDRO_19*DENDRO_252;
		 const double DENDRO_313 = DENDRO_19*DENDRO_253;
		 const double DENDRO_314 = DENDRO_19*DENDRO_254;
		 const double DENDRO_315 = DENDRO_16 - DENDRO_24;
		 const double DENDRO_316 = DENDRO_62 + DENDRO_63;
		 const double DENDRO_317 = DENDRO_315*DENDRO_40 + DENDRO_316;
		 const double DENDRO_318 = DENDRO_37*(DENDRO_308*DENDRO_317*DENDRO_80 - 1.0*DENDRO_38);
		 const double DENDRO_319 = grad_2_Gt0[pp];
		 const double DENDRO_320 = 4*gt4[pp];
		 const double DENDRO_321 = grad_2_Gt1[pp];
		 const double DENDRO_322 = grad_2_Gt2[pp];
		 const double DENDRO_323 = 4*DENDRO_101*DENDRO_26;
		 const double DENDRO_324 = 0.25*DENDRO_218;
		 const double DENDRO_325 = -DENDRO_324;
		 const double DENDRO_326 = 0.75*DENDRO_103;
		 const double DENDRO_327 = -DENDRO_175;
		 const double DENDRO_328 = 2.0*DENDRO_101*DENDRO_25;
		 const double DENDRO_329 = DENDRO_218*DENDRO_231;
		 const double DENDRO_330 = DENDRO_113*DENDRO_324;
		 const double DENDRO_331 = DENDRO_119*DENDRO_221;
		 const double DENDRO_332 = DENDRO_113*DENDRO_238;
		 const double DENDRO_333 = DENDRO_111*DENDRO_221;
		 const double DENDRO_334 = 0.25*DENDRO_333;
		 const double DENDRO_335 = 0.25*DENDRO_216;
		 const double DENDRO_336 = -0.5*DENDRO_227 + DENDRO_335;
		 const double DENDRO_337 = -DENDRO_221*DENDRO_336;
		 const double DENDRO_338 = DENDRO_100*grad2_0_0_gt5[pp] - DENDRO_113*DENDRO_177*(DENDRO_107 + DENDRO_326 + DENDRO_327) + DENDRO_123*(2*DENDRO_231*DENDRO_238 + DENDRO_337) - DENDRO_128*(DENDRO_111*DENDRO_231 + DENDRO_113*DENDRO_216) + DENDRO_134*(DENDRO_330 + 0.5*DENDRO_331) + DENDRO_134*(DENDRO_332 + DENDRO_334) - DENDRO_221*DENDRO_323*(DENDRO_236 + DENDRO_325) - DENDRO_283*DENDRO_93 + DENDRO_319*DENDRO_91 + DENDRO_320*DENDRO_321 + 4*DENDRO_322*gt5[pp] + DENDRO_328*(DENDRO_216*DENDRO_221 + DENDRO_329) - DENDRO_95*grad2_1_2_gt5[pp] + DENDRO_96*grad2_0_2_gt5[pp] - DENDRO_97*grad2_0_1_gt5[pp] + DENDRO_98*grad2_2_2_gt5[pp] + DENDRO_99*grad2_1_1_gt5[pp];
		 const double DENDRO_339 = DENDRO_216*DENDRO_249;
		 const double DENDRO_340 = 3.0*DENDRO_101*DENDRO_31;
		 const double DENDRO_341 = DENDRO_110*DENDRO_167;
		 const double DENDRO_342 = 6.0*DENDRO_101*DENDRO_224;
		 const double DENDRO_343 = 4*DENDRO_101*DENDRO_31*(DENDRO_204 + DENDRO_47);
		 const double DENDRO_344 = 4*DENDRO_101*DENDRO_26*(DENDRO_104 + DENDRO_174 + DENDRO_327);
		 const double DENDRO_345 = 4*DENDRO_101*DENDRO_274*DENDRO_33;
		 const double DENDRO_346 = 4*DENDRO_101*DENDRO_231*DENDRO_33;
		 const double DENDRO_347 = DENDRO_167*DENDRO_335;
		 const double DENDRO_348 = DENDRO_160*DENDRO_249;
		 const double DENDRO_349 = DENDRO_224*DENDRO_249;
		 const double DENDRO_350 = DENDRO_216*DENDRO_255;
		 const double DENDRO_351 = DENDRO_167*DENDRO_224;
		 const double DENDRO_352 = DENDRO_110*DENDRO_255;
		 const double DENDRO_353 = DENDRO_274*DENDRO_48;
		 const double DENDRO_354 = 0.25*DENDRO_224;
		 const double DENDRO_355 = DENDRO_249*DENDRO_354;
		 const double DENDRO_356 = DENDRO_167*DENDRO_354;
		 const double DENDRO_357 = DENDRO_179*DENDRO_267;
		 const double DENDRO_358 = DENDRO_119*DENDRO_262;
		 const double DENDRO_359 = DENDRO_126*DENDRO_274;
		 const double DENDRO_360 = DENDRO_126*DENDRO_262;
		 const double DENDRO_361 = 0.25*DENDRO_360;
		 const double DENDRO_362 = DENDRO_113*DENDRO_336;
		 const double DENDRO_363 = -DENDRO_362;
		 const double DENDRO_364 = DENDRO_119*DENDRO_231;
		 const double DENDRO_365 = DENDRO_160 - 0.5*DENDRO_161;
		 const double DENDRO_366 = DENDRO_267*DENDRO_365;
		 const double DENDRO_367 = -DENDRO_366;
		 const double DENDRO_368 = DENDRO_119*DENDRO_274;
		 const double DENDRO_369 = -DENDRO_262*DENDRO_365;
		 const double DENDRO_370 = 2.0*DENDRO_46 - 1.0*DENDRO_48;
		 const double DENDRO_371 = -DENDRO_281;
		 const double DENDRO_372 = DENDRO_38*DENDRO_80;
		 const double DENDRO_373 = -DENDRO_226;
		 const double DENDRO_374 = DENDRO_228 + DENDRO_373;
		 const double DENDRO_375 = -DENDRO_197;
		 const double DENDRO_376 = DENDRO_162 + DENDRO_375;
		 const double DENDRO_377 = DENDRO_40*DENDRO_80;
		 const double DENDRO_378 = -0.5*gt0[pp]*gt4[pp] + 0.5*gt1[pp]*gt2[pp];
		 const double DENDRO_379 = DENDRO_39*DENDRO_80;
		 const double DENDRO_380 = 2.0*DENDRO_101*DENDRO_298;
		 const double DENDRO_381 = 2.0*DENDRO_101*DENDRO_300;
		 const double DENDRO_382 = 2.0*DENDRO_101*DENDRO_302;
		 const double DENDRO_383 = DENDRO_19*DENDRO_37*(-DENDRO_284 - DENDRO_287 - DENDRO_288 + DENDRO_291 - DENDRO_294 + DENDRO_296 - DENDRO_299 - DENDRO_301 - DENDRO_303);
		 const double DENDRO_384 = grad2_1_1_alpha[pp];
		 const double DENDRO_385 = 4*DENDRO_19*DENDRO_59;
		 const double DENDRO_386 = 0.5*DENDRO_37*gt3[pp];
		 const double DENDRO_387 = -1.0*DENDRO_40;
		 const double DENDRO_388 = 0.5*gt3[pp];
		 const double DENDRO_389 = DENDRO_315*DENDRO_38 + DENDRO_39*DENDRO_81 + DENDRO_41;
		 const double DENDRO_390 = -DENDRO_19*DENDRO_234 + DENDRO_19*DENDRO_239 - DENDRO_19*DENDRO_240;
		 const double DENDRO_391 = grad_1_Gt0[pp];
		 const double DENDRO_392 = grad_1_Gt1[pp];
		 const double DENDRO_393 = grad_1_Gt2[pp];
		 const double DENDRO_394 = DENDRO_218*DENDRO_221;
		 const double DENDRO_395 = DENDRO_117*DENDRO_121;
		 const double DENDRO_396 = DENDRO_121*DENDRO_324;
		 const double DENDRO_397 = DENDRO_124*DENDRO_221;
		 const double DENDRO_398 = DENDRO_100*grad2_0_0_gt3[pp] - DENDRO_114*DENDRO_258*DENDRO_26*(DENDRO_236 + DENDRO_237) - DENDRO_129*(DENDRO_121*DENDRO_237 + DENDRO_397) - DENDRO_129*(DENDRO_136*DENDRO_221 + DENDRO_396) - DENDRO_142*DENDRO_394 - DENDRO_286*DENDRO_93 + DENDRO_320*DENDRO_393 - DENDRO_340*DENDRO_395 + DENDRO_391*DENDRO_89 + 4*DENDRO_392*gt3[pp] - DENDRO_95*grad2_1_2_gt3[pp] + DENDRO_96*grad2_0_2_gt3[pp] - DENDRO_97*grad2_0_1_gt3[pp] + DENDRO_98*grad2_2_2_gt3[pp] + DENDRO_99*grad2_1_1_gt3[pp];
		 const double DENDRO_399 = 6.0*DENDRO_233;
		 const double DENDRO_400 = 4*DENDRO_101*DENDRO_249*DENDRO_33;
		 const double DENDRO_401 = 4*DENDRO_101*DENDRO_31*(DENDRO_131 + DENDRO_52);
		 const double DENDRO_402 = -DENDRO_107;
		 const double DENDRO_403 = 4*DENDRO_101*DENDRO_33*(DENDRO_104 + DENDRO_109 + DENDRO_402);
		 const double DENDRO_404 = 4*DENDRO_101*DENDRO_31*(DENDRO_175 + DENDRO_326 + DENDRO_402);
		 const double DENDRO_405 = 4*DENDRO_101*DENDRO_26*DENDRO_277;
		 const double DENDRO_406 = DENDRO_221*DENDRO_233;
		 const double DENDRO_407 = DENDRO_218*DENDRO_241;
		 const double DENDRO_408 = DENDRO_121*DENDRO_233;
		 const double DENDRO_409 = DENDRO_117*DENDRO_241;
		 const double DENDRO_410 = DENDRO_216*DENDRO_258;
		 const double DENDRO_411 = DENDRO_277*DENDRO_53;
		 const double DENDRO_412 = 0.25*DENDRO_406;
		 const double DENDRO_413 = 0.25*DENDRO_408;
		 const double DENDRO_414 = DENDRO_199*DENDRO_335;
		 const double DENDRO_415 = 0.5*DENDRO_103;
		 const double DENDRO_416 = 0.5*DENDRO_108;
		 const double DENDRO_417 = -0.5*DENDRO_106 + DENDRO_415 + DENDRO_416;
		 const double DENDRO_418 = DENDRO_130*DENDRO_267;
		 const double DENDRO_419 = DENDRO_126*DENDRO_277;
		 const double DENDRO_420 = DENDRO_119*DENDRO_258;
		 const double DENDRO_421 = DENDRO_126*DENDRO_269;
		 const double DENDRO_422 = 0.25*DENDRO_421;
		 const double DENDRO_423 = DENDRO_199*DENDRO_230;
		 const double DENDRO_424 = DENDRO_119*DENDRO_249;
		 const double DENDRO_425 = 0.25*DENDRO_424;
		 const double DENDRO_426 = DENDRO_124 - 0.5*DENDRO_137;
		 const double DENDRO_427 = DENDRO_267*DENDRO_426;
		 const double DENDRO_428 = -DENDRO_427;
		 const double DENDRO_429 = DENDRO_111*DENDRO_277;
		 const double DENDRO_430 = 0.5*DENDRO_235 + DENDRO_325;
		 const double DENDRO_431 = DENDRO_249*DENDRO_430;
		 const double DENDRO_432 = 2*DENDRO_230*DENDRO_258;
		 const double DENDRO_433 = -DENDRO_269*DENDRO_426;
		 const double DENDRO_434 = 2*DENDRO_277*DENDRO_55;
		 const double DENDRO_435 = DENDRO_199*DENDRO_430;
		 const double DENDRO_436 = DENDRO_111*DENDRO_258;
		 const double DENDRO_437 = -DENDRO_285;
		 const double DENDRO_438 = -DENDRO_136;
		 const double DENDRO_439 = DENDRO_138 + DENDRO_438;
		 const double DENDRO_440 = -0.5*gt1[pp]*gt5[pp] + 0.5*gt2[pp]*gt4[pp];
		 const double DENDRO_441 = DENDRO_262*DENDRO_48;
		 const double DENDRO_442 = DENDRO_269*DENDRO_53;
		 const double DENDRO_443 = DENDRO_179*DENDRO_269;
		 const double DENDRO_444 = DENDRO_130*DENDRO_262;
		 const double DENDRO_445 = DENDRO_110*DENDRO_211;
		 const double DENDRO_446 = DENDRO_262*DENDRO_44;
		 const double DENDRO_447 = DENDRO_214*DENDRO_48;
		 const double DENDRO_448 = DENDRO_269*DENDRO_44;
		 const double DENDRO_449 = DENDRO_214*DENDRO_53;
		 const double DENDRO_450 = 0.25*DENDRO_446;
		 const double DENDRO_451 = 0.25*DENDRO_448;
		 const double DENDRO_452 = DENDRO_160*DENDRO_199;
		 const double DENDRO_453 = DENDRO_126*DENDRO_167;
		 const double DENDRO_454 = DENDRO_119*DENDRO_211;
		 const double DENDRO_455 = DENDRO_167*DENDRO_205;
		 const double DENDRO_456 = DENDRO_199*DENDRO_205;
		 const double DENDRO_457 = grad2_0_2_alpha[pp];
		 const double DENDRO_458 = DENDRO_19*DENDRO_36*(DENDRO_113 + DENDRO_37*DENDRO_42*gt2[pp]);
		 const double DENDRO_459 = 2.0*DENDRO_59;
		 const double DENDRO_460 = DENDRO_164*DENDRO_19;
		 const double DENDRO_461 = DENDRO_165*DENDRO_19;
		 const double DENDRO_462 = DENDRO_166*DENDRO_19;
		 const double DENDRO_463 = -DENDRO_39;
		 const double DENDRO_464 = DENDRO_80*gt2[pp];
		 const double DENDRO_465 = DENDRO_37*(DENDRO_317*DENDRO_464 + DENDRO_463);
		 const double DENDRO_466 = 2.0*DENDRO_73;
		 const double DENDRO_467 = DENDRO_144*DENDRO_19;
		 const double DENDRO_468 = DENDRO_145*DENDRO_19;
		 const double DENDRO_469 = DENDRO_143*DENDRO_19;
		 const double DENDRO_470 = -DENDRO_38;
		 const double DENDRO_471 = DENDRO_37*(DENDRO_464*DENDRO_85 + DENDRO_470);
		 const double DENDRO_472 = -4*DENDRO_457 + 2.0*DENDRO_458 + DENDRO_459*(-DENDRO_460 - DENDRO_461 + DENDRO_462 + DENDRO_465) + DENDRO_466*(-DENDRO_467 - DENDRO_468 + DENDRO_469 + DENDRO_471);
		 const double DENDRO_473 = -DENDRO_292;
		 const double DENDRO_474 = 0.5*DENDRO_38*DENDRO_80;
		 const double DENDRO_475 = 0.5*DENDRO_40*DENDRO_80;
		 const double DENDRO_476 = 0.5*DENDRO_39*DENDRO_80;
		 const double DENDRO_477 = DENDRO_106*DENDRO_380 + DENDRO_161*DENDRO_381 - DENDRO_207*(DENDRO_473 + DENDRO_474*(DENDRO_111*DENDRO_315 + DENDRO_182) + DENDRO_475*(DENDRO_110*DENDRO_315 + DENDRO_112 + DENDRO_48*DENDRO_81) + DENDRO_476*(DENDRO_111*DENDRO_81 + DENDRO_146)) + DENDRO_382*DENDRO_46 + DENDRO_383*gt2[pp];
		 const double DENDRO_478 = 2.0*gt0[pp];
		 const double DENDRO_479 = DENDRO_319*DENDRO_478;
		 const double DENDRO_480 = 2.0*gt1[pp];
		 const double DENDRO_481 = DENDRO_321*DENDRO_480;
		 const double DENDRO_482 = 2.0*gt2[pp];
		 const double DENDRO_483 = DENDRO_482*DENDRO_88;
		 const double DENDRO_484 = DENDRO_322*DENDRO_482;
		 const double DENDRO_485 = 2.0*gt4[pp];
		 const double DENDRO_486 = DENDRO_485*DENDRO_90;
		 const double DENDRO_487 = 2.0*gt5[pp];
		 const double DENDRO_488 = DENDRO_487*DENDRO_92;
		 const double DENDRO_489 = DENDRO_39*DENDRO_93;
		 const double DENDRO_490 = -DENDRO_38*DENDRO_489;
		 const double DENDRO_491 = -DENDRO_95*grad2_1_2_gt2[pp];
		 const double DENDRO_492 = DENDRO_96*grad2_0_2_gt2[pp];
		 const double DENDRO_493 = -DENDRO_97*grad2_0_1_gt2[pp];
		 const double DENDRO_494 = DENDRO_98*grad2_2_2_gt2[pp];
		 const double DENDRO_495 = DENDRO_99*grad2_1_1_gt2[pp];
		 const double DENDRO_496 = DENDRO_100*grad2_0_0_gt2[pp];
		 const double DENDRO_497 = DENDRO_160*DENDRO_262;
		 const double DENDRO_498 = DENDRO_119*DENDRO_269;
		 const double DENDRO_499 = 0.25*DENDRO_498;
		 const double DENDRO_500 = DENDRO_214*DENDRO_50;
		 const double DENDRO_501 = DENDRO_101*DENDRO_23;
		 const double DENDRO_502 = DENDRO_119*DENDRO_121;
		 const double DENDRO_503 = DENDRO_113*DENDRO_117;
		 const double DENDRO_504 = DENDRO_221*DENDRO_53 + DENDRO_503;
		 const double DENDRO_505 = DENDRO_110*DENDRO_199;
		 const double DENDRO_506 = DENDRO_249*DENDRO_48 + DENDRO_505;
		 const double DENDRO_507 = DENDRO_274*DENDRO_54;
		 const double DENDRO_508 = DENDRO_160*DENDRO_269 + DENDRO_507;
		 const double DENDRO_509 = 0.25*DENDRO_44;
		 const double DENDRO_510 = DENDRO_267*DENDRO_509;
		 const double DENDRO_511 = DENDRO_205*DENDRO_269;
		 const double DENDRO_512 = DENDRO_444 + DENDRO_511;
		 const double DENDRO_513 = DENDRO_126*DENDRO_221;
		 const double DENDRO_514 = 0.25*DENDRO_513;
		 const double DENDRO_515 = DENDRO_136*DENDRO_231;
		 const double DENDRO_516 = DENDRO_121*DENDRO_335 + DENDRO_515;
		 const double DENDRO_517 = -DENDRO_221*DENDRO_426;
		 const double DENDRO_518 = DENDRO_121*DENDRO_430;
		 const double DENDRO_519 = DENDRO_397 + DENDRO_518;
		 const double DENDRO_520 = 0.5*DENDRO_44;
		 const double DENDRO_521 = DENDRO_274*DENDRO_520;
		 const double DENDRO_522 = DENDRO_179*DENDRO_262 + DENDRO_521;
		 const double DENDRO_523 = DENDRO_205*DENDRO_262;
		 const double DENDRO_524 = 0.5*DENDRO_106;
		 const double DENDRO_525 = -0.5*DENDRO_103 + DENDRO_416 + DENDRO_524;
		 const double DENDRO_526 = DENDRO_255*DENDRO_525 + DENDRO_347;
		 const double DENDRO_527 = 0.25*DENDRO_358 + DENDRO_507;
		 const double DENDRO_528 = 1.0*DENDRO_101*DENDRO_26;
		 const double DENDRO_529 = DENDRO_199*DENDRO_216;
		 const double DENDRO_530 = DENDRO_126*DENDRO_249;
		 const double DENDRO_531 = -0.5*DENDRO_108 + DENDRO_415 + DENDRO_524;
		 const double DENDRO_532 = DENDRO_214*DENDRO_531 + DENDRO_444;
		 const double DENDRO_533 = DENDRO_167*DENDRO_179;
		 const double DENDRO_534 = DENDRO_198*DENDRO_255;
		 const double DENDRO_535 = -DENDRO_534;
		 const double DENDRO_536 = 0.25*DENDRO_110*DENDRO_25 - 0.25*DENDRO_111*DENDRO_26 + 0.25*DENDRO_23*DENDRO_48;
		 const double DENDRO_537 = DENDRO_111*DENDRO_536;
		 const double DENDRO_538 = DENDRO_119*DENDRO_536 + DENDRO_231*DENDRO_54;
		 const double DENDRO_539 = DENDRO_113*DENDRO_130 + DENDRO_531*DENDRO_57;
		 const double DENDRO_540 = DENDRO_249*DENDRO_365;
		 const double DENDRO_541 = -DENDRO_540;
		 const double DENDRO_542 = DENDRO_199*DENDRO_354;
		 const double DENDRO_543 = DENDRO_255*DENDRO_531 + DENDRO_542;
		 const double DENDRO_544 = DENDRO_211*DENDRO_226;
		 const double DENDRO_545 = DENDRO_205*DENDRO_249;
		 const double DENDRO_546 = 0.25*DENDRO_453;
		 const double DENDRO_547 = DENDRO_132*DENDRO_221;
		 const double DENDRO_548 = -0.5*DENDRO_194 + DENDRO_238*DENDRO_57;
		 const double DENDRO_549 = DENDRO_126*DENDRO_536 + DENDRO_226*DENDRO_57;
		 const double DENDRO_550 = 0.5*DENDRO_224;
		 const double DENDRO_551 = DENDRO_211*DENDRO_550;
		 const double DENDRO_552 = -DENDRO_167*DENDRO_365;
		 const double DENDRO_553 = 0.5*DENDRO_332;
		 const double DENDRO_554 = DENDRO_140*DENDRO_231;
		 const double DENDRO_555 = DENDRO_553 - DENDRO_554;
		 const double DENDRO_556 = DENDRO_113*DENDRO_335 + DENDRO_231*DENDRO_525;
		 const double DENDRO_557 = 0.25*DENDRO_530;
		 const double DENDRO_558 = 0.5*DENDRO_351;
		 const double DENDRO_559 = DENDRO_101*DENDRO_25;
		 const double DENDRO_560 = DENDRO_113*DENDRO_218;
		 const double DENDRO_561 = DENDRO_121*DENDRO_216 + DENDRO_560;
		 const double DENDRO_562 = DENDRO_559*(DENDRO_513 + DENDRO_561);
		 const double DENDRO_563 = DENDRO_267*DENDRO_48;
		 const double DENDRO_564 = DENDRO_110*DENDRO_269 + DENDRO_563;
		 const double DENDRO_565 = DENDRO_179*DENDRO_249;
		 const double DENDRO_566 = DENDRO_452 + DENDRO_544;
		 const double DENDRO_567 = DENDRO_347 + DENDRO_541;
		 const double DENDRO_568 = DENDRO_396 + DENDRO_517;
		 const double DENDRO_569 = -DENDRO_323*(DENDRO_518 + DENDRO_568);
		 const double DENDRO_570 = DENDRO_160*DENDRO_167 + DENDRO_551;
		 const double DENDRO_571 = DENDRO_130*DENDRO_221;
		 const double DENDRO_572 = DENDRO_237*DENDRO_57;
		 const double DENDRO_573 = 0.25*DENDRO_502;
		 const double DENDRO_574 = DENDRO_134*(DENDRO_571 + DENDRO_572 + DENDRO_573);
		 const double DENDRO_575 = DENDRO_267*DENDRO_53;
		 const double DENDRO_576 = -DENDRO_102*(DENDRO_363 + DENDRO_556);
		 const double DENDRO_577 = -DENDRO_129*(DENDRO_537 + DENDRO_549);
		 const double DENDRO_578 = -DENDRO_269*DENDRO_365;
		 const double DENDRO_579 = DENDRO_214*DENDRO_525 + DENDRO_510;
		 const double DENDRO_580 = DENDRO_121*DENDRO_336;
		 const double DENDRO_581 = -DENDRO_580;
		 const double DENDRO_582 = DENDRO_134*(DENDRO_196 + DENDRO_548);
		 const double DENDRO_583 = -DENDRO_129*(-DENDRO_230*DENDRO_57 + DENDRO_538);
		 const double DENDRO_584 = -DENDRO_177*(DENDRO_417*DENDRO_57 + DENDRO_539);
		 const double DENDRO_585 = grad2_1_2_alpha[pp];
		 const double DENDRO_586 = DENDRO_19*DENDRO_73;
		 const double DENDRO_587 = 2.0*DENDRO_36;
		 const double DENDRO_588 = DENDRO_80*gt4[pp];
		 const double DENDRO_589 = DENDRO_19*DENDRO_217 - DENDRO_19*DENDRO_219 + DENDRO_19*DENDRO_220;
		 const double DENDRO_590 = DENDRO_19*DENDRO_246;
		 const double DENDRO_591 = DENDRO_19*DENDRO_247;
		 const double DENDRO_592 = DENDRO_19*DENDRO_248;
		 const double DENDRO_593 = -DENDRO_40;
		 const double DENDRO_594 = DENDRO_37*(DENDRO_317*DENDRO_588 + DENDRO_593);
		 const double DENDRO_595 = DENDRO_459*(DENDRO_590 - DENDRO_591 - DENDRO_592 + DENDRO_594) - 4*DENDRO_585 + DENDRO_586*(-2.0*DENDRO_126*DENDRO_31 - 2.0*DENDRO_216*DENDRO_29 + 2.0*DENDRO_218*DENDRO_23 + 2.0*DENDRO_310*DENDRO_37*gt4[pp]) + DENDRO_587*(DENDRO_37*(DENDRO_389*DENDRO_588 + DENDRO_470) + DENDRO_589);
		 const double DENDRO_596 = -DENDRO_289;
		 const double DENDRO_597 = DENDRO_247 + DENDRO_248;
		 const double DENDRO_598 = DENDRO_265 + DENDRO_266;
		 const double DENDRO_599 = DENDRO_103*DENDRO_382 - DENDRO_207*(DENDRO_474*(DENDRO_218*DENDRO_315 + DENDRO_597) + DENDRO_475*(DENDRO_126*DENDRO_81 + DENDRO_216*DENDRO_315 + DENDRO_219) + DENDRO_476*(DENDRO_218*DENDRO_81 + DENDRO_598) + DENDRO_596) + DENDRO_227*DENDRO_381 + DENDRO_235*DENDRO_380 + DENDRO_383*gt4[pp];
		 const double DENDRO_600 = DENDRO_319*DENDRO_480;
		 const double DENDRO_601 = DENDRO_391*DENDRO_482;
		 const double DENDRO_602 = 2.0*gt3[pp];
		 const double DENDRO_603 = DENDRO_321*DENDRO_602;
		 const double DENDRO_604 = DENDRO_392*DENDRO_485;
		 const double DENDRO_605 = DENDRO_322*DENDRO_485;
		 const double DENDRO_606 = DENDRO_393*DENDRO_487;
		 const double DENDRO_607 = -DENDRO_290*DENDRO_93;
		 const double DENDRO_608 = -DENDRO_95*grad2_1_2_gt4[pp];
		 const double DENDRO_609 = DENDRO_96*grad2_0_2_gt4[pp];
		 const double DENDRO_610 = -DENDRO_97*grad2_0_1_gt4[pp];
		 const double DENDRO_611 = DENDRO_98*grad2_2_2_gt4[pp];
		 const double DENDRO_612 = DENDRO_99*grad2_1_1_gt4[pp];
		 const double DENDRO_613 = DENDRO_100*grad2_0_0_gt4[pp];
		 const double DENDRO_614 = DENDRO_221*DENDRO_335;
		 const double DENDRO_615 = DENDRO_238*DENDRO_241;
		 const double DENDRO_616 = DENDRO_233*DENDRO_536;
		 const double DENDRO_617 = DENDRO_167*DENDRO_218 + DENDRO_529;
		 const double DENDRO_618 = DENDRO_117*DENDRO_262 + DENDRO_575;
		 const double DENDRO_619 = DENDRO_221*DENDRO_430;
		 const double DENDRO_620 = 0.5*DENDRO_233;
		 const double DENDRO_621 = DENDRO_231*DENDRO_620;
		 const double DENDRO_622 = DENDRO_221*DENDRO_324 + DENDRO_621;
		 const double DENDRO_623 = 0.25*DENDRO_331 + DENDRO_515;
		 const double DENDRO_624 = DENDRO_241*DENDRO_531;
		 const double DENDRO_625 = DENDRO_249*DENDRO_324;
		 const double DENDRO_626 = DENDRO_255*DENDRO_417 + DENDRO_348;
		 const double DENDRO_627 = DENDRO_104 + DENDRO_175 + DENDRO_402;
		 const double DENDRO_628 = DENDRO_262*DENDRO_627;
		 const double DENDRO_629 = 1.0*DENDRO_101*DENDRO_31;
		 const double DENDRO_630 = DENDRO_111*DENDRO_167;
		 const double DENDRO_631 = DENDRO_132*DENDRO_262;
		 const double DENDRO_632 = DENDRO_230*DENDRO_255;
		 const double DENDRO_633 = -DENDRO_632;
		 const double DENDRO_634 = DENDRO_167*DENDRO_336;
		 const double DENDRO_635 = -DENDRO_634;
		 const double DENDRO_636 = DENDRO_197*DENDRO_258;
		 const double DENDRO_637 = DENDRO_167*DENDRO_430;
		 const double DENDRO_638 = DENDRO_249*DENDRO_627;
		 const double DENDRO_639 = -0.25*DENDRO_126*DENDRO_31 - 0.25*DENDRO_216*DENDRO_29 + 0.25*DENDRO_218*DENDRO_23;
		 const double DENDRO_640 = DENDRO_126*DENDRO_639;
		 const double DENDRO_641 = DENDRO_119*DENDRO_639 + DENDRO_136*DENDRO_274;
		 const double DENDRO_642 = DENDRO_277*DENDRO_531;
		 const double DENDRO_643 = DENDRO_124*DENDRO_267 + DENDRO_642;
		 const double DENDRO_644 = DENDRO_258*DENDRO_550;
		 const double DENDRO_645 = -DENDRO_249*DENDRO_336;
		 const double DENDRO_646 = -DENDRO_262*DENDRO_426;
		 const double DENDRO_647 = DENDRO_277*DENDRO_50;
		 const double DENDRO_648 = DENDRO_132*DENDRO_267 + DENDRO_647;
		 const double DENDRO_649 = DENDRO_197*DENDRO_277;
		 const double DENDRO_650 = DENDRO_267*DENDRO_627 + DENDRO_649;
		 const double DENDRO_651 = DENDRO_205*DENDRO_267 + DENDRO_274*DENDRO_55;
		 const double DENDRO_652 = DENDRO_160*DENDRO_267 + DENDRO_274*DENDRO_417;
		 const double DENDRO_653 = 1.0*DENDRO_410;
		 const double DENDRO_654 = 0.25*DENDRO_630;
		 const double DENDRO_655 = 0.5*DENDRO_349;
		 const double DENDRO_656 = 1.0*DENDRO_101*DENDRO_29;
		 const double DENDRO_657 = -DENDRO_656*(DENDRO_333 + DENDRO_561);
		 const double DENDRO_658 = DENDRO_111*DENDRO_262;
		 const double DENDRO_659 = DENDRO_167*DENDRO_324;
		 const double DENDRO_660 = DENDRO_414 + DENDRO_636;
		 const double DENDRO_661 = DENDRO_348 + DENDRO_635;
		 const double DENDRO_662 = -DENDRO_629*(DENDRO_195 + DENDRO_502 + DENDRO_503);
		 const double DENDRO_663 = -DENDRO_102*(DENDRO_231*DENDRO_237 + DENDRO_337 + DENDRO_614);
		 const double DENDRO_664 = DENDRO_249*DENDRO_335 + DENDRO_644;
		 const double DENDRO_665 = DENDRO_396 + DENDRO_397;
		 const double DENDRO_666 = DENDRO_124*DENDRO_262;
		 const double DENDRO_667 = DENDRO_277*DENDRO_49;
		 const double DENDRO_668 = DENDRO_443 + DENDRO_631;
		 const double DENDRO_669 = -DENDRO_129*(DENDRO_581 + DENDRO_623);
		 const double DENDRO_670 = DENDRO_241*DENDRO_417 + DENDRO_616;
		 const double DENDRO_671 = DENDRO_619 + DENDRO_621;
		 const double DENDRO_672 = DENDRO_198*DENDRO_277;
		 const double DENDRO_673 = 0.5*DENDRO_419;
		 const double DENDRO_674 = grad2_0_1_alpha[pp];
		 const double DENDRO_675 = DENDRO_19*DENDRO_59;
		 const double DENDRO_676 = DENDRO_80*gt1[pp];
		 const double DENDRO_677 = DENDRO_116*DENDRO_19 - DENDRO_118*DENDRO_19 + DENDRO_120*DENDRO_19;
		 const double DENDRO_678 = DENDRO_150*DENDRO_19;
		 const double DENDRO_679 = DENDRO_151*DENDRO_19;
		 const double DENDRO_680 = DENDRO_152*DENDRO_19;
		 const double DENDRO_681 = DENDRO_37*(DENDRO_593 + DENDRO_676*DENDRO_85);
		 const double DENDRO_682 = DENDRO_466*(DENDRO_678 - DENDRO_679 - DENDRO_680 + DENDRO_681) + DENDRO_587*(DENDRO_37*(DENDRO_389*DENDRO_676 + DENDRO_463) + DENDRO_677) - 4*DENDRO_674 + DENDRO_675*(2.0*DENDRO_117*DENDRO_25 - 2.0*DENDRO_119*DENDRO_33 - 2.0*DENDRO_29*DENDRO_53 + 2.0*DENDRO_37*DENDRO_64*gt1[pp]);
		 const double DENDRO_683 = -DENDRO_295;
		 const double DENDRO_684 = DENDRO_108*DENDRO_381 + DENDRO_137*DENDRO_380 - DENDRO_207*(DENDRO_474*(DENDRO_117*DENDRO_315 + DENDRO_172) + DENDRO_475*(DENDRO_118 + DENDRO_119*DENDRO_315 + DENDRO_53*DENDRO_81) + DENDRO_476*(DENDRO_117*DENDRO_81 + DENDRO_153) + DENDRO_683) + DENDRO_382*DENDRO_51 + DENDRO_383*gt1[pp];
		 const double DENDRO_685 = DENDRO_391*DENDRO_478;
		 const double DENDRO_686 = DENDRO_480*DENDRO_88;
		 const double DENDRO_687 = DENDRO_392*DENDRO_480;
		 const double DENDRO_688 = DENDRO_393*DENDRO_482;
		 const double DENDRO_689 = DENDRO_602*DENDRO_90;
		 const double DENDRO_690 = DENDRO_485*DENDRO_92;
		 const double DENDRO_691 = -DENDRO_40*DENDRO_489;
		 const double DENDRO_692 = -DENDRO_95*grad2_1_2_gt1[pp];
		 const double DENDRO_693 = DENDRO_96*grad2_0_2_gt1[pp];
		 const double DENDRO_694 = -DENDRO_97*grad2_0_1_gt1[pp];
		 const double DENDRO_695 = DENDRO_98*grad2_2_2_gt1[pp];
		 const double DENDRO_696 = DENDRO_99*grad2_1_1_gt1[pp];
		 const double DENDRO_697 = DENDRO_100*grad2_0_0_gt1[pp];
		 const double DENDRO_698 = DENDRO_121*DENDRO_130;
		 const double DENDRO_699 = -DENDRO_177*(1.0*DENDRO_122 + DENDRO_698);
		 const double DENDRO_700 = -DENDRO_102*(DENDRO_113*DENDRO_237 + DENDRO_514);
		 const double DENDRO_701 = 0.5*DENDRO_408;
		 const double DENDRO_702 = DENDRO_140*DENDRO_241;
		 const double DENDRO_703 = -DENDRO_702;
		 const double DENDRO_704 = DENDRO_123*(DENDRO_568 + DENDRO_616);
		 const double DENDRO_705 = DENDRO_125 + DENDRO_572;
		 const double DENDRO_706 = -DENDRO_129*(DENDRO_571 + DENDRO_705);
		 const double DENDRO_707 = -DENDRO_121*DENDRO_426;
		 const double DENDRO_708 = DENDRO_57*DENDRO_620;
		 const double DENDRO_709 = DENDRO_121*DENDRO_124 + DENDRO_708;
		 const double DENDRO_710 = DENDRO_134*(DENDRO_707 + DENDRO_709);
		 const double DENDRO_711 = DENDRO_241*DENDRO_525;
		 const double DENDRO_712 = DENDRO_396 + DENDRO_616;
		 const double DENDRO_713 = 0.25*DENDRO_127;
		 const double DENDRO_714 = -DENDRO_129*(DENDRO_705 + DENDRO_713);
		 const double DENDRO_715 = 1.0*DENDRO_101*DENDRO_33;
		 const double DENDRO_716 = DENDRO_124*DENDRO_269;
		 const double DENDRO_717 = DENDRO_277*DENDRO_54;
		 const double DENDRO_718 = DENDRO_214*DENDRO_417 + DENDRO_443;
		 const double DENDRO_719 = DENDRO_214*DENDRO_55;
		 const double DENDRO_720 = DENDRO_269*DENDRO_627;
		 const double DENDRO_721 = DENDRO_258*DENDRO_525;
		 const double DENDRO_722 = DENDRO_199*DENDRO_324 + DENDRO_721;
		 const double DENDRO_723 = 0.25*DENDRO_117*DENDRO_25 - 0.25*DENDRO_119*DENDRO_33 - 0.25*DENDRO_29*DENDRO_53;
		 const double DENDRO_724 = DENDRO_119*DENDRO_723;
		 const double DENDRO_725 = DENDRO_126*DENDRO_723 + DENDRO_211*DENDRO_237;
		 const double DENDRO_726 = DENDRO_277*DENDRO_520;
		 const double DENDRO_727 = DENDRO_132*DENDRO_269;
		 const double DENDRO_728 = DENDRO_258*DENDRO_49;
		 const double DENDRO_729 = DENDRO_199*DENDRO_627 + DENDRO_728;
		 const double DENDRO_730 = 0.5*DENDRO_423;
		 const double DENDRO_731 = DENDRO_198*DENDRO_258;
		 const double DENDRO_732 = -DENDRO_730 - DENDRO_731;
		 const double DENDRO_733 = 0.5*DENDRO_200;
		 const double DENDRO_734 = DENDRO_211*DENDRO_230;
		 const double DENDRO_735 = -DENDRO_733 - DENDRO_734;
		 const double DENDRO_736 = DENDRO_179*DENDRO_199 + DENDRO_211*DENDRO_417;
		 const double DENDRO_737 = DENDRO_418 + DENDRO_667;
		 const double DENDRO_738 = DENDRO_130*DENDRO_269 + DENDRO_726;
		 const double DENDRO_739 = DENDRO_19*(-DENDRO_23*(DENDRO_682 + alpha[pp]*(-DENDRO_102*(DENDRO_541 + DENDRO_661) - DENDRO_102*(DENDRO_267*DENDRO_49 + DENDRO_628) + DENDRO_115*(DENDRO_241*DENDRO_53 + DENDRO_395) + DENDRO_123*(DENDRO_425 + DENDRO_732) + DENDRO_123*(DENDRO_517 + DENDRO_670) + DENDRO_123*(DENDRO_665 + DENDRO_711) + DENDRO_123*(DENDRO_666 + DENDRO_737) + DENDRO_123*(DENDRO_720 + DENDRO_737) + DENDRO_123*(DENDRO_557 + DENDRO_636 + DENDRO_659) - DENDRO_129*(DENDRO_510 + DENDRO_668) - DENDRO_129*(DENDRO_510 + DENDRO_718) - DENDRO_129*(DENDRO_545 + DENDRO_735) - DENDRO_129*(DENDRO_547 + DENDRO_572 + DENDRO_713) + DENDRO_134*(DENDRO_724 + DENDRO_729) + DENDRO_134*(DENDRO_727 + DENDRO_738) + DENDRO_134*(DENDRO_136*DENDRO_214 + DENDRO_738) + DENDRO_134*(DENDRO_258*DENDRO_50 + DENDRO_725) + DENDRO_134*(DENDRO_241*DENDRO_55 + DENDRO_707 + DENDRO_708) - DENDRO_177*(0.5*DENDRO_448 + DENDRO_719) - DENDRO_177*(DENDRO_456 + DENDRO_736) - DENDRO_177*(DENDRO_135 + DENDRO_136*DENDRO_57 + DENDRO_698) - DENDRO_323*(1.0*DENDRO_411 + DENDRO_716) - DENDRO_323*(0.5*DENDRO_420 + DENDRO_722) - DENDRO_323*(DENDRO_136*DENDRO_241 + DENDRO_413 + DENDRO_703) - DENDRO_656*(DENDRO_195 + DENDRO_504) - DENDRO_656*(DENDRO_506 + DENDRO_630) + DENDRO_684 + DENDRO_685 + DENDRO_686 + DENDRO_687 + DENDRO_688 + DENDRO_689 + DENDRO_690 + DENDRO_691 + DENDRO_692 + DENDRO_693 + DENDRO_694 + DENDRO_695 + DENDRO_696 + DENDRO_697 - DENDRO_715*(DENDRO_333 + DENDRO_513 + DENDRO_560))) - DENDRO_23*(DENDRO_682 + alpha[pp]*(-DENDRO_102*(DENDRO_567 + DENDRO_635) + DENDRO_115*(DENDRO_117*DENDRO_214 + DENDRO_442) + DENDRO_123*(DENDRO_637 + DENDRO_732) + DENDRO_123*(DENDRO_711 + DENDRO_712) + DENDRO_123*(DENDRO_646 + DENDRO_667 + DENDRO_720) - DENDRO_129*(DENDRO_202 + DENDRO_735) - DENDRO_129*(DENDRO_444 + DENDRO_718) - DENDRO_129*(DENDRO_579 + DENDRO_631) - DENDRO_129*(DENDRO_544 + DENDRO_565 + DENDRO_654) + DENDRO_134*(DENDRO_724 + DENDRO_725) + DENDRO_134*(DENDRO_211*DENDRO_238 + DENDRO_729) + DENDRO_134*(DENDRO_241*DENDRO_54 + DENDRO_709) + DENDRO_134*(-DENDRO_140*DENDRO_214 + DENDRO_726 + DENDRO_727) - DENDRO_177*(0.5*DENDRO_454 + DENDRO_736) - DENDRO_177*(DENDRO_214*DENDRO_54 + DENDRO_451 + DENDRO_719) - DENDRO_323*(DENDRO_435 + DENDRO_722) - DENDRO_323*(DENDRO_701 + DENDRO_703) - DENDRO_323*(DENDRO_433 + DENDRO_716 + DENDRO_717) + DENDRO_559*(DENDRO_421 + DENDRO_618) + DENDRO_559*(DENDRO_530 + DENDRO_617) + DENDRO_684 + DENDRO_685 + DENDRO_686 + DENDRO_687 + DENDRO_688 + DENDRO_689 + DENDRO_690 + DENDRO_691 + DENDRO_692 + DENDRO_693 + DENDRO_694 + DENDRO_695 + DENDRO_696 + DENDRO_697 + DENDRO_699 + DENDRO_700 + DENDRO_704 + DENDRO_706 + DENDRO_710 + DENDRO_714 - DENDRO_715*(DENDRO_360 + DENDRO_563 + DENDRO_658))) - DENDRO_25*(DENDRO_595 + alpha[pp]*(-DENDRO_102*(1.0*DENDRO_329 + DENDRO_614) - DENDRO_102*(0.5*DENDRO_359 + DENDRO_652) - DENDRO_102*(DENDRO_226*DENDRO_255 + DENDRO_355 + DENDRO_633) + DENDRO_123*(DENDRO_619 + DENDRO_622) + DENDRO_123*(DENDRO_640 + DENDRO_641) + DENDRO_123*(-DENDRO_140*DENDRO_274 + DENDRO_650) + DENDRO_123*(DENDRO_226*DENDRO_241 + DENDRO_622) + DENDRO_123*(DENDRO_238*DENDRO_255 + DENDRO_644 + DENDRO_645) - DENDRO_129*(DENDRO_330 + DENDRO_516) - DENDRO_129*(DENDRO_330 + DENDRO_623) - DENDRO_129*(DENDRO_347 + DENDRO_626) - DENDRO_129*(DENDRO_361 + DENDRO_651) - DENDRO_129*(DENDRO_508 + DENDRO_628) - DENDRO_129*(DENDRO_543 + DENDRO_635) + DENDRO_134*(DENDRO_519 + DENDRO_616) + DENDRO_134*(DENDRO_646 + DENDRO_648) + DENDRO_134*(DENDRO_397 + DENDRO_616 + DENDRO_624) + DENDRO_134*(DENDRO_636 + DENDRO_637 + DENDRO_638) - DENDRO_177*(DENDRO_512 + DENDRO_631) - DENDRO_177*(DENDRO_113*DENDRO_136 + DENDRO_573) - DENDRO_323*(0.5*DENDRO_406 + DENDRO_615) - DENDRO_323*(DENDRO_428 + DENDRO_643) - DENDRO_323*(DENDRO_226*DENDRO_258 + DENDRO_431 + DENDRO_625) + DENDRO_328*(DENDRO_218*DENDRO_255 + DENDRO_339) + DENDRO_501*(DENDRO_424 + DENDRO_617) + DENDRO_501*(DENDRO_498 + DENDRO_618) + DENDRO_599 + DENDRO_600 + DENDRO_601 + DENDRO_603 + DENDRO_604 + DENDRO_605 + DENDRO_606 + DENDRO_607 + DENDRO_608 + DENDRO_609 + DENDRO_610 + DENDRO_611 + DENDRO_612 + DENDRO_613 - DENDRO_629*(DENDRO_201 + DENDRO_505 + DENDRO_630))) - DENDRO_25*(DENDRO_595 + alpha[pp]*(-DENDRO_102*(DENDRO_367 + DENDRO_652) - DENDRO_102*(DENDRO_633 + DENDRO_655) + DENDRO_123*(DENDRO_640 + DENDRO_650) + DENDRO_123*(DENDRO_641 - DENDRO_672) + DENDRO_123*(DENDRO_645 + DENDRO_664) + DENDRO_123*(-DENDRO_230*DENDRO_241 + DENDRO_671) + DENDRO_123*(DENDRO_237*DENDRO_255 + DENDRO_664) - DENDRO_129*(DENDRO_542 + DENDRO_626) - DENDRO_129*(DENDRO_542 + DENDRO_661) - DENDRO_129*(DENDRO_578 + DENDRO_651) + DENDRO_134*(DENDRO_422 + DENDRO_648) + DENDRO_134*(DENDRO_518 + DENDRO_670) + DENDRO_134*(DENDRO_624 + DENDRO_665) + DENDRO_134*(DENDRO_638 + DENDRO_660) + DENDRO_134*(DENDRO_659 + DENDRO_660) + DENDRO_134*(DENDRO_499 + DENDRO_666 + DENDRO_667) - DENDRO_177*(DENDRO_511 + DENDRO_668) - DENDRO_177*(DENDRO_197*DENDRO_199 + DENDRO_654) - DENDRO_323*(DENDRO_625 + DENDRO_653) - DENDRO_323*(DENDRO_643 + DENDRO_673) - DENDRO_323*(DENDRO_237*DENDRO_241 + DENDRO_412 + DENDRO_615) + DENDRO_328*(DENDRO_216*DENDRO_241 + DENDRO_394) + DENDRO_599 + DENDRO_600 + DENDRO_601 + DENDRO_603 + DENDRO_604 + DENDRO_605 + DENDRO_606 + DENDRO_607 + DENDRO_608 + DENDRO_609 + DENDRO_610 + DENDRO_611 + DENDRO_612 + DENDRO_613 - DENDRO_656*(DENDRO_564 + DENDRO_658) + DENDRO_657 + DENDRO_662 + DENDRO_663 + DENDRO_669)) + DENDRO_26*(DENDRO_307*(DENDRO_277 + DENDRO_310*DENDRO_386) + 4*DENDRO_36*(DENDRO_37*(DENDRO_387 + DENDRO_388*DENDRO_389*DENDRO_80) + DENDRO_390) - 4*DENDRO_384 + DENDRO_385*(DENDRO_258 + DENDRO_65*gt3[pp]) + alpha[pp]*(-DENDRO_101*DENDRO_241*DENDRO_26*DENDRO_399 + DENDRO_115*(DENDRO_408 + DENDRO_409) + DENDRO_115*(DENDRO_117*DENDRO_269 + DENDRO_411) + DENDRO_115*(DENDRO_199*DENDRO_218 + DENDRO_420) + DENDRO_117*DENDRO_382 + DENDRO_123*(1.0*DENDRO_407 + DENDRO_412) + DENDRO_123*(DENDRO_428 + DENDRO_429) + DENDRO_123*(DENDRO_431 - DENDRO_432) - DENDRO_129*(-1.0*DENDRO_423 + DENDRO_425) - DENDRO_129*(DENDRO_249*DENDRO_417 + DENDRO_414) - DENDRO_129*(DENDRO_267*DENDRO_55 + DENDRO_422) - DENDRO_129*(DENDRO_269*DENDRO_417 + DENDRO_418) + DENDRO_134*(1.0*DENDRO_409 + DENDRO_413) + DENDRO_134*(DENDRO_433 + DENDRO_434) + DENDRO_134*(DENDRO_435 + DENDRO_436) - DENDRO_199*DENDRO_404 - DENDRO_207*(DENDRO_372*(DENDRO_233*DENDRO_378 + DENDRO_257 + DENDRO_29*DENDRO_439) + DENDRO_377*(DENDRO_234 + DENDRO_238*DENDRO_315 + DENDRO_439*DENDRO_81) + DENDRO_379*(DENDRO_233*DENDRO_440 + DENDRO_276 + DENDRO_31*DENDRO_439) + DENDRO_437) + DENDRO_218*DENDRO_381 + DENDRO_233*DENDRO_380 - DENDRO_267*DENDRO_403 - DENDRO_269*DENDRO_401 + DENDRO_328*(DENDRO_406 + DENDRO_407) + DENDRO_328*(DENDRO_117*DENDRO_267 + DENDRO_419) + DENDRO_328*(DENDRO_218*DENDRO_249 + DENDRO_410) + DENDRO_383*gt3[pp] + DENDRO_398 - DENDRO_400*(DENDRO_228 - DENDRO_335) - DENDRO_405*(DENDRO_136 + DENDRO_138))) + DENDRO_29*(DENDRO_472 + alpha[pp]*(-DENDRO_102*(1.0*DENDRO_353 + DENDRO_497) - DENDRO_102*(DENDRO_231*DENDRO_417 + DENDRO_556) - DENDRO_102*(DENDRO_197*DENDRO_255 + DENDRO_356 + DENDRO_535) + DENDRO_123*(DENDRO_334 + DENDRO_555) + DENDRO_123*(DENDRO_348 + DENDRO_526) + DENDRO_123*(DENDRO_357 + DENDRO_508) + DENDRO_123*(DENDRO_357 + DENDRO_527) + DENDRO_123*(DENDRO_514 + DENDRO_516) + DENDRO_123*(DENDRO_541 + DENDRO_543) - DENDRO_128*(DENDRO_255*DENDRO_48 + DENDRO_341) - DENDRO_129*(DENDRO_522 + DENDRO_523) - DENDRO_129*(DENDRO_537 + DENDRO_538) - DENDRO_129*(DENDRO_197*DENDRO_214 + DENDRO_522) - DENDRO_129*(DENDRO_231*DENDRO_55 + DENDRO_549) - DENDRO_129*(DENDRO_255*DENDRO_50 + DENDRO_551 + DENDRO_552) + DENDRO_134*(DENDRO_510 + DENDRO_512) + DENDRO_134*(DENDRO_510 + DENDRO_532) + DENDRO_134*(DENDRO_547 + DENDRO_548) + DENDRO_134*(DENDRO_544 + DENDRO_545 + DENDRO_546) - DENDRO_177*(DENDRO_133 + DENDRO_539) - DENDRO_177*(0.5*DENDRO_446 + DENDRO_500) - DENDRO_177*(DENDRO_197*DENDRO_211 + DENDRO_455 + DENDRO_533) - DENDRO_323*(DENDRO_517 + DENDRO_519) - DENDRO_323*(DENDRO_267*DENDRO_54 + DENDRO_499) + DENDRO_477 + DENDRO_479 + DENDRO_481 + DENDRO_483 + DENDRO_484 + DENDRO_486 + DENDRO_488 + DENDRO_490 + DENDRO_491 + DENDRO_492 + DENDRO_493 + DENDRO_494 + DENDRO_495 + DENDRO_496 + DENDRO_501*(DENDRO_201 + DENDRO_506) + DENDRO_501*(DENDRO_502 + DENDRO_504) - DENDRO_528*(DENDRO_424 + DENDRO_529 + DENDRO_530))) + DENDRO_29*(DENDRO_472 + alpha[pp]*(-DENDRO_102*(DENDRO_535 + DENDRO_558) - DENDRO_102*(DENDRO_274*DENDRO_49 + DENDRO_369 + DENDRO_497) + DENDRO_123*(DENDRO_526 + DENDRO_542) + DENDRO_123*(DENDRO_527 + DENDRO_578) + DENDRO_123*(DENDRO_542 + DENDRO_567) + DENDRO_123*(DENDRO_555 + DENDRO_581) - DENDRO_128*(DENDRO_110*DENDRO_214 + DENDRO_441) - DENDRO_129*(DENDRO_552 + DENDRO_570) - DENDRO_129*(DENDRO_255*DENDRO_49 + DENDRO_570) - DENDRO_129*(-DENDRO_198*DENDRO_214 + DENDRO_521 + DENDRO_523) + DENDRO_134*(DENDRO_443 + DENDRO_532) + DENDRO_134*(DENDRO_511 + DENDRO_579) + DENDRO_134*(DENDRO_546 + DENDRO_566) + DENDRO_134*(DENDRO_565 + DENDRO_566) - DENDRO_177*(1.0*DENDRO_445 + DENDRO_533) - DENDRO_177*(DENDRO_214*DENDRO_49 + DENDRO_450 + DENDRO_500) - DENDRO_323*(DENDRO_199*DENDRO_226 + DENDRO_557) + DENDRO_477 + DENDRO_479 + DENDRO_481 + DENDRO_483 + DENDRO_484 + DENDRO_486 + DENDRO_488 + DENDRO_490 + DENDRO_491 + DENDRO_492 + DENDRO_493 + DENDRO_494 + DENDRO_495 + DENDRO_496 - DENDRO_528*(DENDRO_421 + DENDRO_498 + DENDRO_575) + DENDRO_559*(DENDRO_360 + DENDRO_564) + DENDRO_562 + DENDRO_569 + DENDRO_574 + DENDRO_576 + DENDRO_577 + DENDRO_582 + DENDRO_583 + DENDRO_584)) + DENDRO_31*(-4*DENDRO_35 + DENDRO_385*(DENDRO_211 + DENDRO_66) + 4*DENDRO_58 + 4*DENDRO_73*(-DENDRO_75 - DENDRO_77 + DENDRO_79 + DENDRO_86) + alpha[pp]*(-DENDRO_114*DENDRO_178*DENDRO_211*DENDRO_31 + DENDRO_115*(DENDRO_448 + DENDRO_449) + DENDRO_115*(DENDRO_199*DENDRO_48 + DENDRO_454) + DENDRO_123*(-1.0*DENDRO_194 + DENDRO_196) + DENDRO_123*(-1.0*DENDRO_200 + DENDRO_202) + DENDRO_123*(DENDRO_452 + 0.5*DENDRO_453) + DENDRO_123*(DENDRO_262*DENDRO_54 + DENDRO_443) + DENDRO_123*(DENDRO_269*DENDRO_49 + DENDRO_444) - DENDRO_128*(DENDRO_446 + DENDRO_447) - DENDRO_128*(DENDRO_167*DENDRO_48 + DENDRO_445) - DENDRO_129*(1.0*DENDRO_447 + DENDRO_450) - DENDRO_129*(-DENDRO_206*DENDRO_211 + DENDRO_455) + DENDRO_134*(1.0*DENDRO_449 + DENDRO_451) + DENDRO_134*(DENDRO_126*DENDRO_211 + DENDRO_456) + DENDRO_141 - DENDRO_142*DENDRO_441 - DENDRO_149*DENDRO_442 - DENDRO_156*(-DENDRO_124 + DENDRO_138) - DENDRO_157*DENDRO_279 - DENDRO_168*(-DENDRO_160 + DENDRO_162) - DENDRO_176*DENDRO_199 - DENDRO_207*(DENDRO_209 + DENDRO_372*(DENDRO_315*DENDRO_55 + DENDRO_71) + DENDRO_377*(DENDRO_315*DENDRO_50 + DENDRO_44*DENDRO_440 + DENDRO_56) + DENDRO_379*(DENDRO_158 + DENDRO_55*DENDRO_81)) + DENDRO_380*DENDRO_53 + DENDRO_381*DENDRO_48 + DENDRO_382*DENDRO_44 + DENDRO_383*gt0[pp])) + DENDRO_33*(-4*DENDRO_305 + 4*DENDRO_306 + DENDRO_307*(DENDRO_274 + DENDRO_311) + 4*DENDRO_59*(-DENDRO_312 + DENDRO_313 - DENDRO_314 + DENDRO_318) + alpha[pp]*(DENDRO_110*DENDRO_382 + DENDRO_123*(1.0*DENDRO_350 + DENDRO_355) + DENDRO_123*(DENDRO_367 + DENDRO_368) - DENDRO_128*(DENDRO_351 + DENDRO_352) - DENDRO_128*(DENDRO_110*DENDRO_262 + DENDRO_353) - DENDRO_129*(1.0*DENDRO_352 + DENDRO_356) - DENDRO_129*(DENDRO_363 + DENDRO_364) - DENDRO_129*(DENDRO_274*DENDRO_370 + DENDRO_369) + DENDRO_134*(DENDRO_357 + 0.5*DENDRO_358) + DENDRO_134*(DENDRO_167*DENDRO_226 + DENDRO_348) + DENDRO_134*(DENDRO_197*DENDRO_249 + DENDRO_347) + DENDRO_134*(DENDRO_267*DENDRO_50 + DENDRO_361) - DENDRO_149*DENDRO_339 - DENDRO_207*(DENDRO_371 + DENDRO_372*(DENDRO_252 + DENDRO_29*DENDRO_376 + DENDRO_315*DENDRO_374) + DENDRO_377*(DENDRO_224*DENDRO_378 + DENDRO_26*DENDRO_374 + DENDRO_376*DENDRO_81) + DENDRO_379*(DENDRO_271 + DENDRO_31*DENDRO_376 + DENDRO_374*DENDRO_81)) + DENDRO_216*DENDRO_380 + DENDRO_224*DENDRO_381 - DENDRO_256*DENDRO_342 - DENDRO_262*DENDRO_343 - DENDRO_267*DENDRO_344 + DENDRO_328*(DENDRO_349 + DENDRO_350) + DENDRO_328*(DENDRO_110*DENDRO_267 + DENDRO_359) + DENDRO_338 - DENDRO_340*DENDRO_341 - DENDRO_345*(DENDRO_162 + DENDRO_197) - DENDRO_346*(DENDRO_226 + DENDRO_228) + DENDRO_383*gt5[pp])));
		 const double DENDRO_740 = grad_1_beta0[pp];
		 const double DENDRO_741 = grad_1_beta2[pp];
		 const double DENDRO_742 = (1.0L/3.0L)*At1[pp];
		 const double DENDRO_743 = (2.0L/3.0L)*DENDRO_3;
		 const double DENDRO_744 = At4[pp]*DENDRO_25;
		 const double DENDRO_745 = -At3[pp]*DENDRO_26 + DENDRO_28 + DENDRO_744;
		 const double DENDRO_746 = -At1[pp]*DENDRO_31 + At3[pp]*DENDRO_23 - At4[pp]*DENDRO_29;
		 const double DENDRO_747 = -At1[pp]*DENDRO_29 + At3[pp]*DENDRO_25 - At4[pp]*DENDRO_33;
		 const double DENDRO_748 = 6.0*DENDRO_36;
		 const double DENDRO_749 = DENDRO_19*DENDRO_42;
		 const double DENDRO_750 = 6.0*DENDRO_73;
		 const double DENDRO_751 = 1.0*DENDRO_101*DENDRO_25;
		 const double DENDRO_752 = -DENDRO_246 + DENDRO_597;
		 const double DENDRO_753 = DENDRO_126*DENDRO_752;
		 const double DENDRO_754 = -DENDRO_264 + DENDRO_598;
		 const double DENDRO_755 = DENDRO_126*DENDRO_154;
		 const double DENDRO_756 = DENDRO_53*DENDRO_754 + DENDRO_755;
		 const double DENDRO_757 = DENDRO_48*DENDRO_754;
		 const double DENDRO_758 = DENDRO_126*DENDRO_147;
		 const double DENDRO_759 = DENDRO_111*DENDRO_147;
		 const double DENDRO_760 = DENDRO_234 - DENDRO_239 + DENDRO_240;
		 const double DENDRO_761 = DENDRO_154*DENDRO_426;
		 const double DENDRO_762 = DENDRO_179*DENDRO_752;
		 const double DENDRO_763 = DENDRO_226*DENDRO_72;
		 const double DENDRO_764 = DENDRO_183*DENDRO_627;
		 const double DENDRO_765 = DENDRO_180 + DENDRO_181;
		 const double DENDRO_766 = DENDRO_132*DENDRO_147;
		 const double DENDRO_767 = DENDRO_159*DENDRO_525 + DENDRO_509*DENDRO_754;
		 const double DENDRO_768 = -DENDRO_173*DENDRO_430;
		 const double DENDRO_769 = -0.25*DENDRO_117*DENDRO_25 + 0.25*DENDRO_119*DENDRO_33 + 0.25*DENDRO_29*DENDRO_53;
		 const double DENDRO_770 = 0.5*DENDRO_19*DENDRO_40;
		 const double DENDRO_771 = 0.5*DENDRO_19*DENDRO_38;
		 const double DENDRO_772 = 0.5*DENDRO_19*DENDRO_39;
		 const double DENDRO_773 = grad_2_beta0[pp];
		 const double DENDRO_774 = grad_2_beta1[pp];
		 const double DENDRO_775 = (1.0L/3.0L)*At2[pp];
		 const double DENDRO_776 = (2.0L/3.0L)*DENDRO_2;
		 const double DENDRO_777 = At2[pp]*DENDRO_23 - At4[pp]*DENDRO_26 + At5[pp]*DENDRO_25;
		 const double DENDRO_778 = -At2[pp]*DENDRO_31 + At4[pp]*DENDRO_23 - At5[pp]*DENDRO_29;
		 const double DENDRO_779 = -At5[pp]*DENDRO_33 + DENDRO_30 + DENDRO_744;
		 const double DENDRO_780 = 6.0*DENDRO_59;
		 const double DENDRO_781 = DENDRO_110*DENDRO_154 + DENDRO_757;
		 const double DENDRO_782 = DENDRO_173*DENDRO_354;
		 const double DENDRO_783 = -DENDRO_782;
		 const double DENDRO_784 = DENDRO_183*DENDRO_335;
		 const double DENDRO_785 = DENDRO_191 + DENDRO_763;
		 const double DENDRO_786 = DENDRO_119*DENDRO_154;
		 const double DENDRO_787 = DENDRO_160*DENDRO_183;
		 const double DENDRO_788 = DENDRO_550*DENDRO_72;
		 const double DENDRO_789 = DENDRO_252 - DENDRO_253 + DENDRO_254;
		 const double DENDRO_790 = DENDRO_147*DENDRO_365;
		 const double DENDRO_791 = DENDRO_271 + DENDRO_272 - DENDRO_273;
		 const double DENDRO_792 = DENDRO_154*DENDRO_365;
		 const double DENDRO_793 = DENDRO_119*DENDRO_147;
		 const double DENDRO_794 = DENDRO_154*DENDRO_205;
		 const double DENDRO_795 = (2.0L/3.0L)*DENDRO_0;
		 const double DENDRO_796 = 2*At4[pp];
		 const double DENDRO_797 = 2*At3[pp]*DENDRO_19;
		 const double DENDRO_798 = 2*At4[pp]*DENDRO_19;
		 const double DENDRO_799 = 12*DENDRO_19*DENDRO_73;
		 const double DENDRO_800 = DENDRO_218*DENDRO_760;
		 const double DENDRO_801 = DENDRO_117*DENDRO_760;
		 const double DENDRO_802 = DENDRO_173*DENDRO_335;
		 const double DENDRO_803 = 1.0*DENDRO_126*DENDRO_31 + 1.0*DENDRO_216*DENDRO_29 - 1.0*DENDRO_218*DENDRO_23;
		 const double DENDRO_804 = 0.25*DENDRO_755;
		 const double DENDRO_805 = (1.0L/3.0L)*At4[pp];
		 const double DENDRO_806 = DENDRO_160*DENDRO_752;
		 const double DENDRO_807 = DENDRO_636 - DENDRO_802;
		 const double DENDRO_808 = -DENDRO_335*DENDRO_752 + DENDRO_644;
		 const double DENDRO_809 = 0.25*DENDRO_126*DENDRO_31 + 0.25*DENDRO_216*DENDRO_29 - 0.25*DENDRO_218*DENDRO_23;
		 const double DENDRO_810 = DENDRO_224*DENDRO_752;
		 const double DENDRO_811 = DENDRO_216*DENDRO_789;
		 const double DENDRO_812 = DENDRO_183*DENDRO_224;
		 const double DENDRO_813 = DENDRO_110*DENDRO_789;
			      // Dendro: printing variables

		   At_rhs00[pp] = (4.0L/3.0L)*At0[pp]*DENDRO_0 - DENDRO_1*DENDRO_2 - DENDRO_1*DENDRO_3 + DENDRO_34*(-12*DENDRO_35 + 12*DENDRO_58 - DENDRO_60*(-DENDRO_66 + DENDRO_72) - 12*DENDRO_73*(DENDRO_75 + DENDRO_77 - DENDRO_79 - DENDRO_86) + DENDRO_739*gt0[pp] + DENDRO_87*(-DENDRO_115*(DENDRO_187 + DENDRO_188) - DENDRO_115*(DENDRO_173*DENDRO_48 + DENDRO_193) - DENDRO_123*(DENDRO_191 + 0.5*DENDRO_192) - DENDRO_123*(DENDRO_194 - DENDRO_196) - DENDRO_123*(DENDRO_200 + DENDRO_203) - DENDRO_123*(DENDRO_147*DENDRO_54 + DENDRO_180) - DENDRO_123*(DENDRO_154*DENDRO_49 + DENDRO_181) + DENDRO_128*(DENDRO_185 + DENDRO_186) + DENDRO_128*(DENDRO_183*DENDRO_48 + DENDRO_184) + DENDRO_129*(1.0*DENDRO_186 + DENDRO_189) - DENDRO_129*(-DENDRO_183*DENDRO_205 + DENDRO_206*DENDRO_72) - DENDRO_134*(1.0*DENDRO_188 + DENDRO_190) - DENDRO_134*(1.0*DENDRO_126*DENDRO_72 + DENDRO_173*DENDRO_205) + DENDRO_141 + DENDRO_142*DENDRO_148 + DENDRO_149*DENDRO_155 + DENDRO_156*(DENDRO_124 + DENDRO_139) + DENDRO_157*DENDRO_159*DENDRO_31 + DENDRO_168*(DENDRO_160 + DENDRO_163) + DENDRO_173*DENDRO_176 + DENDRO_177*DENDRO_178*DENDRO_72 - DENDRO_207*(DENDRO_209 + DENDRO_210*DENDRO_211 + DENDRO_212*DENDRO_57 + DENDRO_213*DENDRO_214) - DENDRO_244*DENDRO_53 - DENDRO_261*DENDRO_48 - DENDRO_280*DENDRO_44 - DENDRO_304*gt0[pp])) + DENDRO_4*DENDRO_5 + DENDRO_6*DENDRO_7 - alpha[pp]*(-At0[pp]*K[pp] + DENDRO_20*(At0[pp]*DENDRO_23 - At1[pp]*DENDRO_26 + At2[pp]*DENDRO_25) + DENDRO_27*(-At0[pp]*DENDRO_31 + DENDRO_28 + DENDRO_30) + DENDRO_32*(-At0[pp]*DENDRO_29 + At1[pp]*DENDRO_25 - At2[pp]*DENDRO_33)) + beta0[pp]*agrad_0_At0[pp] + beta1[pp]*agrad_1_At0[pp] + beta2[pp]*agrad_2_At0[pp];
		   At_rhs01[pp] = At0[pp]*DENDRO_740 - At1[pp]*DENDRO_743 + At2[pp]*DENDRO_741 + At3[pp]*DENDRO_5 + At4[pp]*DENDRO_7 + DENDRO_0*DENDRO_742 + DENDRO_2*DENDRO_742 + DENDRO_34*(-12*DENDRO_674 - DENDRO_675*(-6.0*DENDRO_117*DENDRO_25 + 6.0*DENDRO_119*DENDRO_33 + 6.0*DENDRO_29*DENDRO_53 - 6.0*DENDRO_37*DENDRO_64*gt1[pp]) + DENDRO_739*gt1[pp] + DENDRO_748*(DENDRO_37*(DENDRO_463 + DENDRO_749*gt1[pp]) + DENDRO_677) - DENDRO_750*(-DENDRO_678 + DENDRO_679 + DENDRO_680 - DENDRO_681) + DENDRO_87*(DENDRO_101*DENDRO_33*(DENDRO_757 + DENDRO_758 + DENDRO_759) + DENDRO_102*(-DENDRO_347 + DENDRO_540 + DENDRO_634) - DENDRO_108*DENDRO_261 - DENDRO_115*(DENDRO_117*DENDRO_159 + DENDRO_155) + DENDRO_123*(-DENDRO_525*DENDRO_760 + DENDRO_712) - DENDRO_123*(-DENDRO_637 + DENDRO_730 + DENDRO_731) + DENDRO_123*(DENDRO_147*DENDRO_426 - DENDRO_154*DENDRO_627 + DENDRO_667) + DENDRO_129*(DENDRO_766 + DENDRO_767) + DENDRO_129*(DENDRO_159*DENDRO_417 + DENDRO_765) + DENDRO_129*(DENDRO_203 + DENDRO_733 + DENDRO_734) + DENDRO_129*(DENDRO_762 + DENDRO_763 + DENDRO_764) + DENDRO_134*(-DENDRO_54*DENDRO_760 + DENDRO_709) + DENDRO_134*(-DENDRO_111*DENDRO_769 - DENDRO_238*DENDRO_72 + DENDRO_728) - DENDRO_134*(DENDRO_119*DENDRO_769 + DENDRO_126*DENDRO_769 + DENDRO_237*DENDRO_72) + DENDRO_134*(-DENDRO_132*DENDRO_154 + DENDRO_140*DENDRO_159 + DENDRO_726) - DENDRO_137*DENDRO_244 + DENDRO_177*(DENDRO_159*DENDRO_54 + DENDRO_159*DENDRO_55 + DENDRO_190) + DENDRO_177*(DENDRO_173*DENDRO_179 + 0.5*DENDRO_193 + DENDRO_417*DENDRO_72) - DENDRO_207*(DENDRO_121*DENDRO_770 + DENDRO_199*DENDRO_771 + DENDRO_269*DENDRO_772 + DENDRO_683) - DENDRO_280*DENDRO_51 - DENDRO_304*gt1[pp] + DENDRO_323*(-DENDRO_701 + DENDRO_702) - DENDRO_323*(-DENDRO_124*DENDRO_154 + DENDRO_717 + DENDRO_761) - DENDRO_323*(-DENDRO_173*DENDRO_324 + DENDRO_721 + DENDRO_768) + DENDRO_685 + DENDRO_686 + DENDRO_687 + DENDRO_688 + DENDRO_689 + DENDRO_690 + DENDRO_691 + DENDRO_692 + DENDRO_693 + DENDRO_694 + DENDRO_695 + DENDRO_696 + DENDRO_697 + DENDRO_699 + DENDRO_700 + DENDRO_704 + DENDRO_706 + DENDRO_710 + DENDRO_714 - DENDRO_751*(DENDRO_117*DENDRO_147 + DENDRO_756) - DENDRO_751*(DENDRO_173*DENDRO_216 + DENDRO_183*DENDRO_218 + DENDRO_753))) - alpha[pp]*(-At1[pp]*K[pp] + DENDRO_20*DENDRO_745 + DENDRO_27*DENDRO_746 + DENDRO_32*DENDRO_747) + beta0[pp]*agrad_0_At1[pp] + beta1[pp]*agrad_1_At1[pp] + beta2[pp]*agrad_2_At1[pp];
		   At_rhs02[pp] = At0[pp]*DENDRO_773 + At1[pp]*DENDRO_774 - At2[pp]*DENDRO_776 + At4[pp]*DENDRO_5 + At5[pp]*DENDRO_7 + DENDRO_0*DENDRO_775 + DENDRO_3*DENDRO_775 + DENDRO_34*(-12*DENDRO_457 + 6.0*DENDRO_458 + DENDRO_739*gt2[pp] - DENDRO_750*(DENDRO_467 + DENDRO_468 - DENDRO_469 - DENDRO_471) - DENDRO_780*(DENDRO_460 + DENDRO_461 - DENDRO_462 - DENDRO_465) + DENDRO_87*(DENDRO_101*DENDRO_26*(DENDRO_756 + DENDRO_786) + DENDRO_102*(DENDRO_534 - DENDRO_558) - DENDRO_102*(-DENDRO_147*DENDRO_160 - DENDRO_49*DENDRO_791 + DENDRO_790) - DENDRO_106*DENDRO_244 - DENDRO_123*(-DENDRO_553 + DENDRO_554 + DENDRO_580) + DENDRO_123*(DENDRO_365*DENDRO_752 + DENDRO_783 - DENDRO_784) - DENDRO_123*(DENDRO_525*DENDRO_789 + DENDRO_782 + DENDRO_784) + DENDRO_123*(-DENDRO_54*DENDRO_791 + DENDRO_792 - 0.25*DENDRO_793) + DENDRO_128*(DENDRO_110*DENDRO_159 + DENDRO_148) - DENDRO_129*(-DENDRO_147*DENDRO_205 + DENDRO_159*DENDRO_198 - DENDRO_520*DENDRO_791) - DENDRO_129*(DENDRO_183*DENDRO_365 - DENDRO_787 - DENDRO_788) + DENDRO_129*(DENDRO_49*DENDRO_789 + DENDRO_787 + DENDRO_788) - DENDRO_134*(0.25*DENDRO_192 + DENDRO_785) - DENDRO_134*(DENDRO_762 + DENDRO_785) - DENDRO_134*(DENDRO_767 + DENDRO_794) - DENDRO_134*(DENDRO_159*DENDRO_531 + DENDRO_765) - DENDRO_161*DENDRO_261 + DENDRO_177*(DENDRO_179*DENDRO_183 + 1.0*DENDRO_184) + DENDRO_177*(DENDRO_159*DENDRO_49 + DENDRO_159*DENDRO_50 + DENDRO_189) - DENDRO_207*(DENDRO_113*DENDRO_770 + DENDRO_167*DENDRO_771 + DENDRO_262*DENDRO_772 + DENDRO_473) - DENDRO_280*DENDRO_46 - DENDRO_304*gt2[pp] + DENDRO_323*(DENDRO_173*DENDRO_226 + 0.25*DENDRO_753) + DENDRO_479 + DENDRO_481 + DENDRO_483 + DENDRO_484 + DENDRO_486 + DENDRO_488 + DENDRO_490 + DENDRO_491 + DENDRO_492 + DENDRO_493 + DENDRO_494 + DENDRO_495 + DENDRO_496 + DENDRO_562 + DENDRO_569 + DENDRO_574 + DENDRO_576 + DENDRO_577 + DENDRO_582 + DENDRO_583 + DENDRO_584 - DENDRO_751*(DENDRO_758 + DENDRO_781))) - alpha[pp]*(-At2[pp]*K[pp] + DENDRO_20*DENDRO_777 + DENDRO_27*DENDRO_778 + DENDRO_32*DENDRO_779) + beta0[pp]*agrad_0_At2[pp] + beta1[pp]*agrad_1_At2[pp] + beta2[pp]*agrad_2_At2[pp];
		   At_rhs11[pp] = (4.0L/3.0L)*At3[pp]*DENDRO_2 - At3[pp]*DENDRO_743 - At3[pp]*DENDRO_795 + DENDRO_34*(12*DENDRO_36*(DENDRO_37*(DENDRO_387 + DENDRO_388*DENDRO_749) + DENDRO_390) - 12*DENDRO_384 + DENDRO_60*(DENDRO_258 - DENDRO_386*(DENDRO_316 - DENDRO_61)) + DENDRO_739*gt3[pp] + DENDRO_799*(DENDRO_277 - DENDRO_386*(-DENDRO_309 + DENDRO_84)) + DENDRO_87*(DENDRO_101*DENDRO_26*DENDRO_399*DENDRO_760 + DENDRO_115*(DENDRO_408 - DENDRO_801) + DENDRO_115*(-DENDRO_117*DENDRO_154 + DENDRO_411) + DENDRO_115*(-DENDRO_173*DENDRO_218 + DENDRO_420) - DENDRO_117*DENDRO_280 + DENDRO_123*(DENDRO_412 - 1.0*DENDRO_800) - DENDRO_123*(DENDRO_427 - 1.0*DENDRO_429) - DENDRO_123*(DENDRO_430*DENDRO_752 + DENDRO_432) + DENDRO_129*(DENDRO_423 - DENDRO_425) + DENDRO_129*(DENDRO_130*DENDRO_754 + DENDRO_154*DENDRO_417) + DENDRO_129*(DENDRO_417*DENDRO_752 + DENDRO_802) + DENDRO_129*(DENDRO_55*DENDRO_803 + DENDRO_804) + DENDRO_134*(DENDRO_413 - 1.0*DENDRO_801) + DENDRO_134*(DENDRO_434 + DENDRO_761) + DENDRO_134*(DENDRO_436 + DENDRO_768) + DENDRO_154*DENDRO_401 + DENDRO_173*DENDRO_404 - DENDRO_207*(DENDRO_210*DENDRO_258 + DENDRO_212*DENDRO_241 + DENDRO_213*DENDRO_277 + DENDRO_437) - DENDRO_218*DENDRO_261 - DENDRO_233*DENDRO_244 - DENDRO_304*gt3[pp] + DENDRO_328*(DENDRO_406 - DENDRO_800) + DENDRO_328*(-DENDRO_117*DENDRO_754 + DENDRO_419) + DENDRO_328*(-DENDRO_218*DENDRO_752 + DENDRO_410) + DENDRO_398 + DENDRO_400*(DENDRO_229 + DENDRO_335) + DENDRO_403*DENDRO_754 + DENDRO_405*(DENDRO_139 + DENDRO_438))) + DENDRO_4*DENDRO_740 + DENDRO_741*DENDRO_796 - alpha[pp]*(-At3[pp]*K[pp] + DENDRO_20*DENDRO_746 + DENDRO_745*DENDRO_797 + DENDRO_747*DENDRO_798) + beta0[pp]*agrad_0_At3[pp] + beta1[pp]*agrad_1_At3[pp] + beta2[pp]*agrad_2_At3[pp];
		   At_rhs12[pp] = At1[pp]*DENDRO_773 + At2[pp]*DENDRO_740 + At3[pp]*DENDRO_774 - At4[pp]*DENDRO_795 + At5[pp]*DENDRO_741 + DENDRO_2*DENDRO_805 + DENDRO_3*DENDRO_805 + DENDRO_34*(-12*DENDRO_585 - DENDRO_586*(6.0*DENDRO_126*DENDRO_31 + 6.0*DENDRO_216*DENDRO_29 - 6.0*DENDRO_218*DENDRO_23 - 6.0*DENDRO_310*DENDRO_37*gt4[pp]) + DENDRO_739*gt4[pp] + DENDRO_748*(DENDRO_37*(DENDRO_470 + DENDRO_749*gt4[pp]) + DENDRO_589) - DENDRO_780*(-DENDRO_590 + DENDRO_591 + DENDRO_592 - DENDRO_594) + DENDRO_87*(DENDRO_101*DENDRO_29*(DENDRO_759 + DENDRO_781) + DENDRO_102*(DENDRO_632 - DENDRO_655) - DENDRO_102*(-DENDRO_160*DENDRO_754 + DENDRO_365*DENDRO_754 - DENDRO_417*DENDRO_791) - DENDRO_103*DENDRO_280 + DENDRO_123*(DENDRO_230*DENDRO_760 + DENDRO_671) + DENDRO_123*(-DENDRO_237*DENDRO_789 + DENDRO_808) + DENDRO_123*(DENDRO_336*DENDRO_752 + DENDRO_808) - DENDRO_123*(DENDRO_119*DENDRO_809 + DENDRO_136*DENDRO_791 + DENDRO_672) + DENDRO_123*(-DENDRO_126*DENDRO_809 - DENDRO_627*DENDRO_754 + DENDRO_649) - DENDRO_129*(DENDRO_183*DENDRO_336 + DENDRO_783 - DENDRO_806) - DENDRO_129*(-DENDRO_205*DENDRO_754 - DENDRO_55*DENDRO_791 + DENDRO_792) + DENDRO_129*(DENDRO_417*DENDRO_789 + DENDRO_782 + DENDRO_806) + DENDRO_134*(-DENDRO_183*DENDRO_324 + DENDRO_807) + DENDRO_134*(-DENDRO_531*DENDRO_760 + DENDRO_665) + DENDRO_134*(-DENDRO_627*DENDRO_752 + DENDRO_807) + DENDRO_134*(-DENDRO_124*DENDRO_147 + DENDRO_667 - 0.25*DENDRO_786) + DENDRO_134*(-DENDRO_132*DENDRO_754 + DENDRO_647 - DENDRO_804) + DENDRO_134*(-DENDRO_417*DENDRO_760 + DENDRO_518 + DENDRO_616) + DENDRO_177*(DENDRO_173*DENDRO_197 + DENDRO_764) + DENDRO_177*(DENDRO_180 + DENDRO_766 + DENDRO_794) - DENDRO_207*(DENDRO_221*DENDRO_770 + DENDRO_249*DENDRO_771 + DENDRO_267*DENDRO_772 + DENDRO_596) - DENDRO_227*DENDRO_261 - DENDRO_235*DENDRO_244 - DENDRO_304*gt4[pp] - DENDRO_323*(-DENDRO_324*DENDRO_752 + DENDRO_653) - DENDRO_323*(-DENDRO_124*DENDRO_754 + DENDRO_642 + DENDRO_673) - DENDRO_323*(-DENDRO_237*DENDRO_760 - DENDRO_238*DENDRO_760 + DENDRO_412) + DENDRO_328*(-DENDRO_216*DENDRO_760 + DENDRO_394) + DENDRO_600 + DENDRO_601 + DENDRO_603 + DENDRO_604 + DENDRO_605 + DENDRO_606 + DENDRO_607 + DENDRO_608 + DENDRO_609 + DENDRO_610 + DENDRO_611 + DENDRO_612 + DENDRO_613 + DENDRO_657 + DENDRO_662 + DENDRO_663 + DENDRO_669)) - alpha[pp]*(-At4[pp]*K[pp] + DENDRO_20*DENDRO_778 + DENDRO_777*DENDRO_797 + DENDRO_779*DENDRO_798) + beta0[pp]*agrad_0_At4[pp] + beta1[pp]*agrad_1_At4[pp] + beta2[pp]*agrad_2_At4[pp];
		   At_rhs22[pp] = (4.0L/3.0L)*At5[pp]*DENDRO_3 - At5[pp]*DENDRO_776 - At5[pp]*DENDRO_795 + DENDRO_34*(-12*DENDRO_305 + 12*DENDRO_306 - 12*DENDRO_59*(DENDRO_312 - DENDRO_313 + DENDRO_314 - DENDRO_318) + DENDRO_739*gt5[pp] - DENDRO_799*(-DENDRO_311 + DENDRO_791) + DENDRO_87*(DENDRO_110*DENDRO_183*DENDRO_340 - DENDRO_110*DENDRO_280 - DENDRO_123*(DENDRO_366 - 1.0*DENDRO_368) - DENDRO_123*(0.25*DENDRO_810 + 1.0*DENDRO_811) + DENDRO_128*(DENDRO_812 + DENDRO_813) + DENDRO_128*(DENDRO_110*DENDRO_147 + DENDRO_48*DENDRO_791) + DENDRO_129*(DENDRO_362 - 1.0*DENDRO_364) + DENDRO_129*(0.25*DENDRO_812 + 1.0*DENDRO_813) - DENDRO_129*(-DENDRO_370*DENDRO_791 + DENDRO_790) - DENDRO_134*(DENDRO_179*DENDRO_754 + 0.5*DENDRO_793) - DENDRO_134*(DENDRO_183*DENDRO_226 + DENDRO_806) - DENDRO_134*(DENDRO_197*DENDRO_752 + DENDRO_784) - DENDRO_134*(DENDRO_50*DENDRO_803 + 0.25*DENDRO_758) + DENDRO_147*DENDRO_343 + DENDRO_149*DENDRO_216*DENDRO_752 - DENDRO_207*(DENDRO_210*DENDRO_255 + DENDRO_212*DENDRO_231 + DENDRO_213*DENDRO_274 + DENDRO_371) - DENDRO_216*DENDRO_244 - DENDRO_224*DENDRO_261 - DENDRO_304*gt5[pp] - DENDRO_328*(DENDRO_810 + DENDRO_811) - DENDRO_328*(DENDRO_110*DENDRO_754 + DENDRO_126*DENDRO_791) + DENDRO_33*DENDRO_342*DENDRO_789 + DENDRO_338 + DENDRO_344*DENDRO_754 + DENDRO_345*(DENDRO_163 + DENDRO_375) + DENDRO_346*(DENDRO_229 + DENDRO_373))) + DENDRO_6*DENDRO_773 + DENDRO_774*DENDRO_796 - alpha[pp]*(At5[pp]*DENDRO_297*DENDRO_779 - At5[pp]*K[pp] + DENDRO_32*DENDRO_778 + DENDRO_777*DENDRO_798) + beta0[pp]*agrad_0_At5[pp] + beta1[pp]*agrad_1_At5[pp] + beta2[pp]*agrad_2_At5[pp];
			      // Dendro: reduced ops: 3569
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(At_rhs12, &__unzipOutVar[cuda::VAR::U_SYMAT4][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(At_rhs11, &__unzipOutVar[cuda::VAR::U_SYMAT3][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(At_rhs22, &__unzipOutVar[cuda::VAR::U_SYMAT5][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(At_rhs02, &__unzipOutVar[cuda::VAR::U_SYMAT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(At_rhs00, &__unzipOutVar[cuda::VAR::U_SYMAT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(At_rhs01, &__unzipOutVar[cuda::VAR::U_SYMAT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_At_rhs 

/**@brief compute K_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_K_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for K_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={4,4,4};
	
	 //input vars begin
	double * K = __sm_base + 0;
	double * gt1 = __sm_base + 64;
	double * beta1 = __sm_base + 128;
	double * gt3 = __sm_base + 192;
	double * At1 = __sm_base + 256;
	double * gt5 = __sm_base + 320;
	double * alpha = __sm_base + 384;
	double * gt4 = __sm_base + 448;
	double * gt2 = __sm_base + 512;
	double * At3 = __sm_base + 576;
	double * beta2 = __sm_base + 640;
	double * At4 = __sm_base + 704;
	double * At0 = __sm_base + 768;
	double * At2 = __sm_base + 832;
	double * beta0 = __sm_base + 896;
	double * gt0 = __sm_base + 960;
	double * chi = __sm_base + 1024;
	double * At5 = __sm_base + 1088;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * grad_0_gt5 = __sm_base + 1152;
	double * grad_1_gt0 = __sm_base + 1216;
	double * grad2_0_1_alpha = __sm_base + 1280;
	double * grad2_2_2_alpha = __sm_base + 1344;
	double * grad_2_gt0 = __sm_base + 1408;
	double * grad_0_gt4 = __sm_base + 1472;
	double * grad_2_gt3 = __sm_base + 1536;
	double * grad_1_alpha = __sm_base + 1600;
	double * grad_2_alpha = __sm_base + 1664;
	double * grad2_1_1_alpha = __sm_base + 1728;
	double * grad_1_gt5 = __sm_base + 1792;
	double * grad_0_gt1 = __sm_base + 1856;
	double * grad_1_gt4 = __sm_base + 1920;
	double * agrad_2_K = __sm_base + 1984;
	double * grad_1_gt1 = __sm_base + 2048;
	double * grad_2_gt4 = __sm_base + 2112;
	double * grad_0_alpha = __sm_base + 2176;
	double * grad_0_chi = __sm_base + 2240;
	double * grad2_0_0_alpha = __sm_base + 2304;
	double * agrad_1_K = __sm_base + 2368;
	double * grad_2_gt2 = __sm_base + 2432;
	double * grad_1_chi = __sm_base + 2496;
	double * grad_0_gt0 = __sm_base + 2560;
	double * grad_0_gt3 = __sm_base + 2624;
	double * grad2_1_2_alpha = __sm_base + 2688;
	double * grad_2_gt5 = __sm_base + 2752;
	double * agrad_0_K = __sm_base + 2816;
	double * grad_1_gt3 = __sm_base + 2880;
	double * grad_2_chi = __sm_base + 2944;
	double * grad_2_gt1 = __sm_base + 3008;
	double * grad_0_gt2 = __sm_base + 3072;
	double * grad2_0_2_alpha = __sm_base + 3136;
	double * grad_1_gt2 = __sm_base + 3200;
	 // deriv vars end
	 // output vars begin
	double * K_rhs = __sm_base + 3264;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 3960
			     // Dendro: printing temp variables
		 const double DENDRO_0 = pow(gt4[pp], 2);
		 const double DENDRO_1 = DENDRO_0*gt0[pp];
		 const double DENDRO_2 = pow(gt1[pp], 2);
		 const double DENDRO_3 = DENDRO_2*gt5[pp];
		 const double DENDRO_4 = pow(gt2[pp], 2);
		 const double DENDRO_5 = DENDRO_4*gt3[pp];
		 const double DENDRO_6 = gt0[pp]*gt3[pp];
		 const double DENDRO_7 = DENDRO_6*gt5[pp];
		 const double DENDRO_8 = gt1[pp]*gt2[pp];
		 const double DENDRO_9 = 2*DENDRO_8*gt4[pp];
		 const double DENDRO_10 = DENDRO_1 + DENDRO_3 + DENDRO_5 - DENDRO_7 - DENDRO_9;
		 const double DENDRO_11 = 1.0/DENDRO_10;
		 const double DENDRO_12 = DENDRO_11*chi[pp];
		 const double DENDRO_13 = -DENDRO_2 + DENDRO_6;
		 const double DENDRO_14 = grad_1_alpha[pp];
		 const double DENDRO_15 = 1.0/(-DENDRO_1 - DENDRO_3 - DENDRO_5 + DENDRO_7 + DENDRO_9);
		 const double DENDRO_16 = DENDRO_14*DENDRO_15;
		 const double DENDRO_17 = grad_2_gt5[pp];
		 const double DENDRO_18 = -0.5*gt0[pp]*gt4[pp] + 0.5*gt1[pp]*gt2[pp];
		 const double DENDRO_19 = gt2[pp]*gt4[pp];
		 const double DENDRO_20 = gt1[pp]*gt5[pp];
		 const double DENDRO_21 = DENDRO_19 - DENDRO_20;
		 const double DENDRO_22 = grad_0_gt5[pp];
		 const double DENDRO_23 = -0.5*DENDRO_22 + 1.0*grad_2_gt2[pp];
		 const double DENDRO_24 = -DENDRO_4 + gt0[pp]*gt5[pp];
		 const double DENDRO_25 = grad_1_gt5[pp];
		 const double DENDRO_26 = -0.5*DENDRO_25 + 1.0*grad_2_gt4[pp];
		 const double DENDRO_27 = 0.5*gt5[pp];
		 const double DENDRO_28 = 1.0/chi[pp];
		 const double DENDRO_29 = grad_2_chi[pp];
		 const double DENDRO_30 = gt0[pp]*gt4[pp];
		 const double DENDRO_31 = -DENDRO_30 + DENDRO_8;
		 const double DENDRO_32 = grad_0_chi[pp];
		 const double DENDRO_33 = grad_1_chi[pp];
		 const double DENDRO_34 = DENDRO_21*DENDRO_32 + DENDRO_24*DENDRO_33 + DENDRO_29*DENDRO_31;
		 const double DENDRO_35 = DENDRO_28*DENDRO_34;
		 const double DENDRO_36 = grad_0_alpha[pp];
		 const double DENDRO_37 = DENDRO_15*DENDRO_36;
		 const double DENDRO_38 = 0.5*gt1[pp]*gt4[pp] - 0.5*gt2[pp]*gt3[pp];
		 const double DENDRO_39 = -DENDRO_0 + gt3[pp]*gt5[pp];
		 const double DENDRO_40 = gt1[pp]*gt4[pp] - gt2[pp]*gt3[pp];
		 const double DENDRO_41 = DENDRO_21*DENDRO_33 + DENDRO_29*DENDRO_40 + DENDRO_32*DENDRO_39;
		 const double DENDRO_42 = DENDRO_28*DENDRO_41;
		 const double DENDRO_43 = grad_2_alpha[pp];
		 const double DENDRO_44 = DENDRO_13*DENDRO_15;
		 const double DENDRO_45 = DENDRO_15*DENDRO_31;
		 const double DENDRO_46 = DENDRO_15*DENDRO_40;
		 const double DENDRO_47 = DENDRO_13*DENDRO_29 + DENDRO_31*DENDRO_33 + DENDRO_32*DENDRO_40;
		 const double DENDRO_48 = DENDRO_15*DENDRO_43;
		 const double DENDRO_49 = grad_1_gt3[pp];
		 const double DENDRO_50 = grad_0_gt3[pp];
		 const double DENDRO_51 = -0.5*DENDRO_50 + 1.0*grad_1_gt1[pp];
		 const double DENDRO_52 = grad_2_gt3[pp];
		 const double DENDRO_53 = -0.5*DENDRO_52 + 1.0*grad_1_gt4[pp];
		 const double DENDRO_54 = 0.5*gt3[pp];
		 const double DENDRO_55 = DENDRO_28*DENDRO_47;
		 const double DENDRO_56 = -0.5*gt1[pp]*gt5[pp] + 0.5*gt2[pp]*gt4[pp];
		 const double DENDRO_57 = DENDRO_15*DENDRO_24;
		 const double DENDRO_58 = DENDRO_15*DENDRO_21;
		 const double DENDRO_59 = grad_0_gt0[pp];
		 const double DENDRO_60 = grad_1_gt0[pp];
		 const double DENDRO_61 = -0.5*DENDRO_60 + 1.0*grad_0_gt1[pp];
		 const double DENDRO_62 = grad_2_gt0[pp];
		 const double DENDRO_63 = -0.5*DENDRO_62 + 1.0*grad_0_gt2[pp];
		 const double DENDRO_64 = 0.5*gt0[pp];
		 const double DENDRO_65 = DENDRO_15*DENDRO_39;
		 const double DENDRO_66 = 2*DENDRO_11*chi[pp];
		 const double DENDRO_67 = DENDRO_30 - DENDRO_8;
		 const double DENDRO_68 = 0.5*DENDRO_15;
		 const double DENDRO_69 = grad_1_gt2[pp];
		 const double DENDRO_70 = grad_2_gt1[pp];
		 const double DENDRO_71 = grad_0_gt4[pp];
		 const double DENDRO_72 = DENDRO_69 + DENDRO_70 - DENDRO_71;
		 const double DENDRO_73 = 0.5*DENDRO_43;
		 const double DENDRO_74 = DENDRO_15*gt4[pp];
		 const double DENDRO_75 = 0.5*DENDRO_14;
		 const double DENDRO_76 = -DENDRO_69 + DENDRO_70 + DENDRO_71;
		 const double DENDRO_77 = DENDRO_15*gt2[pp];
		 const double DENDRO_78 = 0.5*DENDRO_36;
		 const double DENDRO_79 = -DENDRO_19 + DENDRO_20;
		 const double DENDRO_80 = DENDRO_69 - DENDRO_70 + DENDRO_71;
		 const double DENDRO_81 = DENDRO_15*gt1[pp];
		 const double DENDRO_82 = pow(DENDRO_10, -2);
		 const double DENDRO_83 = 3*DENDRO_82;
		 const double DENDRO_84 = pow(DENDRO_79, 2);
		 const double DENDRO_85 = pow(DENDRO_40, 2);
		 const double DENDRO_86 = DENDRO_40*DENDRO_79;
		 const double DENDRO_87 = 2*At1[pp]*DENDRO_79;
		 const double DENDRO_88 = 2*At2[pp]*DENDRO_40;
		 const double DENDRO_89 = pow(DENDRO_67, 2);
		 const double DENDRO_90 = DENDRO_67*DENDRO_79;
		 const double DENDRO_91 = 2*At4[pp]*DENDRO_67;
		 const double DENDRO_92 = DENDRO_40*DENDRO_67;
		 const double DENDRO_93 = 6*DENDRO_82;
		 const double DENDRO_94 = At0[pp]*DENDRO_39;
		 const double DENDRO_95 = At5[pp]*DENDRO_13;
		 const double DENDRO_96 = DENDRO_39*DENDRO_67;
		 const double DENDRO_97 = DENDRO_13*DENDRO_79;
		 const double DENDRO_98 = DENDRO_24*DENDRO_40;
		 const double DENDRO_99 = At3[pp]*DENDRO_24;
			      // Dendro: printing variables

		   K_rhs[pp] = -DENDRO_12*DENDRO_13*(DENDRO_16*(DENDRO_17*DENDRO_18 + DENDRO_21*DENDRO_23 + DENDRO_24*DENDRO_26 + DENDRO_27*DENDRO_35) + DENDRO_37*(DENDRO_17*DENDRO_38 + DENDRO_21*DENDRO_26 + DENDRO_23*DENDRO_39 + DENDRO_27*DENDRO_42) + DENDRO_43*(0.5*DENDRO_17*DENDRO_44 + DENDRO_23*DENDRO_46 + DENDRO_26*DENDRO_45 - DENDRO_28*(-DENDRO_15*DENDRO_27*DENDRO_47 + 1.0*DENDRO_29)) - grad2_2_2_alpha[pp]) - DENDRO_12*DENDRO_24*(DENDRO_14*(-DENDRO_28*(-DENDRO_15*DENDRO_34*DENDRO_54 + 1.0*DENDRO_33) + DENDRO_45*DENDRO_53 + 0.5*DENDRO_49*DENDRO_57 + DENDRO_51*DENDRO_58) + DENDRO_37*(DENDRO_39*DENDRO_51 + DENDRO_40*DENDRO_53 + DENDRO_42*DENDRO_54 + DENDRO_49*DENDRO_56) + DENDRO_48*(DENDRO_13*DENDRO_53 + DENDRO_18*DENDRO_49 + DENDRO_40*DENDRO_51 + DENDRO_54*DENDRO_55) - grad2_1_1_alpha[pp]) - DENDRO_12*DENDRO_39*(DENDRO_16*(DENDRO_24*DENDRO_61 + DENDRO_31*DENDRO_63 + DENDRO_35*DENDRO_64 + DENDRO_56*DENDRO_59) + DENDRO_36*(-DENDRO_28*(-DENDRO_15*DENDRO_41*DENDRO_64 + 1.0*DENDRO_32) + DENDRO_46*DENDRO_63 + DENDRO_58*DENDRO_61 + 0.5*DENDRO_59*DENDRO_65) + DENDRO_48*(DENDRO_13*DENDRO_63 + DENDRO_31*DENDRO_61 + DENDRO_38*DENDRO_59 + DENDRO_55*DENDRO_64) - grad2_0_0_alpha[pp]) - DENDRO_40*DENDRO_66*(DENDRO_14*DENDRO_68*(DENDRO_21*DENDRO_62 + DENDRO_22*DENDRO_31 + DENDRO_24*DENDRO_76 + DENDRO_35*gt2[pp]) + DENDRO_73*(DENDRO_22*DENDRO_44 - DENDRO_28*(DENDRO_32 - DENDRO_47*DENDRO_77) + DENDRO_45*DENDRO_76 + DENDRO_46*DENDRO_62) + DENDRO_78*(DENDRO_22*DENDRO_46 - DENDRO_28*(DENDRO_29 - DENDRO_41*DENDRO_77) + DENDRO_58*DENDRO_76 + DENDRO_62*DENDRO_65) - grad2_0_2_alpha[pp]) + DENDRO_66*DENDRO_67*(DENDRO_36*DENDRO_68*(DENDRO_21*DENDRO_52 + DENDRO_25*DENDRO_40 + DENDRO_39*DENDRO_72 + DENDRO_42*gt4[pp]) + DENDRO_73*(DENDRO_25*DENDRO_44 - DENDRO_28*(DENDRO_33 - DENDRO_47*DENDRO_74) + DENDRO_45*DENDRO_52 + DENDRO_46*DENDRO_72) + DENDRO_75*(DENDRO_25*DENDRO_45 - DENDRO_28*(DENDRO_29 - DENDRO_34*DENDRO_74) + DENDRO_52*DENDRO_57 + DENDRO_58*DENDRO_72) - grad2_1_2_alpha[pp]) + DENDRO_66*DENDRO_79*(DENDRO_43*DENDRO_68*(DENDRO_13*DENDRO_80 + DENDRO_31*DENDRO_50 + DENDRO_40*DENDRO_60 + DENDRO_55*gt1[pp]) + DENDRO_75*(-DENDRO_28*(DENDRO_32 - DENDRO_34*DENDRO_81) + DENDRO_45*DENDRO_80 + DENDRO_50*DENDRO_57 + DENDRO_58*DENDRO_60) + DENDRO_78*(-DENDRO_28*(DENDRO_33 - DENDRO_41*DENDRO_81) + DENDRO_46*DENDRO_80 + DENDRO_50*DENDRO_58 + DENDRO_60*DENDRO_65) - grad2_0_1_alpha[pp]) + (1.0L/3.0L)*alpha[pp]*(At0[pp]*DENDRO_83*(At0[pp]*pow(DENDRO_39, 2) + At3[pp]*DENDRO_84 - 2*At4[pp]*DENDRO_86 + At5[pp]*DENDRO_85 - DENDRO_39*DENDRO_87 + DENDRO_39*DENDRO_88) + At1[pp]*DENDRO_93*(At1[pp]*DENDRO_24*DENDRO_39 + At1[pp]*DENDRO_84 - At2[pp]*DENDRO_86 - At2[pp]*DENDRO_96 + At4[pp]*DENDRO_90 + At4[pp]*DENDRO_98 - At5[pp]*DENDRO_92 - DENDRO_79*DENDRO_94 - DENDRO_79*DENDRO_99) + At2[pp]*DENDRO_93*(-At1[pp]*DENDRO_86 - At1[pp]*DENDRO_96 + At2[pp]*DENDRO_13*DENDRO_39 + At2[pp]*DENDRO_85 + At3[pp]*DENDRO_90 - At4[pp]*DENDRO_92 - At4[pp]*DENDRO_97 + DENDRO_40*DENDRO_94 + DENDRO_40*DENDRO_95) + At3[pp]*DENDRO_83*(At0[pp]*DENDRO_84 + 2*At2[pp]*DENDRO_90 + At3[pp]*pow(DENDRO_24, 2) + At5[pp]*DENDRO_89 - DENDRO_24*DENDRO_87 - DENDRO_24*DENDRO_91) + At4[pp]*DENDRO_93*(-At0[pp]*DENDRO_86 + At1[pp]*DENDRO_90 + At1[pp]*DENDRO_98 - At2[pp]*DENDRO_92 - At2[pp]*DENDRO_97 + At4[pp]*DENDRO_13*DENDRO_24 + At4[pp]*DENDRO_89 - DENDRO_67*DENDRO_95 - DENDRO_67*DENDRO_99) + At5[pp]*DENDRO_83*(At0[pp]*DENDRO_85 - 2*At1[pp]*DENDRO_92 + At3[pp]*DENDRO_89 + At5[pp]*pow(DENDRO_13, 2) + DENDRO_13*DENDRO_88 - DENDRO_13*DENDRO_91) + pow(K[pp], 2)) + beta0[pp]*agrad_0_K[pp] + beta1[pp]*agrad_1_K[pp] + beta2[pp]*agrad_2_K[pp];
			      // Dendro: reduced ops: 501
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(K_rhs, &__unzipOutVar[cuda::VAR::U_K][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_K_rhs 

/**@brief compute Gt_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_Gt_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for Gt_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={3,3,3};
	
	 //input vars begin
	double * gt1 = __sm_base + 0;
	double * beta1 = __sm_base + 27;
	double * gt3 = __sm_base + 54;
	double * At1 = __sm_base + 81;
	double * gt5 = __sm_base + 108;
	double * alpha = __sm_base + 135;
	double * gt4 = __sm_base + 162;
	double * gt2 = __sm_base + 189;
	double * At3 = __sm_base + 216;
	double * beta2 = __sm_base + 243;
	double * At4 = __sm_base + 270;
	double * At0 = __sm_base + 297;
	double * At2 = __sm_base + 324;
	double * beta0 = __sm_base + 351;
	double * gt0 = __sm_base + 378;
	double * chi = __sm_base + 405;
	double * At5 = __sm_base + 432;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * grad_0_gt5 = __sm_base + 459;
	double * grad_1_gt0 = __sm_base + 486;
	double * grad2_1_2_beta2 = __sm_base + 513;
	double * grad_2_K = __sm_base + 540;
	double * grad_0_beta0 = __sm_base + 567;
	double * grad_2_gt0 = __sm_base + 594;
	double * grad_0_gt4 = __sm_base + 621;
	double * grad2_1_1_beta1 = __sm_base + 648;
	double * grad_2_gt3 = __sm_base + 675;
	double * grad2_0_1_beta0 = __sm_base + 702;
	double * grad2_0_0_beta1 = __sm_base + 729;
	double * grad_1_K = __sm_base + 756;
	double * grad_1_alpha = __sm_base + 783;
	double * grad2_0_2_beta1 = __sm_base + 810;
	double * grad2_0_1_beta1 = __sm_base + 837;
	double * grad2_2_2_beta2 = __sm_base + 864;
	double * grad_1_beta1 = __sm_base + 891;
	double * grad_2_alpha = __sm_base + 918;
	double * grad_2_beta0 = __sm_base + 945;
	double * grad_0_gt1 = __sm_base + 972;
	double * grad_1_gt5 = __sm_base + 999;
	double * agrad_2_Gt1 = __sm_base + 1026;
	double * agrad_0_Gt2 = __sm_base + 1053;
	double * grad2_1_1_beta2 = __sm_base + 1080;
	double * grad_1_gt4 = __sm_base + 1107;
	double * grad2_2_2_beta1 = __sm_base + 1134;
	double * grad_1_gt1 = __sm_base + 1161;
	double * grad_2_gt4 = __sm_base + 1188;
	double * grad_0_beta1 = __sm_base + 1215;
	double * grad_0_alpha = __sm_base + 1242;
	double * grad_0_chi = __sm_base + 1269;
	double * grad_2_beta2 = __sm_base + 1296;
	double * grad2_1_2_beta0 = __sm_base + 1323;
	double * grad2_1_1_beta0 = __sm_base + 1350;
	double * agrad_0_Gt1 = __sm_base + 1377;
	double * grad_0_K = __sm_base + 1404;
	double * grad2_0_2_beta2 = __sm_base + 1431;
	double * agrad_0_Gt0 = __sm_base + 1458;
	double * agrad_1_Gt1 = __sm_base + 1485;
	double * grad2_0_0_beta0 = __sm_base + 1512;
	double * agrad_1_Gt2 = __sm_base + 1539;
	double * agrad_1_Gt0 = __sm_base + 1566;
	double * grad_2_gt2 = __sm_base + 1593;
	double * grad_1_chi = __sm_base + 1620;
	double * grad_0_gt0 = __sm_base + 1647;
	double * grad_0_gt3 = __sm_base + 1674;
	double * grad2_2_2_beta0 = __sm_base + 1701;
	double * agrad_2_Gt2 = __sm_base + 1728;
	double * grad_2_beta1 = __sm_base + 1755;
	double * grad_2_gt5 = __sm_base + 1782;
	double * grad_1_beta0 = __sm_base + 1809;
	double * grad2_0_1_beta2 = __sm_base + 1836;
	double * grad_1_gt3 = __sm_base + 1863;
	double * grad2_0_2_beta0 = __sm_base + 1890;
	double * grad_2_chi = __sm_base + 1917;
	double * grad_2_gt1 = __sm_base + 1944;
	double * agrad_2_Gt0 = __sm_base + 1971;
	double * grad_0_gt2 = __sm_base + 1998;
	double * grad_0_beta2 = __sm_base + 2025;
	double * grad_1_beta2 = __sm_base + 2052;
	double * grad2_0_0_beta2 = __sm_base + 2079;
	double * grad_1_gt2 = __sm_base + 2106;
	double * grad2_1_2_beta1 = __sm_base + 2133;
	 // deriv vars end
	 // output vars begin
	double * Gt_rhs0 = __sm_base + 2160;
	double * Gt_rhs2 = __sm_base + 2187;
	double * Gt_rhs1 = __sm_base + 2214;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 16710
			     // Dendro: printing temp variables
		 const double DENDRO_0 = gt1[pp]*gt2[pp];
		 const double DENDRO_1 = -DENDRO_0 + gt0[pp]*gt4[pp];
		 const double DENDRO_2 = pow(gt4[pp], 2);
		 const double DENDRO_3 = pow(gt1[pp], 2);
		 const double DENDRO_4 = pow(gt2[pp], 2);
		 const double DENDRO_5 = gt0[pp]*gt3[pp];
		 const double DENDRO_6 = -2*DENDRO_0*gt4[pp] + DENDRO_2*gt0[pp] + DENDRO_3*gt5[pp] + DENDRO_4*gt3[pp] - DENDRO_5*gt5[pp];
		 const double DENDRO_7 = 1.0/DENDRO_6;
		 const double DENDRO_8 = grad2_0_2_beta0[pp];
		 const double DENDRO_9 = gt1[pp]*gt4[pp] - gt2[pp]*gt3[pp];
		 const double DENDRO_10 = (7.0L/3.0L)*DENDRO_7*DENDRO_9;
		 const double DENDRO_11 = grad2_1_2_beta1[pp];
		 const double DENDRO_12 = (1.0L/3.0L)*DENDRO_7*DENDRO_9;
		 const double DENDRO_13 = grad2_2_2_beta2[pp];
		 const double DENDRO_14 = grad2_0_1_beta0[pp];
		 const double DENDRO_15 = gt1[pp]*gt5[pp] - gt2[pp]*gt4[pp];
		 const double DENDRO_16 = (7.0L/3.0L)*DENDRO_15*DENDRO_7;
		 const double DENDRO_17 = grad2_1_1_beta1[pp];
		 const double DENDRO_18 = (1.0L/3.0L)*DENDRO_15*DENDRO_7;
		 const double DENDRO_19 = grad2_1_2_beta2[pp];
		 const double DENDRO_20 = -DENDRO_3 + DENDRO_5;
		 const double DENDRO_21 = DENDRO_20*DENDRO_7;
		 const double DENDRO_22 = -DENDRO_4 + gt0[pp]*gt5[pp];
		 const double DENDRO_23 = DENDRO_22*DENDRO_7;
		 const double DENDRO_24 = grad2_0_0_beta0[pp];
		 const double DENDRO_25 = -DENDRO_2 + gt3[pp]*gt5[pp];
		 const double DENDRO_26 = DENDRO_25*DENDRO_7;
		 const double DENDRO_27 = grad2_0_1_beta1[pp];
		 const double DENDRO_28 = (1.0L/3.0L)*DENDRO_25*DENDRO_7;
		 const double DENDRO_29 = grad2_0_2_beta2[pp];
		 const double DENDRO_30 = pow(DENDRO_6, -2);
		 const double DENDRO_31 = 2*DENDRO_30*grad_0_alpha[pp];
		 const double DENDRO_32 = pow(DENDRO_15, 2);
		 const double DENDRO_33 = pow(DENDRO_9, 2);
		 const double DENDRO_34 = DENDRO_15*DENDRO_9;
		 const double DENDRO_35 = 2*At1[pp]*DENDRO_15;
		 const double DENDRO_36 = 2*At2[pp]*DENDRO_9;
		 const double DENDRO_37 = At0[pp]*pow(DENDRO_25, 2) + At3[pp]*DENDRO_32 - 2*At4[pp]*DENDRO_34 + At5[pp]*DENDRO_33 - DENDRO_25*DENDRO_35 + DENDRO_25*DENDRO_36;
		 const double DENDRO_38 = (1.0L/3.0L)*DENDRO_7*alpha[pp];
		 const double DENDRO_39 = grad_0_K[pp];
		 const double DENDRO_40 = 1.0/chi[pp];
		 const double DENDRO_41 = 9*DENDRO_40*DENDRO_7*grad_0_chi[pp];
		 const double DENDRO_42 = grad_0_gt0[pp];
		 const double DENDRO_43 = grad_1_gt0[pp];
		 const double DENDRO_44 = -0.5*DENDRO_43 + 1.0*grad_0_gt1[pp];
		 const double DENDRO_45 = grad_2_gt0[pp];
		 const double DENDRO_46 = -0.5*DENDRO_45 + 1.0*grad_0_gt2[pp];
		 const double DENDRO_47 = DENDRO_15*DENDRO_44 - 0.5*DENDRO_25*DENDRO_42 - DENDRO_46*DENDRO_9;
		 const double DENDRO_48 = pow(DENDRO_6, -3);
		 const double DENDRO_49 = 2*DENDRO_37*DENDRO_48*alpha[pp];
		 const double DENDRO_50 = grad_1_gt3[pp];
		 const double DENDRO_51 = 0.5*gt1[pp]*gt5[pp] - 0.5*gt2[pp]*gt4[pp];
		 const double DENDRO_52 = grad_2_gt3[pp];
		 const double DENDRO_53 = -0.5*DENDRO_52 + 1.0*grad_1_gt4[pp];
		 const double DENDRO_54 = grad_0_gt3[pp];
		 const double DENDRO_55 = 0.5*DENDRO_54 - 1.0*grad_1_gt1[pp];
		 const double DENDRO_56 = DENDRO_25*DENDRO_55 + DENDRO_50*DENDRO_51 - DENDRO_53*DENDRO_9;
		 const double DENDRO_57 = pow(DENDRO_1, 2);
		 const double DENDRO_58 = DENDRO_1*DENDRO_15;
		 const double DENDRO_59 = 2*At4[pp]*DENDRO_1;
		 const double DENDRO_60 = At0[pp]*DENDRO_32 + 2*At2[pp]*DENDRO_58 + At3[pp]*pow(DENDRO_22, 2) + At5[pp]*DENDRO_57 - DENDRO_22*DENDRO_35 - DENDRO_22*DENDRO_59;
		 const double DENDRO_61 = 2*DENDRO_48*DENDRO_60*alpha[pp];
		 const double DENDRO_62 = grad_2_gt5[pp];
		 const double DENDRO_63 = 0.5*gt1[pp]*gt4[pp] - 0.5*gt2[pp]*gt3[pp];
		 const double DENDRO_64 = grad_1_gt5[pp];
		 const double DENDRO_65 = 0.5*DENDRO_64 - 1.0*grad_2_gt4[pp];
		 const double DENDRO_66 = grad_0_gt5[pp];
		 const double DENDRO_67 = 0.5*DENDRO_66 - 1.0*grad_2_gt2[pp];
		 const double DENDRO_68 = -DENDRO_15*DENDRO_65 + DENDRO_25*DENDRO_67 - DENDRO_62*DENDRO_63;
		 const double DENDRO_69 = DENDRO_1*DENDRO_9;
		 const double DENDRO_70 = At0[pp]*DENDRO_33 - 2*At1[pp]*DENDRO_69 + At3[pp]*DENDRO_57 + At5[pp]*pow(DENDRO_20, 2) + DENDRO_20*DENDRO_36 - DENDRO_20*DENDRO_59;
		 const double DENDRO_71 = 2*DENDRO_48*DENDRO_70*alpha[pp];
		 const double DENDRO_72 = 2*DENDRO_30*grad_2_alpha[pp];
		 const double DENDRO_73 = At0[pp]*DENDRO_25;
		 const double DENDRO_74 = At5[pp]*DENDRO_20;
		 const double DENDRO_75 = DENDRO_1*DENDRO_25;
		 const double DENDRO_76 = DENDRO_15*DENDRO_20;
		 const double DENDRO_77 = -At1[pp]*DENDRO_34 - At1[pp]*DENDRO_75 + At2[pp]*DENDRO_20*DENDRO_25 + At2[pp]*DENDRO_33 + At3[pp]*DENDRO_58 - At4[pp]*DENDRO_69 - At4[pp]*DENDRO_76 + DENDRO_73*DENDRO_9 + DENDRO_74*DENDRO_9;
		 const double DENDRO_78 = 2*DENDRO_30*grad_1_alpha[pp];
		 const double DENDRO_79 = At1[pp]*DENDRO_32;
		 const double DENDRO_80 = At4[pp]*DENDRO_58;
		 const double DENDRO_81 = At2[pp]*DENDRO_34;
		 const double DENDRO_82 = DENDRO_22*DENDRO_9;
		 const double DENDRO_83 = At4[pp]*DENDRO_82;
		 const double DENDRO_84 = At5[pp]*DENDRO_69;
		 const double DENDRO_85 = DENDRO_15*DENDRO_73;
		 const double DENDRO_86 = At1[pp]*DENDRO_22*DENDRO_25;
		 const double DENDRO_87 = At2[pp]*DENDRO_75;
		 const double DENDRO_88 = At3[pp]*DENDRO_22;
		 const double DENDRO_89 = DENDRO_15*DENDRO_88;
		 const double DENDRO_90 = DENDRO_79 + DENDRO_80 - DENDRO_81 + DENDRO_83 - DENDRO_84 - DENDRO_85 + DENDRO_86 - DENDRO_87 - DENDRO_89;
		 const double DENDRO_91 = grad_0_gt4[pp];
		 const double DENDRO_92 = grad_2_gt1[pp];
		 const double DENDRO_93 = grad_1_gt2[pp];
		 const double DENDRO_94 = DENDRO_91 + DENDRO_92 - DENDRO_93;
		 const double DENDRO_95 = DENDRO_15*DENDRO_94 - DENDRO_25*DENDRO_45 - DENDRO_66*DENDRO_9;
		 const double DENDRO_96 = 2.0*DENDRO_48*DENDRO_77*alpha[pp];
		 const double DENDRO_97 = grad_2_K[pp];
		 const double DENDRO_98 = 4*gt1[pp]*gt4[pp] - 4*gt2[pp]*gt3[pp];
		 const double DENDRO_99 = 9*DENDRO_40*DENDRO_7*grad_2_chi[pp];
		 const double DENDRO_100 = DENDRO_91 - DENDRO_92 + DENDRO_93;
		 const double DENDRO_101 = -DENDRO_100*DENDRO_9 + DENDRO_15*DENDRO_54 - DENDRO_25*DENDRO_43;
		 const double DENDRO_102 = 2.0*DENDRO_48*DENDRO_90*alpha[pp];
		 const double DENDRO_103 = -DENDRO_91 + DENDRO_92 + DENDRO_93;
		 const double DENDRO_104 = -DENDRO_103*DENDRO_25 + DENDRO_15*DENDRO_52 - DENDRO_64*DENDRO_9;
		 const double DENDRO_105 = At4[pp]*DENDRO_57;
		 const double DENDRO_106 = At1[pp]*DENDRO_58;
		 const double DENDRO_107 = At0[pp]*DENDRO_34;
		 const double DENDRO_108 = At1[pp]*DENDRO_82;
		 const double DENDRO_109 = At2[pp]*DENDRO_69;
		 const double DENDRO_110 = At2[pp]*DENDRO_76;
		 const double DENDRO_111 = DENDRO_1*DENDRO_88;
		 const double DENDRO_112 = At4[pp]*DENDRO_20*DENDRO_22;
		 const double DENDRO_113 = DENDRO_1*DENDRO_74;
		 const double DENDRO_114 = DENDRO_105 + DENDRO_106 - DENDRO_107 + DENDRO_108 - DENDRO_109 - DENDRO_110 - DENDRO_111 + DENDRO_112 - DENDRO_113;
		 const double DENDRO_115 = 2.0*DENDRO_114*DENDRO_48*alpha[pp];
		 const double DENDRO_116 = grad_1_K[pp];
		 const double DENDRO_117 = 4*gt1[pp]*gt5[pp] - 4*gt2[pp]*gt4[pp];
		 const double DENDRO_118 = 9*DENDRO_40*DENDRO_7*grad_1_chi[pp];
		 const double DENDRO_119 = DENDRO_1*DENDRO_64 + DENDRO_103*DENDRO_15 - DENDRO_22*DENDRO_52;
		 const double DENDRO_120 = DENDRO_1*DENDRO_119;
		 const double DENDRO_121 = DENDRO_1*DENDRO_100 + DENDRO_15*DENDRO_43 - DENDRO_22*DENDRO_54;
		 const double DENDRO_122 = DENDRO_121*DENDRO_15;
		 const double DENDRO_123 = DENDRO_1*DENDRO_66 + DENDRO_15*DENDRO_45 - DENDRO_22*DENDRO_94;
		 const double DENDRO_124 = DENDRO_123*DENDRO_9;
		 const double DENDRO_125 = 0.5*gt0[pp]*gt4[pp] - 0.5*gt1[pp]*gt2[pp];
		 const double DENDRO_126 = DENDRO_125*DENDRO_62 - DENDRO_15*DENDRO_67 + DENDRO_22*DENDRO_65;
		 const double DENDRO_127 = DENDRO_126*DENDRO_20;
		 const double DENDRO_128 = 0.5*DENDRO_22*DENDRO_50;
		 const double DENDRO_129 = DENDRO_1*DENDRO_53;
		 const double DENDRO_130 = DENDRO_15*DENDRO_55;
		 const double DENDRO_131 = DENDRO_22*(-DENDRO_128 + DENDRO_129 - DENDRO_130);
		 const double DENDRO_132 = DENDRO_1*DENDRO_46 - DENDRO_22*DENDRO_44 + DENDRO_42*DENDRO_51;
		 const double DENDRO_133 = DENDRO_132*DENDRO_25;
		 const double DENDRO_134 = DENDRO_30*(DENDRO_120 + DENDRO_122 - 1.0*DENDRO_124 - DENDRO_127 - DENDRO_131 - DENDRO_133);
		 const double DENDRO_135 = DENDRO_1*DENDRO_52 - DENDRO_103*DENDRO_9 - DENDRO_20*DENDRO_64;
		 const double DENDRO_136 = DENDRO_1*DENDRO_135;
		 const double DENDRO_137 = DENDRO_1*DENDRO_54 - DENDRO_100*DENDRO_20 - DENDRO_43*DENDRO_9;
		 const double DENDRO_138 = DENDRO_137*DENDRO_15;
		 const double DENDRO_139 = DENDRO_1*DENDRO_94 - DENDRO_20*DENDRO_66 - DENDRO_45*DENDRO_9;
		 const double DENDRO_140 = DENDRO_139*DENDRO_9;
		 const double DENDRO_141 = -DENDRO_1*DENDRO_65 - 0.5*DENDRO_20*DENDRO_62 + DENDRO_67*DENDRO_9;
		 const double DENDRO_142 = DENDRO_141*DENDRO_20;
		 const double DENDRO_143 = DENDRO_125*DENDRO_50 - DENDRO_20*DENDRO_53 + DENDRO_55*DENDRO_9;
		 const double DENDRO_144 = DENDRO_143*DENDRO_22;
		 const double DENDRO_145 = DENDRO_1*DENDRO_44 - DENDRO_20*DENDRO_46 - DENDRO_42*DENDRO_63;
		 const double DENDRO_146 = DENDRO_145*DENDRO_25;
		 const double DENDRO_147 = DENDRO_30*(DENDRO_136 + DENDRO_138 - 1.0*DENDRO_140 - DENDRO_142 - DENDRO_144 - DENDRO_146);
		 const double DENDRO_148 = grad_0_beta0[pp];
		 const double DENDRO_149 = DENDRO_1*DENDRO_104;
		 const double DENDRO_150 = DENDRO_101*DENDRO_15;
		 const double DENDRO_151 = DENDRO_9*DENDRO_95;
		 const double DENDRO_152 = DENDRO_20*DENDRO_68;
		 const double DENDRO_153 = DENDRO_22*DENDRO_56;
		 const double DENDRO_154 = DENDRO_25*DENDRO_47;
		 const double DENDRO_155 = DENDRO_30*(DENDRO_149 + DENDRO_150 - 1.0*DENDRO_151 - DENDRO_152 - DENDRO_153 - DENDRO_154);
		 const double DENDRO_156 = grad_1_beta1[pp];
		 const double DENDRO_157 = grad_2_beta2[pp];
		 const double DENDRO_158 = (2.0L/3.0L)*DENDRO_148 + (2.0L/3.0L)*DENDRO_156 + (2.0L/3.0L)*DENDRO_157;
		 const double DENDRO_159 = (1.0L/3.0L)*DENDRO_1*DENDRO_7;
		 const double DENDRO_160 = (7.0L/3.0L)*DENDRO_1*DENDRO_7;
		 const double DENDRO_161 = (1.0L/3.0L)*DENDRO_22*DENDRO_7;
		 const double DENDRO_162 = -DENDRO_105 - DENDRO_106 + DENDRO_107 - DENDRO_108 + DENDRO_109 + DENDRO_110 + DENDRO_111 - DENDRO_112 + DENDRO_113;
		 const double DENDRO_163 = -DENDRO_79 - DENDRO_80 + DENDRO_81 - DENDRO_83 + DENDRO_84 + DENDRO_85 - DENDRO_86 + DENDRO_87 + DENDRO_89;
		 const double DENDRO_164 = 2.0*DENDRO_48*alpha[pp];
		 const double DENDRO_165 = 4*gt0[pp]*gt4[pp] - 4*gt1[pp]*gt2[pp];
		 const double DENDRO_166 = DENDRO_30*(-1.0*DENDRO_120 - 1.0*DENDRO_122 + DENDRO_124 + DENDRO_127 + DENDRO_131 + DENDRO_133);
		 const double DENDRO_167 = (1.0L/3.0L)*DENDRO_20*DENDRO_7;
			      // Dendro: printing variables

		   Gt_rhs0[pp] = 2*DENDRO_1*DENDRO_7*grad2_1_2_beta0[pp] - DENDRO_10*DENDRO_8 + DENDRO_101*DENDRO_102 + DENDRO_104*DENDRO_115 - DENDRO_11*DENDRO_12 - DENDRO_12*DENDRO_13 - DENDRO_134*grad_1_beta0[pp] + DENDRO_14*DENDRO_16 - DENDRO_147*grad_2_beta0[pp] - DENDRO_148*DENDRO_155 + DENDRO_155*DENDRO_158 + DENDRO_17*DENDRO_18 + DENDRO_18*DENDRO_19 - DENDRO_21*grad2_2_2_beta0[pp] - DENDRO_23*grad2_1_1_beta0[pp] - 4.0L/3.0L*DENDRO_24*DENDRO_26 - DENDRO_27*DENDRO_28 - DENDRO_28*DENDRO_29 - DENDRO_31*DENDRO_37 - DENDRO_38*(DENDRO_116*DENDRO_117 + DENDRO_118*DENDRO_90) - DENDRO_38*(-4*DENDRO_25*DENDRO_39 + DENDRO_37*DENDRO_41) - DENDRO_38*(DENDRO_77*DENDRO_99 - DENDRO_97*DENDRO_98) + DENDRO_47*DENDRO_49 + DENDRO_56*DENDRO_61 + DENDRO_68*DENDRO_71 - DENDRO_72*DENDRO_77 - DENDRO_78*DENDRO_90 + DENDRO_95*DENDRO_96 + beta0[pp]*agrad_0_Gt0[pp] + beta1[pp]*agrad_1_Gt0[pp] + beta2[pp]*agrad_2_Gt0[pp];
		   Gt_rhs1[pp] = DENDRO_11*DENDRO_160 - DENDRO_119*DENDRO_162*DENDRO_164 - DENDRO_121*DENDRO_163*DENDRO_164 + DENDRO_123*DENDRO_96 + DENDRO_126*DENDRO_71 + DENDRO_13*DENDRO_159 + DENDRO_132*DENDRO_49 - DENDRO_14*DENDRO_161 + DENDRO_156*DENDRO_166 - DENDRO_158*DENDRO_166 + DENDRO_159*DENDRO_8 + DENDRO_16*DENDRO_27 - DENDRO_161*DENDRO_19 + DENDRO_162*DENDRO_72 + DENDRO_163*DENDRO_31 - 4.0L/3.0L*DENDRO_17*DENDRO_23 + DENDRO_18*DENDRO_24 + DENDRO_18*DENDRO_29 - DENDRO_21*grad2_2_2_beta1[pp] - DENDRO_26*grad2_0_0_beta1[pp] + DENDRO_30*(-1.0*DENDRO_136 - 1.0*DENDRO_138 + DENDRO_140 + DENDRO_142 + DENDRO_144 + DENDRO_146)*grad_2_beta1[pp] + DENDRO_30*(-1.0*DENDRO_149 - 1.0*DENDRO_150 + DENDRO_151 + DENDRO_152 + DENDRO_153 + DENDRO_154)*grad_0_beta1[pp] + DENDRO_38*(4*DENDRO_116*DENDRO_22 - DENDRO_118*DENDRO_60) - DENDRO_38*(DENDRO_117*DENDRO_39 - DENDRO_163*DENDRO_41) - DENDRO_38*(-DENDRO_162*DENDRO_99 + DENDRO_165*DENDRO_97) - DENDRO_60*DENDRO_78 - DENDRO_61*(DENDRO_128 - DENDRO_129 + DENDRO_130) - 2*DENDRO_7*DENDRO_9*grad2_0_2_beta1[pp] + beta0[pp]*agrad_0_Gt1[pp] + beta1[pp]*agrad_1_Gt1[pp] + beta2[pp]*agrad_2_Gt1[pp];
		   Gt_rhs2[pp] = -DENDRO_10*DENDRO_29 + DENDRO_102*DENDRO_137 - DENDRO_11*DENDRO_167 - DENDRO_114*DENDRO_78 + DENDRO_115*DENDRO_135 - DENDRO_12*DENDRO_24 - DENDRO_12*DENDRO_27 - 4.0L/3.0L*DENDRO_13*DENDRO_21 - DENDRO_134*grad_1_beta2[pp] + DENDRO_139*DENDRO_96 + DENDRO_14*DENDRO_159 + DENDRO_141*DENDRO_71 + DENDRO_143*DENDRO_61 + DENDRO_145*DENDRO_49 - DENDRO_147*DENDRO_157 + DENDRO_147*DENDRO_158 + 2*DENDRO_15*DENDRO_7*grad2_0_1_beta2[pp] - DENDRO_155*grad_0_beta2[pp] + DENDRO_159*DENDRO_17 + DENDRO_160*DENDRO_19 - DENDRO_167*DENDRO_8 - DENDRO_23*grad2_1_1_beta2[pp] - DENDRO_26*grad2_0_0_beta2[pp] - DENDRO_31*DENDRO_77 - DENDRO_38*(DENDRO_114*DENDRO_118 + DENDRO_116*DENDRO_165) - DENDRO_38*(-4*DENDRO_20*DENDRO_97 + DENDRO_70*DENDRO_99) - DENDRO_38*(-DENDRO_39*DENDRO_98 + DENDRO_41*DENDRO_77) - DENDRO_70*DENDRO_72 + beta0[pp]*agrad_0_Gt2[pp] + beta1[pp]*agrad_1_Gt2[pp] + beta2[pp]*agrad_2_Gt2[pp];
			      // Dendro: reduced ops: 732
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(Gt_rhs0, &__unzipOutVar[cuda::VAR::U_GT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(Gt_rhs2, &__unzipOutVar[cuda::VAR::U_GT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(Gt_rhs1, &__unzipOutVar[cuda::VAR::U_GT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_Gt_rhs 

/**@brief compute B_rhs 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __compute_B_rhs(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){



	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	//                             generated code for B_rhs              begin   
	///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();

	const unsigned int tile_sz[3]={3,3,3};
	
	 //input vars begin
	double * gt1 = __sm_base + 0;
	double * beta1 = __sm_base + 27;
	double * gt3 = __sm_base + 54;
	double * At1 = __sm_base + 81;
	double * gt5 = __sm_base + 108;
	double * gt4 = __sm_base + 135;
	double * alpha = __sm_base + 162;
	double * gt2 = __sm_base + 189;
	double * At3 = __sm_base + 216;
	double * beta2 = __sm_base + 243;
	double * B2 = __sm_base + 270;
	double * At4 = __sm_base + 297;
	double * At0 = __sm_base + 324;
	double * At2 = __sm_base + 351;
	double * beta0 = __sm_base + 378;
	double * gt0 = __sm_base + 405;
	double * chi = __sm_base + 432;
	double * B1 = __sm_base + 459;
	double * B0 = __sm_base + 486;
	double * At5 = __sm_base + 513;
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	double * grad_0_gt5 = __sm_base + 540;
	double * grad_1_gt0 = __sm_base + 567;
	double * agrad_0_B1 = __sm_base + 594;
	double * grad2_1_2_beta2 = __sm_base + 621;
	double * grad_2_K = __sm_base + 648;
	double * grad_0_beta0 = __sm_base + 675;
	double * grad_2_gt0 = __sm_base + 702;
	double * grad_0_gt4 = __sm_base + 729;
	double * grad2_1_1_beta1 = __sm_base + 756;
	double * grad_2_gt3 = __sm_base + 783;
	double * grad2_0_1_beta0 = __sm_base + 810;
	double * grad2_0_0_beta1 = __sm_base + 837;
	double * grad_1_K = __sm_base + 864;
	double * grad_1_alpha = __sm_base + 891;
	double * grad2_0_2_beta1 = __sm_base + 918;
	double * grad2_0_1_beta1 = __sm_base + 945;
	double * grad2_2_2_beta2 = __sm_base + 972;
	double * grad_1_beta1 = __sm_base + 999;
	double * grad_2_alpha = __sm_base + 1026;
	double * grad_2_beta0 = __sm_base + 1053;
	double * grad_0_gt1 = __sm_base + 1080;
	double * grad_1_gt5 = __sm_base + 1107;
	double * agrad_2_B0 = __sm_base + 1134;
	double * agrad_2_Gt1 = __sm_base + 1161;
	double * agrad_1_B1 = __sm_base + 1188;
	double * agrad_0_Gt2 = __sm_base + 1215;
	double * grad2_1_1_beta2 = __sm_base + 1242;
	double * grad_1_gt4 = __sm_base + 1269;
	double * grad2_2_2_beta1 = __sm_base + 1296;
	double * grad_1_gt1 = __sm_base + 1323;
	double * agrad_2_B1 = __sm_base + 1350;
	double * grad_2_gt4 = __sm_base + 1377;
	double * grad_0_beta1 = __sm_base + 1404;
	double * agrad_1_B0 = __sm_base + 1431;
	double * grad_0_alpha = __sm_base + 1458;
	double * agrad_0_B0 = __sm_base + 1485;
	double * grad_0_chi = __sm_base + 1512;
	double * grad_2_beta2 = __sm_base + 1539;
	double * grad2_1_2_beta0 = __sm_base + 1566;
	double * grad2_1_1_beta0 = __sm_base + 1593;
	double * agrad_0_Gt1 = __sm_base + 1620;
	double * grad_0_K = __sm_base + 1647;
	double * agrad_1_B2 = __sm_base + 1674;
	double * grad2_0_2_beta2 = __sm_base + 1701;
	double * agrad_2_B2 = __sm_base + 1728;
	double * agrad_0_Gt0 = __sm_base + 1755;
	double * agrad_1_Gt1 = __sm_base + 1782;
	double * grad2_0_0_beta0 = __sm_base + 1809;
	double * agrad_1_Gt2 = __sm_base + 1836;
	double * agrad_1_Gt0 = __sm_base + 1863;
	double * grad_2_gt2 = __sm_base + 1890;
	double * grad_1_chi = __sm_base + 1917;
	double * grad_0_gt0 = __sm_base + 1944;
	double * agrad_0_B2 = __sm_base + 1971;
	double * grad_0_gt3 = __sm_base + 1998;
	double * grad2_2_2_beta0 = __sm_base + 2025;
	double * agrad_2_Gt2 = __sm_base + 2052;
	double * grad_2_beta1 = __sm_base + 2079;
	double * grad_2_gt5 = __sm_base + 2106;
	double * grad_1_beta0 = __sm_base + 2133;
	double * grad2_0_1_beta2 = __sm_base + 2160;
	double * grad_1_gt3 = __sm_base + 2187;
	double * grad2_0_2_beta0 = __sm_base + 2214;
	double * grad_2_chi = __sm_base + 2241;
	double * grad_2_gt1 = __sm_base + 2268;
	double * agrad_2_Gt0 = __sm_base + 2295;
	double * grad_0_gt2 = __sm_base + 2322;
	double * grad_0_beta2 = __sm_base + 2349;
	double * grad_1_beta2 = __sm_base + 2376;
	double * grad2_0_0_beta2 = __sm_base + 2403;
	double * grad_1_gt2 = __sm_base + 2430;
	double * grad2_1_2_beta1 = __sm_base + 2457;
	 // deriv vars end
	 // output vars begin
	double * B_rhs1 = __sm_base + 2484;
	double * B_rhs0 = __sm_base + 2511;
	double * B_rhs2 = __sm_base + 2538;
	 // output vars end
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 //load data from global to shared memory
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B2][offset],(double *) B2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B1][offset],(double *) B1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_B0][offset],(double *) B0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_B1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_B0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_B1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_B1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_B0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_B0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_K,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_B2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_B2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_1_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_0_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_0_B2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_2_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_2_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__agrad_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) agrad_2_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_0_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_0_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__grad2_1_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) grad2_1_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();



	if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 double x,y,z,r_coord,eta;
		 unsigned int pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
			  z = ptmin[2] + (k+ijk_lm[4])*dz;
			  y = ptmin[1] + (threadIdx.y+ijk_lm[2])*dy;
			  x = ptmin[0] + (threadIdx.x+ijk_lm[0])*dx;
			  r_coord = sqrt(x*x + y*y + z*z);
			  eta=ETA_CONST;
			  if (r_coord >= ETA_R0) {
			     eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
			  }

			  // Dendro: {{{ 
			  // Dendro: original ops: 17226
			     // Dendro: printing temp variables
		 const double DENDRO_0 = beta0[pp]*agrad_0_Gt0[pp] + beta1[pp]*agrad_1_Gt0[pp] + beta2[pp]*agrad_2_Gt0[pp];
		 const double DENDRO_1 = 2*gt0[pp]*gt4[pp] - 2*gt1[pp]*gt2[pp];
		 const double DENDRO_2 = pow(gt4[pp], 2);
		 const double DENDRO_3 = pow(gt1[pp], 2);
		 const double DENDRO_4 = pow(gt2[pp], 2);
		 const double DENDRO_5 = gt0[pp]*gt3[pp];
		 const double DENDRO_6 = gt1[pp]*gt2[pp];
		 const double DENDRO_7 = DENDRO_2*gt0[pp] + DENDRO_3*gt5[pp] + DENDRO_4*gt3[pp] - DENDRO_5*gt5[pp] - 2*DENDRO_6*gt4[pp];
		 const double DENDRO_8 = 1.0/DENDRO_7;
		 const double DENDRO_9 = grad2_0_2_beta0[pp];
		 const double DENDRO_10 = gt1[pp]*gt4[pp] - gt2[pp]*gt3[pp];
		 const double DENDRO_11 = (7.0L/3.0L)*DENDRO_10*DENDRO_8;
		 const double DENDRO_12 = grad2_1_2_beta1[pp];
		 const double DENDRO_13 = (1.0L/3.0L)*DENDRO_10*DENDRO_8;
		 const double DENDRO_14 = grad2_2_2_beta2[pp];
		 const double DENDRO_15 = grad2_0_1_beta0[pp];
		 const double DENDRO_16 = gt1[pp]*gt5[pp] - gt2[pp]*gt4[pp];
		 const double DENDRO_17 = (7.0L/3.0L)*DENDRO_16*DENDRO_8;
		 const double DENDRO_18 = grad2_1_1_beta1[pp];
		 const double DENDRO_19 = (1.0L/3.0L)*DENDRO_16*DENDRO_8;
		 const double DENDRO_20 = grad2_1_2_beta2[pp];
		 const double DENDRO_21 = -DENDRO_3 + DENDRO_5;
		 const double DENDRO_22 = DENDRO_21*DENDRO_8;
		 const double DENDRO_23 = -DENDRO_4 + gt0[pp]*gt5[pp];
		 const double DENDRO_24 = DENDRO_23*DENDRO_8;
		 const double DENDRO_25 = grad2_0_0_beta0[pp];
		 const double DENDRO_26 = -DENDRO_2 + gt3[pp]*gt5[pp];
		 const double DENDRO_27 = DENDRO_26*DENDRO_8;
		 const double DENDRO_28 = grad2_0_1_beta1[pp];
		 const double DENDRO_29 = (1.0L/3.0L)*DENDRO_26*DENDRO_8;
		 const double DENDRO_30 = grad2_0_2_beta2[pp];
		 const double DENDRO_31 = pow(DENDRO_7, -2);
		 const double DENDRO_32 = 2*DENDRO_31*grad_0_alpha[pp];
		 const double DENDRO_33 = pow(DENDRO_16, 2);
		 const double DENDRO_34 = pow(DENDRO_10, 2);
		 const double DENDRO_35 = 2*gt1[pp]*gt5[pp] - 2*gt2[pp]*gt4[pp];
		 const double DENDRO_36 = 2*gt1[pp]*gt4[pp] - 2*gt2[pp]*gt3[pp];
		 const double DENDRO_37 = At0[pp]*pow(DENDRO_26, 2) - At1[pp]*DENDRO_26*DENDRO_35 + At2[pp]*DENDRO_26*DENDRO_36 + At3[pp]*DENDRO_33 - At4[pp]*DENDRO_10*DENDRO_35 + At5[pp]*DENDRO_34;
		 const double DENDRO_38 = grad_2_chi[pp];
		 const double DENDRO_39 = grad_1_chi[pp];
		 const double DENDRO_40 = grad_0_chi[pp];
		 const double DENDRO_41 = 2*DENDRO_38;
		 const double DENDRO_42 = -DENDRO_6 + gt0[pp]*gt4[pp];
		 const double DENDRO_43 = R0*sqrt(DENDRO_8*(-DENDRO_10*DENDRO_40*DENDRO_41 - DENDRO_21*pow(DENDRO_38, 2) - DENDRO_23*pow(DENDRO_39, 2) - DENDRO_26*pow(DENDRO_40, 2) + DENDRO_35*DENDRO_39*DENDRO_40 + DENDRO_39*DENDRO_41*DENDRO_42))*pow(-pow(chi[pp], eta_power[0]) + 1, -eta_power[1]);
		 const double DENDRO_44 = (1.0L/3.0L)*DENDRO_8*alpha[pp];
		 const double DENDRO_45 = grad_0_K[pp];
		 const double DENDRO_46 = 1.0/chi[pp];
		 const double DENDRO_47 = 9*DENDRO_40*DENDRO_46*DENDRO_8;
		 const double DENDRO_48 = grad_0_gt0[pp];
		 const double DENDRO_49 = grad_1_gt0[pp];
		 const double DENDRO_50 = -0.5*DENDRO_49 + 1.0*grad_0_gt1[pp];
		 const double DENDRO_51 = grad_2_gt0[pp];
		 const double DENDRO_52 = -0.5*DENDRO_51 + 1.0*grad_0_gt2[pp];
		 const double DENDRO_53 = -DENDRO_10*DENDRO_52 + DENDRO_16*DENDRO_50 - 0.5*DENDRO_26*DENDRO_48;
		 const double DENDRO_54 = pow(DENDRO_7, -3);
		 const double DENDRO_55 = 2*DENDRO_37*DENDRO_54*alpha[pp];
		 const double DENDRO_56 = grad_1_gt3[pp];
		 const double DENDRO_57 = 0.5*gt1[pp]*gt5[pp] - 0.5*gt2[pp]*gt4[pp];
		 const double DENDRO_58 = grad_2_gt3[pp];
		 const double DENDRO_59 = -0.5*DENDRO_58 + 1.0*grad_1_gt4[pp];
		 const double DENDRO_60 = grad_0_gt3[pp];
		 const double DENDRO_61 = 0.5*DENDRO_60 - 1.0*grad_1_gt1[pp];
		 const double DENDRO_62 = -DENDRO_10*DENDRO_59 + DENDRO_26*DENDRO_61 + DENDRO_56*DENDRO_57;
		 const double DENDRO_63 = pow(DENDRO_42, 2);
		 const double DENDRO_64 = At1[pp]*DENDRO_23;
		 const double DENDRO_65 = At0[pp]*DENDRO_33 + At2[pp]*DENDRO_35*DENDRO_42 + At3[pp]*pow(DENDRO_23, 2) - At4[pp]*DENDRO_1*DENDRO_23 + At5[pp]*DENDRO_63 - DENDRO_35*DENDRO_64;
		 const double DENDRO_66 = 2*DENDRO_54*DENDRO_65*alpha[pp];
		 const double DENDRO_67 = grad_2_gt5[pp];
		 const double DENDRO_68 = 0.5*gt1[pp]*gt4[pp] - 0.5*gt2[pp]*gt3[pp];
		 const double DENDRO_69 = grad_1_gt5[pp];
		 const double DENDRO_70 = 0.5*DENDRO_69 - 1.0*grad_2_gt4[pp];
		 const double DENDRO_71 = grad_0_gt5[pp];
		 const double DENDRO_72 = 0.5*DENDRO_71 - 1.0*grad_2_gt2[pp];
		 const double DENDRO_73 = -DENDRO_16*DENDRO_70 + DENDRO_26*DENDRO_72 - DENDRO_67*DENDRO_68;
		 const double DENDRO_74 = DENDRO_10*DENDRO_42;
		 const double DENDRO_75 = At2[pp]*DENDRO_21;
		 const double DENDRO_76 = At4[pp]*DENDRO_21;
		 const double DENDRO_77 = At0[pp]*DENDRO_34 - 2*At1[pp]*DENDRO_74 + At3[pp]*DENDRO_63 + At5[pp]*pow(DENDRO_21, 2) - DENDRO_1*DENDRO_76 + DENDRO_36*DENDRO_75;
		 const double DENDRO_78 = 2*DENDRO_54*DENDRO_77*alpha[pp];
		 const double DENDRO_79 = 2*DENDRO_31*grad_2_alpha[pp];
		 const double DENDRO_80 = DENDRO_16*DENDRO_42;
		 const double DENDRO_81 = At0[pp]*DENDRO_26;
		 const double DENDRO_82 = DENDRO_10*DENDRO_16;
		 const double DENDRO_83 = At5[pp]*DENDRO_21;
		 const double DENDRO_84 = DENDRO_26*DENDRO_42;
		 const double DENDRO_85 = DENDRO_16*DENDRO_21;
		 const double DENDRO_86 = -At1[pp]*DENDRO_82 - At1[pp]*DENDRO_84 + At2[pp]*DENDRO_34 + At3[pp]*DENDRO_80 - At4[pp]*DENDRO_74 - At4[pp]*DENDRO_85 + DENDRO_10*DENDRO_81 + DENDRO_10*DENDRO_83 + DENDRO_26*DENDRO_75;
		 const double DENDRO_87 = 2*DENDRO_31*grad_1_alpha[pp];
		 const double DENDRO_88 = DENDRO_10*DENDRO_23;
		 const double DENDRO_89 = At3[pp]*DENDRO_23;
		 const double DENDRO_90 = At1[pp]*DENDRO_33 - At2[pp]*DENDRO_82 - At2[pp]*DENDRO_84 + At4[pp]*DENDRO_80 + At4[pp]*DENDRO_88 - At5[pp]*DENDRO_74 - DENDRO_16*DENDRO_81 - DENDRO_16*DENDRO_89 + DENDRO_26*DENDRO_64;
		 const double DENDRO_91 = grad_0_gt4[pp];
		 const double DENDRO_92 = grad_2_gt1[pp];
		 const double DENDRO_93 = grad_1_gt2[pp];
		 const double DENDRO_94 = DENDRO_91 + DENDRO_92 - DENDRO_93;
		 const double DENDRO_95 = -DENDRO_10*DENDRO_71 + DENDRO_16*DENDRO_94 - DENDRO_26*DENDRO_51;
		 const double DENDRO_96 = 2.0*DENDRO_54*DENDRO_86*alpha[pp];
		 const double DENDRO_97 = grad_2_K[pp];
		 const double DENDRO_98 = 4*gt1[pp]*gt4[pp] - 4*gt2[pp]*gt3[pp];
		 const double DENDRO_99 = 9*DENDRO_38*DENDRO_46*DENDRO_8;
		 const double DENDRO_100 = DENDRO_91 - DENDRO_92 + DENDRO_93;
		 const double DENDRO_101 = -DENDRO_10*DENDRO_100 + DENDRO_16*DENDRO_60 - DENDRO_26*DENDRO_49;
		 const double DENDRO_102 = 2.0*DENDRO_54*DENDRO_90*alpha[pp];
		 const double DENDRO_103 = -DENDRO_91 + DENDRO_92 + DENDRO_93;
		 const double DENDRO_104 = -DENDRO_10*DENDRO_69 - DENDRO_103*DENDRO_26 + DENDRO_16*DENDRO_58;
		 const double DENDRO_105 = -At0[pp]*DENDRO_82 + At1[pp]*DENDRO_80 + At1[pp]*DENDRO_88 - At2[pp]*DENDRO_74 - At2[pp]*DENDRO_85 + At4[pp]*DENDRO_63 + DENDRO_23*DENDRO_76 - DENDRO_42*DENDRO_83 - DENDRO_42*DENDRO_89;
		 const double DENDRO_106 = 2.0*DENDRO_105*DENDRO_54*alpha[pp];
		 const double DENDRO_107 = grad_1_K[pp];
		 const double DENDRO_108 = 4*gt1[pp]*gt5[pp] - 4*gt2[pp]*gt4[pp];
		 const double DENDRO_109 = 9*DENDRO_39*DENDRO_46*DENDRO_8;
		 const double DENDRO_110 = DENDRO_103*DENDRO_16 - DENDRO_23*DENDRO_58 + DENDRO_42*DENDRO_69;
		 const double DENDRO_111 = DENDRO_100*DENDRO_42 + DENDRO_16*DENDRO_49 - DENDRO_23*DENDRO_60;
		 const double DENDRO_112 = 1.0*gt1[pp]*gt4[pp] - 1.0*gt2[pp]*gt3[pp];
		 const double DENDRO_113 = DENDRO_16*DENDRO_51 - DENDRO_23*DENDRO_94 + DENDRO_42*DENDRO_71;
		 const double DENDRO_114 = 0.5*gt0[pp]*gt4[pp] - 0.5*gt1[pp]*gt2[pp];
		 const double DENDRO_115 = DENDRO_114*DENDRO_67 - DENDRO_16*DENDRO_72 + DENDRO_23*DENDRO_70;
		 const double DENDRO_116 = -DENDRO_16*DENDRO_61 - 0.5*DENDRO_23*DENDRO_56 + DENDRO_42*DENDRO_59;
		 const double DENDRO_117 = -DENDRO_23*DENDRO_50 + DENDRO_42*DENDRO_52 + DENDRO_48*DENDRO_57;
		 const double DENDRO_118 = DENDRO_31*(DENDRO_110*DENDRO_42 + DENDRO_111*DENDRO_16 - DENDRO_112*DENDRO_113 - DENDRO_115*DENDRO_21 - DENDRO_116*DENDRO_23 - DENDRO_117*DENDRO_26);
		 const double DENDRO_119 = -DENDRO_10*DENDRO_103 - DENDRO_21*DENDRO_69 + DENDRO_42*DENDRO_58;
		 const double DENDRO_120 = -DENDRO_10*DENDRO_49 - DENDRO_100*DENDRO_21 + DENDRO_42*DENDRO_60;
		 const double DENDRO_121 = -DENDRO_10*DENDRO_51 - DENDRO_21*DENDRO_71 + DENDRO_42*DENDRO_94;
		 const double DENDRO_122 = DENDRO_10*DENDRO_72 - 0.5*DENDRO_21*DENDRO_67 - DENDRO_42*DENDRO_70;
		 const double DENDRO_123 = DENDRO_10*DENDRO_61 + DENDRO_114*DENDRO_56 - DENDRO_21*DENDRO_59;
		 const double DENDRO_124 = -DENDRO_21*DENDRO_52 + DENDRO_42*DENDRO_50 - DENDRO_48*DENDRO_68;
		 const double DENDRO_125 = DENDRO_31*(-DENDRO_112*DENDRO_121 + DENDRO_119*DENDRO_42 + DENDRO_120*DENDRO_16 - DENDRO_122*DENDRO_21 - DENDRO_123*DENDRO_23 - DENDRO_124*DENDRO_26);
		 const double DENDRO_126 = grad_0_beta0[pp];
		 const double DENDRO_127 = DENDRO_31*(DENDRO_101*DENDRO_16 + DENDRO_104*DENDRO_42 - DENDRO_112*DENDRO_95 - DENDRO_21*DENDRO_73 - DENDRO_23*DENDRO_62 - DENDRO_26*DENDRO_53);
		 const double DENDRO_128 = grad_1_beta1[pp];
		 const double DENDRO_129 = grad_2_beta2[pp];
		 const double DENDRO_130 = (2.0L/3.0L)*DENDRO_126 + (2.0L/3.0L)*DENDRO_128 + (2.0L/3.0L)*DENDRO_129;
		 const double DENDRO_131 = beta0[pp]*agrad_0_Gt1[pp] + beta1[pp]*agrad_1_Gt1[pp] + beta2[pp]*agrad_2_Gt1[pp];
		 const double DENDRO_132 = (1.0L/3.0L)*DENDRO_42*DENDRO_8;
		 const double DENDRO_133 = (7.0L/3.0L)*DENDRO_42*DENDRO_8;
		 const double DENDRO_134 = (1.0L/3.0L)*DENDRO_23*DENDRO_8;
		 const double DENDRO_135 = 4*gt0[pp]*gt4[pp] - 4*gt1[pp]*gt2[pp];
		 const double DENDRO_136 = beta0[pp]*agrad_0_Gt2[pp] + beta1[pp]*agrad_1_Gt2[pp] + beta2[pp]*agrad_2_Gt2[pp];
		 const double DENDRO_137 = (1.0L/3.0L)*DENDRO_21*DENDRO_8;
			      // Dendro: printing variables

		   B_rhs0[pp] = -B0[pp]*DENDRO_43 - DENDRO_0*lambda[3] + DENDRO_0 + DENDRO_1*DENDRO_8*grad2_1_2_beta0[pp] + DENDRO_101*DENDRO_102 + DENDRO_104*DENDRO_106 - DENDRO_11*DENDRO_9 - DENDRO_118*grad_1_beta0[pp] - DENDRO_12*DENDRO_13 - DENDRO_125*grad_2_beta0[pp] - DENDRO_126*DENDRO_127 + DENDRO_127*DENDRO_130 - DENDRO_13*DENDRO_14 + DENDRO_15*DENDRO_17 + DENDRO_18*DENDRO_19 + DENDRO_19*DENDRO_20 - DENDRO_22*grad2_2_2_beta0[pp] - DENDRO_24*grad2_1_1_beta0[pp] - 4.0L/3.0L*DENDRO_25*DENDRO_27 - DENDRO_28*DENDRO_29 - DENDRO_29*DENDRO_30 - DENDRO_32*DENDRO_37 - DENDRO_44*(DENDRO_107*DENDRO_108 + DENDRO_109*DENDRO_90) - DENDRO_44*(-4*DENDRO_26*DENDRO_45 + DENDRO_37*DENDRO_47) - DENDRO_44*(DENDRO_86*DENDRO_99 - DENDRO_97*DENDRO_98) + DENDRO_53*DENDRO_55 + DENDRO_62*DENDRO_66 + DENDRO_73*DENDRO_78 - DENDRO_79*DENDRO_86 - DENDRO_87*DENDRO_90 + DENDRO_95*DENDRO_96 + lambda[2]*(beta0[pp]*agrad_0_B0[pp] + beta1[pp]*agrad_1_B0[pp] + beta2[pp]*agrad_2_B0[pp]);
		   B_rhs1[pp] = -B1[pp]*DENDRO_43 + DENDRO_102*DENDRO_111 - DENDRO_105*DENDRO_79 + DENDRO_106*DENDRO_110 + DENDRO_113*DENDRO_96 + DENDRO_115*DENDRO_78 + DENDRO_116*DENDRO_66 + DENDRO_117*DENDRO_55 - DENDRO_118*DENDRO_128 + DENDRO_118*DENDRO_130 + DENDRO_12*DENDRO_133 - DENDRO_125*grad_2_beta1[pp] - DENDRO_127*grad_0_beta1[pp] - DENDRO_131*lambda[3] + DENDRO_131 + DENDRO_132*DENDRO_14 + DENDRO_132*DENDRO_9 - DENDRO_134*DENDRO_15 - DENDRO_134*DENDRO_20 + DENDRO_17*DENDRO_28 - 4.0L/3.0L*DENDRO_18*DENDRO_24 + DENDRO_19*DENDRO_25 + DENDRO_19*DENDRO_30 - DENDRO_22*grad2_2_2_beta1[pp] - DENDRO_27*grad2_0_0_beta1[pp] - DENDRO_32*DENDRO_90 - DENDRO_36*DENDRO_8*grad2_0_2_beta1[pp] - DENDRO_44*(DENDRO_105*DENDRO_99 + DENDRO_135*DENDRO_97) - DENDRO_44*(-4*DENDRO_107*DENDRO_23 + DENDRO_109*DENDRO_65) - DENDRO_44*(DENDRO_108*DENDRO_45 + DENDRO_47*DENDRO_90) - DENDRO_65*DENDRO_87 + lambda[2]*(beta0[pp]*agrad_0_B1[pp] + beta1[pp]*agrad_1_B1[pp] + beta2[pp]*agrad_2_B1[pp]);
		   B_rhs2[pp] = -B2[pp]*DENDRO_43 + DENDRO_102*DENDRO_120 - DENDRO_105*DENDRO_87 + DENDRO_106*DENDRO_119 - DENDRO_11*DENDRO_30 - DENDRO_118*grad_1_beta2[pp] - DENDRO_12*DENDRO_137 + DENDRO_121*DENDRO_96 + DENDRO_122*DENDRO_78 + DENDRO_123*DENDRO_66 + DENDRO_124*DENDRO_55 - DENDRO_125*DENDRO_129 + DENDRO_125*DENDRO_130 - DENDRO_127*grad_0_beta2[pp] - DENDRO_13*DENDRO_25 - DENDRO_13*DENDRO_28 + DENDRO_132*DENDRO_15 + DENDRO_132*DENDRO_18 + DENDRO_133*DENDRO_20 - DENDRO_136*lambda[3] + DENDRO_136 - DENDRO_137*DENDRO_9 - 4.0L/3.0L*DENDRO_14*DENDRO_22 - DENDRO_24*grad2_1_1_beta2[pp] - DENDRO_27*grad2_0_0_beta2[pp] - DENDRO_32*DENDRO_86 + DENDRO_35*DENDRO_8*grad2_0_1_beta2[pp] - DENDRO_44*(DENDRO_105*DENDRO_109 + DENDRO_107*DENDRO_135) - DENDRO_44*(-4*DENDRO_21*DENDRO_97 + DENDRO_77*DENDRO_99) - DENDRO_44*(-DENDRO_45*DENDRO_98 + DENDRO_47*DENDRO_86) - DENDRO_77*DENDRO_79 + lambda[2]*(beta0[pp]*agrad_0_B2[pp] + beta1[pp]*agrad_1_B2[pp] + beta2[pp]*agrad_2_B2[pp]);
			      // Dendro: reduced ops: 765
			      // Dendro: }}} 
			     } //loop z end 
	}// end of the if for the thread idx 
			__syncthreads();

			// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(B_rhs1, &__unzipOutVar[cuda::VAR::U_B1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(B_rhs0, &__unzipOutVar[cuda::VAR::U_B0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal3D<double>(B_rhs2, &__unzipOutVar[cuda::VAR::U_B2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		   __syncthreads();
	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

} // end of function__compute_B_rhs 

/**@brief apply KO dissipation 
 @param[in] __unzipInVar: unzipped input array (global memory) 
 @param[in] MemoryDerivs: allocated workspace for derivative computations 
 @param[in] __dendroBlkList: dendro block list 
 @param[in] __gpuBlockMap: gpu block map  
 @param[in] __deviceProperties: cuda device properties  
 @param[out] __unzipOutVar: unzipped output computed rhs  
*/ 
__device__ void __ko_dissipation(double **__unzipOutVar, const double**__unzipInVar,MemoryDerivs* __derivWorkspace, const cuda::_Block* dblock, const unsigned int * __gpuBlockMap,const cuda::BSSNComputeParams * __bssnParams,const cudaDeviceProp* __deviceProperties, double* __sm_base, unsigned int stream_id){

	// bssn compute parameters 
	const double lambda[4]={__bssnParams->BSSN_LAMBDA[0],__bssnParams->BSSN_LAMBDA[1],__bssnParams->BSSN_LAMBDA[2],__bssnParams->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnParams->BSSN_LAMBDA_F[0],__bssnParams->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnParams->KO_DISS_SIGMA;
	const double ETA_R0=__bssnParams->ETA_R0;
	const double R0=__bssnParams->ETA_R0;
	const double ETA_DAMPING=__bssnParams->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnParams->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnParams->ETA_CONST;
	const double eta_power[2]={__bssnParams->BSSN_ETA_POWER[0],__bssnParams->BSSN_ETA_POWER[1]};
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=get_smid();//blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock->getOffset();
	const unsigned int *sz=dblock->getSz();
	const unsigned int *alignedSz=dblock->getAlignedSz();
	const double* hx=dblock->getDx();
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const double* ptmin=dblock->getPtMin();
	const double* ptmax=dblock->getPtMax();
	const unsigned int bflag=dblock->getBFlag();
	const unsigned int tile_sz[3]={10,10,10};
	double * kograd_0 = __sm_base + 0;
	double * kograd_1 = __sm_base + 1000;
	double * kograd_2 = __sm_base + 2000;
	double * unZipSharedOut = __sm_base + 3000;
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
//!! Note that we assume tile size are cubic.
	const unsigned int BLK_ITERATIONS_X = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;
	const unsigned int BLK_ITERATIONS_Y = BLK_ITERATIONS_X;
	const unsigned int BLK_ITERATIONS_Z = BLK_ITERATIONS_X;

	unsigned int ijk_lm[3*2];
	unsigned int tile_lm[3*2];
	for(unsigned int iter_z=0;iter_z<BLK_ITERATIONS_Z;iter_z++){

		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter_z -2*iter_z*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2]-1,sz[2]-3-1);

	  for(unsigned int iter_y=0;iter_y<BLK_ITERATIONS_Y;iter_y++){

		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter_y -2*iter_y*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1]-1,sz[1]-3-1);

	    for(unsigned int iter_x=0;iter_x<BLK_ITERATIONS_X;iter_x++){
		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter_x -2*iter_x*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0]-1,sz[0]-3-1);


		tile_lm[0]=0;
		tile_lm[1]=ijk_lm[1] - ijk_lm[0];

		tile_lm[2]=0;
		tile_lm[3]=ijk_lm[3] - ijk_lm[2];

		tile_lm[4]=0;
		tile_lm[5]=ijk_lm[5] - ijk_lm[4];
		 //if(threadIdx.x ==0 && threadIdx.y==0 && threadIdx.z==0)
		 //printf(" iter %d %d %d : threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter_x,iter_y,iter_z, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);



		 unsigned int pp;
		 //ko dissipation for variable alpha

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_alpha[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_ALPHA][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_ALPHA][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable beta0

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_beta0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_BETA0][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_BETA0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable beta1

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_beta1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_BETA1][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_BETA1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable beta2

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_beta2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_BETA2][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_BETA2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable gt0

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMGT0][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMGT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable gt1

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMGT1][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMGT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable gt2

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMGT2][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMGT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable gt3

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_gt3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMGT3][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMGT3][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable gt4

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_gt4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMGT4][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMGT4][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable gt5

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_gt5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMGT5][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMGT5][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable chi

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_chi[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_CHI][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_CHI][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable At0

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_At0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMAT0][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMAT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable At1

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_At1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMAT1][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMAT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable At2

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_At2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMAT2][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMAT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable At3

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_At3[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMAT3][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMAT3][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable At4

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_At4[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMAT4][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMAT4][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable At5

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_At5[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_SYMAT5][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_SYMAT5][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable K

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_K[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_K][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_K][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable Gt0

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_Gt0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_GT0][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_GT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable Gt1

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_Gt1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_GT1][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_GT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable Gt2

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_Gt2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_GT2][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_GT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable B0

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_B0[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_B0][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_B0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable B1

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_B1[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_B1][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_B1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

		 //ko dissipation for variable B2

		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_0_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_0,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_1_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_1,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&(__derivWorkspace->__kograd_2_B2[(stream_id*(__derivWorkspace->__szPerStream) + SM_ID*(__derivWorkspace->__maxBlkSz))]),(double *) kograd_2,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 cuda::__loadGlobalToShared3D<double>(&__unzipOutVar[cuda::VAR::U_B2][offset],(double *) unZipSharedOut,(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz,(const unsigned int *) tile_sz);
		 __syncthreads();

		if(!((threadIdx.x>(ijk_lm[1]-ijk_lm[0])) || (threadIdx.y>(ijk_lm[3]-ijk_lm[2]))) ){ 

		 pp=0*tile_sz[0]*tile_sz[1]+threadIdx.y*tile_sz[1]+threadIdx.x;
		  for(unsigned int k=0;k<=(ijk_lm[5]-ijk_lm[4]);++k,pp+=tile_sz[0]*tile_sz[1]){
		  unZipSharedOut[pp]  += kosigma * (kograd_0[pp] +kograd_1[pp] + kograd_2[pp]);
		  } //loop z end 
		}// end of the if for the thread idx 
		__syncthreads();

		// sotre computed variables

		cuda::__storeSharedToGlobal3D<double>(unZipSharedOut, &__unzipOutVar[cuda::VAR::U_B2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) alignedSz, (const unsigned int *) tile_lm,(const unsigned int *) tile_sz);
		__syncthreads();

	  } // end of block assigned to gpu block loop x 

	 } // end of block assigned to gpu block loop y 

	} // end of block assigned to gpu block loop z 

}// end of function __ko_dissipation
}// end of namespace cuda
